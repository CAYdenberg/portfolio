<!DOCTYPE html>
<html lang="en-CA">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">

		<title>On the emptiness of failed replications: the best parts | Casey A. Ydenberg</title>
		<meta name="description" content="Visual data and science communication on the web">

		<link rel="shortcut icon" href="../favicon.png">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
		<link rel="stylesheet" href="../style.css">
		<link rel="stylesheet" href="../print_styles.css" media="print">

		<link rel="canonical" href="on-the-emptiness-of-failed-replications-the-best-parts.html">
		<link rel="alternate" type="application/rss+xml" href="../feed/index.html">

		<meta name="og:title" content="On the emptiness of failed replications: the best parts | Casey A. Ydenberg">
		<meta name="og:image" content="https://res.cloudinary.com/dfxksdivn/image/upload/w_800/isqgg3q1ushpdqjodap0.png">
		<meta name="og:image:alt" content="Visual data and science communication on the web">
		<meta name="og:url" content="https://caydenberg.io/blog/on-the-emptiness-of-failed-replications-the-best-parts">

		<meta name="twitter:card" content="summary_large_image">
		<meta name="twitter:site" content="@CAYdenberg">
		<meta name="twitter:creator" content="@CAYdenberg">
		<meta name="twitter:title" content="On the emptiness of failed replications: the best parts | Casey A. Ydenberg">
		<meta name="twitter:description" content="Visual data and science communication on the web">
		<meta name="twitter:image" content="https://res.cloudinary.com/dfxksdivn/image/upload/w_800/isqgg3q1ushpdqjodap0.png">
		<meta name="twitter:image:alt" content="Visual data and science communication on the web">


	</head>

	<body class="blog">
		<div class="off-canvas-wrapper">
			<div class="off-canvas-wrapper-inner" data-off-canvas-wrapper>

          <div class="menu-toggle-wrapper">
            <button type="button" class="button hollow menu-toggle" data-toggle="sidebar-wrapper" aria-expanded="false" aria-controls="sidebar-wrapper">
              <i class="icon-bars"></i>
            </button>
          </div>

					<div class="off-canvas position-left reveal-for-large sidebar-wrapper" id="sidebar-wrapper" data-off-canvas>
						<div class="sidebar-filter">
							<aside class="sidebar-body">
								<h2 class="site-title"><a href="../index.html" class="natural">Casey A. Ydenberg</a></h2>
								<h3 class="site-description">Web Developer</h3>

								<ul class="main-nav" role="menu">
										<li class="active">
											<a href="../blog.html">Blog</a>
										</li>
										<li >
											<a href="../talks.html">Speaking</a>
										</li>
										<li >
											<a href="../contact.html">Contact</a>
										</li>
								</ul>

								<ul class="social-nav" role="menu">
									<li><a href="https://github.com/CAYdenberg" target="_blank"><i class="icon-github" title="GitHub profile"></i></a></li>
									<li><a href="https://twitter.com/CAYdenberg" target="_blank"><i class="icon-twitter" title="Twitter feed"></i></a></li>
									<li><a href="https://www.linkedin.com/in/caydenberg" target="_blank"><i class="icon-linkedin" title="LinkedIn page"></i></a></li>
								</ul>

							</aside>
						</div>
					</div>

				<div class="off-canvas-content" data-off-canvas-content>
					<article class="main-content">

		<header class="main-content__header">
			<h1>On the emptiness of failed replications: the best parts</h1>
			<p><a href="../blog.html">&larr; back to the blog</a></p>
		</header>

		<section class="main-content__body blog-content">
			<p>I&#39;ve had essentially no time for reading lately as I&#39;m doing SAHD thing, moving into a new house, and coding like a maniac whenever I get a spare hour, but there was so much buzz on Twitter around Jason Mitchell&#39;s essay <a href="http://wjh.harvard.edu/~jmitchel/writing/failed_science.htm">about replication studies in social psychology</a> that I had to take a half-hour to read it. And for all that is holy, let me just say: What. The. Fuck. That&#39;s 30 min of my life I can&#39;t get back. I will replicate the highlights below so that you don&#39;t have to read it yourself:</p>
<blockquote>
<p><span style="color: #000000;">Although the notion that negative findings deserve equal treatment may hold intuitive appeal, the very foundation of science rests on a profound asymmetry between positive and negative claims.  </span><span style="color: #000000;">Suppose I assert the existence of some phenomenon, and you deny it; for example, I claim that some non-white swans exist, and you claim that none do (i.e., that no swans exist that are any color other than white).  Whatever our <em>a priori</em> beliefs about the phenomenon, from an inductive standpoint, your negative claim (of nonexistence) is infinitely more tenuous than mine.  A single positive example is sufficient to falsify the assertion that something does not exist; one colorful swan is all it takes to rule out the impossibility that swans come in more than one color.  In contrast, negative examples can never establish the nonexistence of a phenomenon, because the next instance might always turn up a counterexample.  Prior to the turn of the 17<sup>th</sup> century, Europeans did indeed assume that all swans were white.  When European explorers observed black swans in Australia, this negative belief was instantly and permanently confuted.  Note the striking asymmetry here: a single positive finding (of a non-white swan) had more evidentiary value than millennia of negative observations.  What more, it is clear that the null claim cannot be reinstated by additional negative observations: rounding up trumpet after trumpet of white swans does not rescue the claim that no non-white swans exists [sic].</span></p>
</blockquote>
<p> The graduate caucus of the ecology department at my undergrad institution published a handbook with a cover image that was just the text &quot;p = 0.06&quot; in huge, friendly letters. Ecology data can take ages to collect, and the right-of-passage of many graduate students was to go through months of collection, analyze the data, and get a (barely) non-significant result. Generally speaking, the scientific hierarchy does not reward non-significant results, and Mitchell tells us why: people who get them are just incompetent scientists. </p>
<p>Mitchell&#39;s implicit assumption - throughout the essay - is that all statistical effects are real, even though the very nature of frequentist statistics forces us to accept that some percentage of positive results are false. Mitchell does not seem to understand statistics or the scientific method. He is searching for swans. </p>
<blockquote>
<p><span style="color: #000000;">[Other replication proponents agree that] any small number of failed experiments cannot dislodge a positive finding, but argues that we can nevertheless learn something important from the </span><em>distribution</em><span style="color: #000000;"> of effect sizes obtained using similar methods.</span><span style="color: #000000;">  </span><span style="color: #000000;">However, for most of the reasons above, such distributions will mainly describe the potency of our methods and those who use them, not the &quot;realness&quot; of an effect.</span><span style="color: #000000;">  </span><span style="color: #000000;">To illustrate this, imagine that I ask a hundred people each to experimentally determine the relation between the temperature and pressure of a gas.</span><span style="color: #000000;">  </span><span style="color: #000000;">Although the &quot;actual&quot; relation is perfectly linear, the group will generate a distribution of effect sizes, and this distribution will depend entirely on the experimental skill of the researchers: a hundred physics graduate students using state-of-the-art equipment will generate a different distribution than a group of seventh-graders working out of their kitchens.</span><span style="color: #000000;">  </span><span style="color: #000000;">In other words, distributions of effect sizes are no less dependent on the experimenters generating them than are single-point estimates. </span><span style="color: #000000;"> </span><span style="color: #000000;">Such distributions can, in a limited way, tell us something about the efficacy of experimenters and their methods, but they cannot be dispositive about whether a phenomenon &quot;exists&quot; or not. A repository of all attempted experiments might benefit our field, but only in the limited way of suggesting which methods—and experimenters—may be more or less robust, and not by bearing on the existence of a phenomenon.</span></p>
</blockquote>
<p>The pharmaceutical industry will be <a href="https://www.ted.com/talks/ben_goldacre_what_doctors_don_t_know_about_the_drugs_they_prescribe">very relieved</a>. The lowest p-values are just the most &quot;right&quot;. </p>
<p>And finally, the problem: </p>
<blockquote>
<p><span style="color: #292f33;">How do we identify replications that fail simply because of undetected experimenter error?</span></p>
</blockquote>
<p>Uh, do it again? </p>
<p>I agree with Mitchell about one thing: one should not do replication studies in an attempt to smear the original authors. If a replication &quot;fails&quot; (a poor word, because it does not distinguish between the experiment being done badly and being done well but failing to find a positive effect), something is fishy, and both groups should work together to find out what happened. That advances science. If they can&#39;t, so be it. Working at the bleeding edge of knowledge means that some things &quot;might&quot; be true. </p>
<p>It&#39;s not even the idea that experiments should not be replicated that bugs me, it&#39;s the idea that null results have no value. It&#39;s the idea that negative results can be the result of error, but positive results can&#39;t. In my own scientific experience, this is simply <a href="http://www.caseyy.org/blog/rivers-vs-lakes-of-information-are-scientific-papers-the-news-or-the-encyclopedia/" title="Rivers vs lakes of information: are scientific papers “the news” or “the encyclopedia”?">not the case</a> (admittedly in a different field, but from my limited knowledge isn&#39;t social psychology more likely to be subject to systemic biases than fields where the research subject is not also a person?) Publication bias, the idea that positive results should be celebrated while negative ones are useless, has led to a host of problems across multiple fields, including incentivizing the fraud that Mitchell thinks is so rare.</p>

		</section>


	<hr />

	<footer class="main-content__footer">
		<p><strong>I am starting out as a freelance frontend developer and looking for projects.</strong> <a href="../contact.html">Contact me</a> and let's talk about what we can make together.</p>

		<h2>Share this post</h2>
		<div class="share-icons">
			<a href="https://facebook.com/sharer.php?url=https%3A%2F%2Fcaydenberg.io%2Fblog%2Fon-the-emptiness-of-failed-replications-the-best-parts" title="Share this page on Facebook">
				<span class="hidden"><i class="icon-facebook"></i></span>
			</a>
			<a href="https://twitter.com/share?text=On%20the%20emptiness%20of%20failed%20replications%3A%20the%20best%20parts&url=https%3A%2F%2Fcaydenberg.io%2Fblog%2Fon-the-emptiness-of-failed-replications-the-best-parts" title="Tweet this page">
				<span class="hidden"><i class="icon-twitter"></i></span>
			</a>
			<a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fcaydenberg.io%2Fblog%2Fon-the-emptiness-of-failed-replications-the-best-parts&mini=true&title=On%20the%20emptiness%20of%20failed%20replications%3A%20the%20best%20parts" title="Tweet this page">
				<span class="hidden"><i class="icon-linkedin"></i></span>
			</a>
		</div>

	</footer>

</article>

				</div>

			</div>
		</div>

		<script src="../main.js" defer></script>
	</body>
</html>
