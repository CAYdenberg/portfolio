{"_id":{"$oid":"57f30c8b1aaec2c30b5314ac"},"slug":"understanding-what-new-does-in-five-easy-steps","title":"Understanding what `new` does in five easy steps","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eThe \u003ccode\u003enew\u003c/code\u003e keyword, inheritance and object creation are some of the most confusing parts of the JavaScript language, and are equally befuddling both to newcomers and to programmers experienced with other languages.\u003c/p\u003e\n","md":"The `new` keyword, inheritance and object creation are some of the most confusing parts of the JavaScript language, and are equally befuddling both to newcomers and to programmers experienced with other languages."},"extended":{"html":"\u003cp\u003eThe \u003ccode\u003enew\u003c/code\u003e keyword, inheritance and object creation are some of the most confusing parts of the JavaScript language, and are equally befuddling both to newcomers and to programmers experienced with other languages. The reasons for this go way back to the design of the spec, and I won\u0026#39;t get into them.\u003c/p\u003e\n\u003cp\u003eI do not believe that being a coding newbie gives you some kind of advantage in understanding prototypes: rather, trying to grasp both prototypes and the way they have been hacked to produce pseudo-classical patterns \u003cstrong\u003eat the same time\u003c/strong\u003e can make newcomers especially bewildered. Moreover, when Googling around on the subject, one encounters a lot of opinion and a lot of \u003cstrong\u003edetail.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eDrawing mainly from \u003ca href=\"http://shop.oreilly.com/product/9780596517748.do\"\u003eJavaScript: The Good Parts\u003c/a\u003e and \u003ca href=\"http://shop.oreilly.com/product/0636920033738.do\"\u003eYDKJS\u003c/a\u003e, I think I have distilled the details on \u003ccode\u003enew\u003c/code\u003e down to five simple steps, which I really wish I\u0026#39;d had a firm grasp on when I was first starting out.\u003c/p\u003e\n\u003ch2 id=\"1-functions-are-objects\"\u003e1. Functions are objects\u003c/h2\u003e\n\u003cp\u003eThis one is pretty straightforward. In JavaScript, functions are objects (of type Function), which basically has the upshot that they can be assigned to variables and passed around like a bag of chips.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction hello() {\n    alert(\u0026#39;Hello\u0026#39;);\n}\n\nvar hello2 = hello;\n\nhello2();\n//alert box says \u0026quot;Hello\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNothing astounding there.\u003c/p\u003e\n\u003ch2 id=\"2-declaring-a-function-actually-creates-two-objects\"\u003e2. Declaring a function actually creates two objects\u003c/h2\u003e\n\u003cp\u003eWhen you declare a function, you are actually creating two objects: the function itself (\u003ccode\u003eMyFunction\u003c/code\u003e), and another \u0026quot;prototype\u0026quot; object (\u003ccode\u003eMyFunction.prototype\u003c/code\u003e). You can assign properties (which can be functions) to the prototype object (for that matter, you can also assign them to the function directly).\u003c/p\u003e\n\u003cp\u003eIn addition, the \u0026quot;prototype\u0026quot; refers back the original function through a property called the \u0026quot;constructor\u0026quot;. So \u003ccode\u003eMyFunction.prototype.constructor\u003c/code\u003e is \u003ccode\u003eMyFunction\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction MyFunction() {}\n\nMyFunction\n// MyFunction() {}\n\nMyFunction.prototype.constructor\n// MyFunction() {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eGot that? Shit\u0026#39;s about the get real.\u003c/p\u003e\n\u003ch2 id=\"3-__proto__-is-not-the-same-as-prototype-\"\u003e3. \u003ccode\u003e__proto__\u003c/code\u003e is not the same as \u003ccode\u003eprototype\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003eIn JavaScript, every object has a linked Prototype object. Any time a variable lookup (\u003ccode\u003emyObject.myProp\u003c/code\u003e) is performed on that object, \u003cem\u003eand the property does not exist\u003c/em\u003e, it will look for the property on the object\u0026#39;s prototype, then prototypes prototype, and so on.\u003c/p\u003e\n\u003cp\u003eHere\u0026#39;s the thing that\u0026#39;s messed up though: that \u003ccode\u003e.prototype\u003c/code\u003e we mentioned above \u003cem\u003eis not the function\u0026#39;s prototype.\u003c/em\u003e Chrome stores the \u003cem\u003eactual\u003c/em\u003e prototype in a different variable called \u003ccode\u003e__proto__\u003c/code\u003e. \u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction MyFunction() {}\n\nMyFunction.prototype\n// MyFunction() {}\n\nMyFunction.__proto__\n// function () {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eor even better\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003eMyFunction.prototype === MyFunction.__proto__\n// false\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNot the same thing at all. This also explains why we can\u0026#39;t access the \u003ccode\u003eprototype\u003c/code\u003e on arbitrary object, even though newbies are pounded over the head with the factoid that all JavaScript objects have prototypes.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003evar myObject = {}\n\nmyObject.prototype\n// undefined\n\nmyObject.__proto__\n// Object {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003eprototype\u003c/code\u003e is not the Prototype. It is best to think of it simply as a special object that is created when a function is created. Why is this useful?\u003c/p\u003e\n\u003ch2 id=\"4-new-changes-what-happens-when-you-execute-a-function\"\u003e4. \u003ccode\u003enew\u003c/code\u003e changes what happens when you execute a function\u003c/h2\u003e\n\u003cp\u003eSo far we\u0026#39;ve only discussed declaring functions, not executing them. Importantly, much of what happens during function execution in JavaScript depends on the \u003cem\u003eway\u003c/em\u003e the function is called, and is not set at declaration time at all. When a function is called with \u003ccode\u003enew\u003c/code\u003e (is in \u003ccode\u003evar myObject = new MyFunction()\u003c/code\u003e) the following things happen:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ea new object is created\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ethis\u003c/code\u003e within the function body is bound to the new object\u003c/li\u003e\n\u003cli\u003ethe new object\u0026#39;s \u003ccode\u003e__proto__\u003c/code\u003e (Prototype) is the \u003ccode\u003e.prototype\u003c/code\u003e of the function\u003c/li\u003e\n\u003cli\u003ethe function will return the new object unless there is an explicit \u003ccode\u003ereturn\u003c/code\u003e statement\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis allows you to invoke the familiar constructor pattern:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction Animal(sound) {\n    this.sound = sound;\n}\nAnimal.prototype.speak = function() {\n    console.log(this.sound); \n}\n\nvar cat = new Animal(\u0026quot;meow\u0026quot;);\ncat.speak();\n// meow\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis creates the appearance of classes in JavaScript, but it is an illusion. In the example above, \u003ccode\u003eAnimal\u003c/code\u003e and \u003ccode\u003ecat\u003c/code\u003e are both objects, they are not classes.\u003c/p\u003e\n\u003cp\u003eA final note on this point: \u003ca href=\"https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Classes\"\u003eES6 adds the \u003ccode\u003eclass\u003c/code\u003e keyword\u003c/a\u003e. However, it merely provides syntactic sugar for the pattern above: there still are not really classes in JavaScript.\u003c/p\u003e\n\u003ch2 id=\"5-object-create-does-one-thing\"\u003e5. \u003ccode\u003eObject.create\u003c/code\u003e does one thing\u003c/h2\u003e\n\u003cp\u003eUnlike \u003ccode\u003enew\u003c/code\u003e, \u003ccode\u003eObject.create\u003c/code\u003e does exactly one thing: it creates a new object with a prototype specified by the first parameter. This means we could rewrite the example above as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003evar Animal = {\n    speak: function() {\n        console.log(this.sound);\n    }\n}\n\nfunction createAnimal(sound) {\n    var animal = Object.create(Animal);\n    animal.sound = sound;\n    return animal;\n}\n\nvar cat = createAnimal(\u0026quot;meow\u0026quot;);\ncat.speak();\n// meow\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI find this type of code a little easier to read because the various elements in it more clearly declare their own intentions. \u003ca href=\"http://shop.oreilly.com/product/9780596517748.do\"\u003eDouglas Crockford\u003c/a\u003e, \u003ca href=\"https://github.com/getify/You-Dont-Know-JS/blob/master/this%20%26%20object%20prototypes/ch6.md\"\u003eKyle Simpson\u003c/a\u003e, and \u003ca href=\"https://medium.com/javascript-scene/common-misconceptions-about-inheritance-in-javascript-d5d9bab29b0a#.9160jmid5\"\u003eEric Elliot\u003c/a\u003e have in fact argued that the pseudo-classical pattern should be done away with altogether. Note that \u003ccode\u003eObject.create\u003c/code\u003e is used in the classical pattern to mimic \u0026quot;class inheritance\u0026quot; and so understanding how it works is important.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOne final point about prototypes:\u003c/strong\u003e Neither \u003ccode\u003eObject.create\u003c/code\u003e nor \u003ccode\u003enew\u003c/code\u003e make copies of objects. It often appears as though the prototype is copied because the prototype and the new object have access to the same properties. \u003cem\u003eBut those properties are actually the same things - not copies.\u003c/em\u003e This can lead to some surprising results when trying to implement \u0026quot;inheritance\u0026quot;. \u003ca href=\"http://shop.oreilly.com/product/0636920033738.do\"\u003eIt may be better to refer to inheritance as \u0026quot;delegation\u0026quot; instead.\u003c/a\u003e\u003c/p\u003e\n","md":"The `new` keyword, inheritance and object creation are some of the most confusing parts of the JavaScript language, and are equally befuddling both to newcomers and to programmers experienced with other languages. The reasons for this go way back to the design of the spec, and I won't get into them.\r\n\r\nI do not believe that being a coding newbie gives you some kind of advantage in understanding prototypes: rather, trying to grasp both prototypes and the way they have been hacked to produce pseudo-classical patterns **at the same time** can make newcomers especially bewildered. Moreover, when Googling around on the subject, one encounters a lot of opinion and a lot of **detail.**\r\n\r\nDrawing mainly from [JavaScript: The Good Parts](http://shop.oreilly.com/product/9780596517748.do) and [YDKJS](http://shop.oreilly.com/product/0636920033738.do), I think I have distilled the details on `new` down to five simple steps, which I really wish I'd had a firm grasp on when I was first starting out.\r\n\r\n## 1. Functions are objects\r\n\r\nThis one is pretty straightforward. In JavaScript, functions are objects (of type Function), which basically has the upshot that they can be assigned to variables and passed around like a bag of chips.\r\n\r\n```javascript\r\nfunction hello() {\r\n    alert('Hello');\r\n}\r\n\r\nvar hello2 = hello;\r\n\r\nhello2();\r\n//alert box says \"Hello\"\r\n```\r\n\r\nNothing astounding there.\r\n\r\n## 2. Declaring a function actually creates two objects\r\n\r\nWhen you declare a function, you are actually creating two objects: the function itself (`MyFunction`), and another \"prototype\" object (`MyFunction.prototype`). You can assign properties (which can be functions) to the prototype object (for that matter, you can also assign them to the function directly).\r\n\r\nIn addition, the \"prototype\" refers back the original function through a property called the \"constructor\". So `MyFunction.prototype.constructor` is `MyFunction`.\r\n\r\n```javascript\r\nfunction MyFunction() {}\r\n\r\nMyFunction\r\n// MyFunction() {}\r\n\r\nMyFunction.prototype.constructor\r\n// MyFunction() {}\r\n```\r\n\r\nGot that? Shit's about the get real.\r\n\r\n## 3. `__proto__` is not the same as `prototype`\r\n\r\nIn JavaScript, every object has a linked Prototype object. Any time a variable lookup (`myObject.myProp`) is performed on that object, *and the property does not exist*, it will look for the property on the object's prototype, then prototypes prototype, and so on.\r\n\r\nHere's the thing that's messed up though: that `.prototype` we mentioned above *is not the function's prototype.* Chrome stores the *actual* prototype in a different variable called `__proto__`. \r\n\r\n```javascript\r\nfunction MyFunction() {}\r\n\r\nMyFunction.prototype\r\n// MyFunction() {}\r\n\r\nMyFunction.__proto__\r\n// function () {}\r\n```\r\n\r\nor even better\r\n\r\n```javascript\r\nMyFunction.prototype === MyFunction.__proto__\r\n// false\r\n```\r\n\r\nNot the same thing at all. This also explains why we can't access the `prototype` on arbitrary object, even though newbies are pounded over the head with the factoid that all JavaScript objects have prototypes.\r\n\r\n```javascript\r\nvar myObject = {}\r\n\r\nmyObject.prototype\r\n// undefined\r\n\r\nmyObject.__proto__\r\n// Object {}\r\n```\r\n\r\nThe `prototype` is not the Prototype. It is best to think of it simply as a special object that is created when a function is created. Why is this useful?\r\n\r\n## 4. `new` changes what happens when you execute a function\r\n\r\nSo far we've only discussed declaring functions, not executing them. Importantly, much of what happens during function execution in JavaScript depends on the *way* the function is called, and is not set at declaration time at all. When a function is called with `new` (is in `var myObject = new MyFunction()`) the following things happen:\r\n\r\n- a new object is created\r\n- `this` within the function body is bound to the new object\r\n- the new object's `__proto__` (Prototype) is the `.prototype` of the function\r\n- the function will return the new object unless there is an explicit `return` statement\r\n\r\nThis allows you to invoke the familiar constructor pattern:\r\n\r\n```javascript\r\nfunction Animal(sound) {\r\n    this.sound = sound;\r\n}\r\nAnimal.prototype.speak = function() {\r\n    console.log(this.sound); \r\n}\r\n\r\nvar cat = new Animal(\"meow\");\r\ncat.speak();\r\n// meow\r\n```\r\n\r\nThis creates the appearance of classes in JavaScript, but it is an illusion. In the example above, `Animal` and `cat` are both objects, they are not classes.\r\n\r\nA final note on this point: [ES6 adds the `class` keyword](https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Classes). However, it merely provides syntactic sugar for the pattern above: there still are not really classes in JavaScript.\r\n\r\n## 5. `Object.create` does one thing\r\n\r\nUnlike `new`, `Object.create` does exactly one thing: it creates a new object with a prototype specified by the first parameter. This means we could rewrite the example above as follows:\r\n\r\n```javascript\r\nvar Animal = {\r\n    speak: function() {\r\n        console.log(this.sound);\r\n    }\r\n}\r\n\r\nfunction createAnimal(sound) {\r\n    var animal = Object.create(Animal);\r\n    animal.sound = sound;\r\n    return animal;\r\n}\r\n\r\nvar cat = createAnimal(\"meow\");\r\ncat.speak();\r\n// meow\r\n```\r\n\r\nI find this type of code a little easier to read because the various elements in it more clearly declare their own intentions. [Douglas Crockford](http://shop.oreilly.com/product/9780596517748.do), [Kyle Simpson](https://github.com/getify/You-Dont-Know-JS/blob/master/this%20%26%20object%20prototypes/ch6.md), and [Eric Elliot](https://medium.com/javascript-scene/common-misconceptions-about-inheritance-in-javascript-d5d9bab29b0a#.9160jmid5) have in fact argued that the pseudo-classical pattern should be done away with altogether. Note that `Object.create` is used in the classical pattern to mimic \"class inheritance\" and so understanding how it works is important.\r\n\r\n**One final point about prototypes:** Neither `Object.create` nor `new` make copies of objects. It often appears as though the prototype is copied because the prototype and the new object have access to the same properties. *But those properties are actually the same things - not copies.* This can lead to some surprising results when trying to implement \"inheritance\". [It may be better to refer to inheritance as \"delegation\" instead.](http://shop.oreilly.com/product/0636920033738.do)"}},"publishedDate":{"$date":"2016-05-07T06:00:00.000Z"}}
{"_id":{"$oid":"57f30cd51aaec2c30b5314ad"},"slug":"curriculum-vitae","title":"Curriculum Vitae","__t":"Page","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"extended":{"html":"\u003ch2 id=\"skills\"\u003eSkills\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages:\u003c/strong\u003e JavaScript, TypeScript, Python, PHP, HTML5 (templating languages, JSX), CSS3 (LESS, SASS)\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eMajor frameworks and libraries:\u003c/strong\u003e React/Redux, styled-components, Vue/Vuex, Express, Django, Flask, Numpy/Pandas/iPython, Laravel\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDatabase tools:\u003c/strong\u003e MySQL, MongoDB, CouchDB/PouchDB\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTools:\u003c/strong\u003e Git, NPM, Jest, Babel, Webpack, Storybook, Cypress, Docker\u003c/p\u003e\n\u003ch2 id=\"professional-experience\"\u003eProfessional Experience\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eFreelance web app developer\u003c/strong\u003e (2018-present) I work with clients to build web applications with complex in-browser user workflows. I specialize in working with scientific organizations developing scholarly writing apps or data visualizations.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eExamples:\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.manuscripts.io/\"\u003eManuscripts.io\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://mitoviewer.girihlet.com/\"\u003eMitochondrial genome viewer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://abbey.girihlet.com/\"\u003eSanger sequence viewer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eFrontend Developer, TruHome Inc.\u003c/strong\u003e (2017-2018) Wrote frontend code for a progressive web app used by realtors to manage SMS interactions with clients, search the multiple-listing service (MLS), and set up showings. I was involved in user-experience design and interacted with end-users on feature requests and bug reports. I also worked on an advanced search plugin used on dozens of real estate websites.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eExample:\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://www.soniatarabay.com/search\"\u003eGUS Real Estate Search\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eWeb Developer, Graphos Design Studios.\u003c/strong\u003e (2014-2017). Wrote frontend and backend code for responsive, CMS-enabled client websites. Was involved in all stages of projects from discovery and planning until deployment and maintenance. Gave input on UX, content, design and SEO. Trained clients in content-management systems, responded to bug reports and feedback.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eExamples:\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://www.t8nmagazine.com/\"\u003eT8N Magazine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.ascensionchiro.ca/\"\u003eAscension Chiropractic\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003ePostdoctoral Fellow, Brandeis University.\u003c/strong\u003e (2010-2014). Collected biological experimental data and analyzed with Python scripts. Presented in research publications and at conferences.\u003c/p\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003ePh.D., Princeton University\u003c/strong\u003e (2003-2009). Department of Molecular Biology.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eB.Sc. (First-class Honours), Simon Fraser University\u003c/strong\u003e (1999-2003). Department of Molecular Biology and Biochemistry.\u003c/p\u003e\n\u003ch2 id=\"open-source\"\u003eOpen Source\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eopenfeed\u003c/strong\u003e: I develop and maintain an open-source, offline-first JSONFeed aggregator\u003cbr /\u003e\n\u003ca href=\"https://openfeed.caydenberg.io\"\u003eMain site\u003c/a\u003e\u003cbr /\u003e\n\u003ca href=\"https://github.com/CAYdenberg/openfeed\"\u003eGitHub\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStylelint:\u003c/strong\u003e I was formerly a core contributor to the \u003ca href=\"https://stylelint.io/\"\u003estylelint\u003c/a\u003e project, used by Facebook, GitHub, Wikimedia, Bootstrap and WordPress. I both contributed and reviewed pull requests.\u003c/p\u003e\n\u003ch2 id=\"other-activities\"\u003eOther activities\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eI am organizer at Edmonton\u0026#39;s JavaScript meetup, and have \u003ca href=\"https://caydenberg.io/talks\"\u003egiven several presentations\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eI teach HTML, CSS, and JavaScript at Canada Learning Code.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","md":"## Skills ##\r\n\r\n**Languages:** JavaScript, TypeScript, Python, PHP, HTML5 (templating languages, JSX), CSS3 (LESS, SASS)\r\n\r\n**Major frameworks and libraries:** React/Redux, styled-components, Vue/Vuex, Express, Django, Flask, Numpy/Pandas/iPython, Laravel\r\n\r\n**Database tools:** MySQL, MongoDB, CouchDB/PouchDB\r\n\r\n**Tools:** Git, NPM, Jest, Babel, Webpack, Storybook, Cypress, Docker\r\n\r\n## Professional Experience ##\r\n\r\n**Freelance web app developer** (2018-present) I work with clients to build web applications with complex in-browser user workflows. I specialize in working with scientific organizations developing scholarly writing apps or data visualizations.\r\n\r\n*Examples:*\r\n* [Manuscripts.io](https://www.manuscripts.io/)\r\n* [Mitochondrial genome viewer](http://mitoviewer.girihlet.com/)\r\n* [Sanger sequence viewer](http://abbey.girihlet.com/)\r\n\r\n**Frontend Developer, TruHome Inc.** (2017-2018) Wrote frontend code for a progressive web app used by realtors to manage SMS interactions with clients, search the multiple-listing service (MLS), and set up showings. I was involved in user-experience design and interacted with end-users on feature requests and bug reports. I also worked on an advanced search plugin used on dozens of real estate websites.\r\n\r\n*Example:*\r\n\r\n* [GUS Real Estate Search](http://www.soniatarabay.com/search)\r\n\r\n**Web Developer, Graphos Design Studios.** (2014-2017). Wrote frontend and backend code for responsive, CMS-enabled client websites. Was involved in all stages of projects from discovery and planning until deployment and maintenance. Gave input on UX, content, design and SEO. Trained clients in content-management systems, responded to bug reports and feedback.\r\n\r\n*Examples:*\r\n\r\n* [T8N Magazine](http://www.t8nmagazine.com/)\r\n* [Ascension Chiropractic](http://www.ascensionchiro.ca/)\r\n\r\n**Postdoctoral Fellow, Brandeis University.** (2010-2014). Collected biological experimental data and analyzed with Python scripts. Presented in research publications and at conferences.\r\n\r\n## Education ##\r\n\r\n**Ph.D., Princeton University** (2003-2009). Department of Molecular Biology.\r\n\r\n**B.Sc. (First-class Honours), Simon Fraser University** (1999-2003). Department of Molecular Biology and Biochemistry.\r\n\r\n## Open Source ##\r\n\r\n**openfeed**: I develop and maintain an open-source, offline-first JSONFeed aggregator\u003cbr /\u003e\r\n[Main site](https://openfeed.caydenberg.io)\u003cbr /\u003e\r\n[GitHub](https://github.com/CAYdenberg/openfeed)\r\n\r\n**Stylelint:** I was formerly a core contributor to the [stylelint](https://stylelint.io/) project, used by Facebook, GitHub, Wikimedia, Bootstrap and WordPress. I both contributed and reviewed pull requests.\r\n\r\n## Other activities ##\r\n\r\n* I am organizer at Edmonton's JavaScript meetup, and have [given several presentations](https://caydenberg.io/talks).\r\n\r\n* I teach HTML, CSS, and JavaScript at Canada Learning Code."}},"publishedDate":{"$date":"2018-11-02T15:16:25.000Z"}}
{"_id":{"$oid":"5802e1cb31c9af6010bb4fbe"},"slug":"version-control-is-a-superpower","title":"Version control is a superpower","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eAs soon as I started to use Git I recognized that I would never look at a folder the same way again.\u003c/p\u003e\n","md":"As soon as I started to use Git I recognized that I would never look at a folder the same way again."},"extended":{"html":"\u003cp\u003eAs soon as I started to use Git I recognized that I would never look at a folder the same way again. I used to work on projects involving several authors, stored in a Dropbox repository, which typically contained dozens of Microsoft Word documents with date prefixes, and often an embarrassingly large number with the word \u0026quot;FINAL\u0026quot; somewhere in the file name. If someone else was working on a document you NEVER opened it. After learning that every change ever made in a software project can be undone, it should be natural to wonder why we don\u0026#39;t do everything this way.\u003c/p\u003e\n\u003cp\u003eBut the real power of Git lies not just in the ability to go back in time, but in it\u0026#39;s distributed nature. In the Git world-view, there is no \u0026quot;canonical\u0026quot; version of a project. Any project can be cloned, and both copies of the clone are \u0026quot;real\u0026quot;. There is tremendous power in this, for it is the power of descent with modification: the driving force of biological evolution. What has worked to select and amplify random mutations in biology must surely work for the purposeful modification of human coders.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dfxksdivn/image/upload/v1476824481/human-evolution_hobzs8.svg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eJust like in biology, good ideas that occur independently of each other need not exist apart from each other for ever. The process of bringing two different mutations that share a recent common ancestor back together in version control is called a \u0026quot;merge\u0026quot;. In biology it\u0026#39;s called \u0026quot;sex\u0026quot;.\u003c/p\u003e\n\u003cp\u003eIt would be a horrible thing if software developers were the only people who could do it.\u003c/p\u003e\n\u003cp\u003eStrictly speaking, version control has nothing to do with writing software. It could act on any document with a linear structure (so the diffing algorithm can find the beginning and the end of a change). This includes text documents, spreadsheets, presentations, and DNA sequences.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eI propose building Wiki-type software that works like a distributed version control system.\u003c/strong\u003e In this system any document could be forked, and both versions continue to exist. The author/editor of the cloned document can propose that their changes be merged back to the original, but they also have a new, real-live document with a real URL they can share. The system should be simple enough for non-coders to use: it should be limited to forks, merges and resets, with no need for the command line. There should be a simple rich-text editor for making changes.\u003c/p\u003e\n\u003cp\u003eI further propose that this system be extended to handle custom fields which are defined by a developer but used by non-developers. For example, a developer could define a \u0026quot;Recipe\u0026quot; data model, and use the system to build a recipe site where any user can fork any other user\u0026#39;s recipe, and then propose a merge back to the original (presumably explaining why the change improves it/makes it more delicious).\u003c/p\u003e\n\u003cp\u003eDistribution powers good ideas because mutations have more places they can happen. Merging brings good ideas together. This is true for biology and software, so it should be for recipes, encyclopaedias, travel guides, scientific papers, lectures, and textbooks.\u003c/p\u003e\n\u003chr /\u003e\n\n\u003cp\u003eI have been working on an implementation of this idea which I call \u0026quot;Wikode\u0026quot;. There isn\u0026#39;t a working production copy of it anywhere yet, but the \u003ca href=\"https://github.com/CAYdenberg/wikode/\"\u003ecode is on GitHub\u003c/a\u003e and you can download and play with (such as it is).\u003c/p\u003e\n","md":"As soon as I started to use Git I recognized that I would never look at a folder the same way again. I used to work on projects involving several authors, stored in a Dropbox repository, which typically contained dozens of Microsoft Word documents with date prefixes, and often an embarrassingly large number with the word \"FINAL\" somewhere in the file name. If someone else was working on a document you NEVER opened it. After learning that every change ever made in a software project can be undone, it should be natural to wonder why we don't do everything this way.\r\n\r\nBut the real power of Git lies not just in the ability to go back in time, but in it's distributed nature. In the Git world-view, there is no \"canonical\" version of a project. Any project can be cloned, and both copies of the clone are \"real\". There is tremendous power in this, for it is the power of descent with modification: the driving force of biological evolution. What has worked to select and amplify random mutations in biology must surely work for the purposeful modification of human coders.\r\n\r\n![](http://res.cloudinary.com/dfxksdivn/image/upload/v1476824481/human-evolution_hobzs8.svg)\r\n\r\nJust like in biology, good ideas that occur independently of each other need not exist apart from each other for ever. The process of bringing two different mutations that share a recent common ancestor back together in version control is called a \"merge\". In biology it's called \"sex\".\r\n\r\nIt would be a horrible thing if software developers were the only people who could do it.\r\n\r\nStrictly speaking, version control has nothing to do with writing software. It could act on any document with a linear structure (so the diffing algorithm can find the beginning and the end of a change). This includes text documents, spreadsheets, presentations, and DNA sequences.\r\n\r\n**I propose building Wiki-type software that works like a distributed version control system.** In this system any document could be forked, and both versions continue to exist. The author/editor of the cloned document can propose that their changes be merged back to the original, but they also have a new, real-live document with a real URL they can share. The system should be simple enough for non-coders to use: it should be limited to forks, merges and resets, with no need for the command line. There should be a simple rich-text editor for making changes.\r\n\r\nI further propose that this system be extended to handle custom fields which are defined by a developer but used by non-developers. For example, a developer could define a \"Recipe\" data model, and use the system to build a recipe site where any user can fork any other user's recipe, and then propose a merge back to the original (presumably explaining why the change improves it/makes it more delicious).\r\n\r\nDistribution powers good ideas because mutations have more places they can happen. Merging brings good ideas together. This is true for biology and software, so it should be for recipes, encyclopaedias, travel guides, scientific papers, lectures, and textbooks.\r\n\r\n\u003chr /\u003e\r\n\r\nI have been working on an implementation of this idea which I call \"Wikode\". There isn't a working production copy of it anywhere yet, but the [code is on GitHub](https://github.com/CAYdenberg/wikode/) and you can download and play with (such as it is)."}},"publishedDate":{"$date":"2016-09-25T06:00:00.000Z"}}
{"_id":{"$oid":"5802e25831c9af6010bb4fbf"},"slug":"three-mundane-things-you-can-do-with-recursion","title":"Three mundane things you can do with recursion","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI have been spending some quality time with \u003ca href=\"http://www.braveclojure.com/\"\u003eClojure\u003c/a\u003e, not because I think I\u0026#39;m likely to use it for a real project any time soon, but because both the syntax and behaviour of the language are so different from what I\u0026#39;m used to that I feel like a total n00b again. This is uncomfortable, but it\u0026#39;s a good thing: I\u0026#39;m looking at my even my production code in a whole new way.\u003c/p\u003e\n","md":"I have been spending some quality time with [Clojure](http://www.braveclojure.com/), not because I think I'm likely to use it for a real project any time soon, but because both the syntax and behaviour of the language are so different from what I'm used to that I feel like a total n00b again. This is uncomfortable, but it's a good thing: I'm looking at my even my production code in a whole new way."},"extended":{"html":"\u003cp\u003eI have been spending some quality time with \u003ca href=\"http://www.braveclojure.com/\"\u003eClojure\u003c/a\u003e, not because I think I\u0026#39;m likely to use it for a real project any time soon, but because both the syntax and behaviour of the language are so different from what I\u0026#39;m used to that I feel like a total n00b again. This is uncomfortable, but it\u0026#39;s a good thing: I\u0026#39;m looking at my even my production code in a whole new way.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRecursion\u003c/strong\u003e is a tricky concept, but it\u0026#39;s so ubiquitous in Clojure that you have to get used to it really, really fast. Clojure does not have formal loop structures, and people who are used to functional languages in fact argue that loops are really a \u003ca href=\"http://clojure.org/about/functional_programming\"\u003etacky add-on to imperative languages\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWhile recursion often feels like it\u0026#39;s performing some sort of magic (see \u003ca href=\"https://en.wikipedia.org/wiki/Merge_sort\"\u003emerge sort\u003c/a\u003e, or any algorithm that walks through tree-like data) it can also have some mundane uses. Sometime practising with the mundane is more illustrative.\u003c/p\u003e\n\u003cp\u003eThis post is intended for those who have some experience with programming but who are unfamiliar or somewhat familiar with recursion. It is mostly conceptual but will include some example in JavaScript. I will also include one example in Clojure as it was the place I got started in thinking about all this. Strict familiarity with either language is not a requirement.\u003c/p\u003e\n\u003ch2 id=\"1-basic-looping\"\u003e1. Basic looping\u003c/h2\u003e\n\u003cp\u003eOne personal \u003ca href=\"http://codekata.com/\"\u003ekata\u003c/a\u003e of mine is writing a function that prints out the Fibonacci series. Here\u0026#39;s how it works:\u003c/p\u003e\n\u003cp\u003eThe first two numbers in the series are 1 and 1. After that, each number is the sum of the two numbers that came before it. So the third Fibonacci number is 2 (1 + 1), then 3 (1 + 2), then 5 (2 + 3) and we get:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e1, 1, 2, 3, 5, 8, 13, 21\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eand so on.\u003c/p\u003e\n\u003cp\u003eThe Fibonacci series is the basis of such diverse concepts as the \u003ca href=\"https://en.wikipedia.org/wiki/Golden_ratio\"\u003egolden mean\u003c/a\u003e and the rhythmic structure of \u003ca href=\"https://www.fibonicci.com/fibonacci/tool-lateralus/\"\u003eprogressive metal band \u003cem\u003eTool\u003c/em\u003e\u0026#39;s masterpiece \u0026quot;Lateralus\u0026quot;\u003c/a\u003e. It\u0026#39;s simple enough to code with a loop, but in Clojure, we can\u0026#39;t use a loop. Here\u0026#39;s what I came up with:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-clojure\"\u003e(defn fibonacci\n    ([max sofar]\n        (def nextnum (+ (first (rseq sofar)) (second (rseq sofar))))\n        (if (\u0026lt; nextnum max)\n            (fibonacci max (conj sofar nextnum))\n                sofar))\n        ([max]\n                (fibonacci max [1, 1])))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe same thing in JavaScript:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction makeFibonacci(soFar) {\n    var next;\n    if (!soFar || soFar.length \u0026lt; 2) {\n        soFar = [1, 1];\n    }\n    next = soFar[soFar.length - 2] + soFar[soFar.length - 1];\n    if (next \u0026gt; 1000) {\n        return soFar;\n    } else {\n        soFar.push(next);\n        return makeFibonacci(soFar);\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn both cases, we\u0026#39;re starting by defining a default (1, 1) in case that hasn\u0026#39;t been done yet. We generate the next number in the series by adding the last two, then pop it on the end of the array. Then we recur (\u003ccode\u003erecur\u003c/code\u003e in Clojure and calling the function itself in JavaScript) and continue the cycle.\u003c/p\u003e\n\u003cp\u003eOne final, really important point: we have an exit strategy. Once the next number is over 1000, we cop out. The real Fibonacci series continues forever, but of course we can\u0026#39;t do this in a computer program. Unlike an ordinary loop, however, a recursive loop has to keep track of all of the whole list of calling functions (the call stack), and will eventually just run out of memory. This is the dreaded \u0026quot;stack overflow\u0026quot; error.\u003c/p\u003e\n\u003ch2 id=\"looping-through-a-list\"\u003eLooping through a list\u003c/h2\u003e\n\u003cp\u003eLibraries such as Underscore.js contain powerful methods that allow you to transform arrays and objects according to arbitrary functions. Suppose you have an array of numbers, and you want a new array containing the square of each one. You could do this with a loop, but this is prone to errors-of-one and mushes the looping logic together with the transforming logic. An alternative is to use Underscore\u0026#39;s \u003ccode\u003e.map\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003e_.map([1, 2, 3, 4], function(item) {\n    return item * item;\n});\n// returns [1, 4, 9, 16]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile the actual Underscore function just uses a loop, let\u0026#39;s implement our own version of using recursion.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction myArrayMap(inputArray, f) {\n    var outputArray = [];\n    function recur(inputArray) {\n        if (inputArray.length === 0) {\n            return outputArray;\n        }\n        var head = inputArray[0];\n        var tail = inputArray.slice(1);\n        outputArray.push(f(head));\n        return recur(tail);\n    }\n    return recur(inputArray);\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis shows a useful pattern: wrapping the recurring function in an outer function which sets standard arguments and defines the things the recurring function will need. \u003c/p\u003e\n\u003cp\u003eIgnoring the first \u003ccode\u003eif\u003c/code\u003e block for now, the inner recurring function splits the input array into a head (one item) and a tail (the rest) and performs the user-defined function \u003ccode\u003ef\u003c/code\u003e on the head. It pushes the new value onto the output array, then calls itself with the tail (now one item shorter than the input array). As before, there is a bottom-out point: when the input array is empty (zero items in length) we just return the output array.\u003c/p\u003e\n\u003ch2 id=\"setting-default-arguments\"\u003eSetting default arguments\u003c/h2\u003e\n\u003cp\u003eSuppose you are creating a function to initialize a jQuery carousel on the element of your choice. You can pass a selector string as an argument, or you can call the function without arguments and will use the default \u003ccode\u003e.carousel\u003c/code\u003e selector. There are a number of ways to set a default argument, but one that isn\u0026#39;t obvious is the simply call the function itself with the default argument in place.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction initCarousel(selector) {\n    if (!selector) {\n        initCarousel(\u0026#39;.carousel\u0026#39;);\n    }\n    $(selector).carousel();\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis pattern is especially mundane and not common in JavaScript, but one place something similar \u003cem\u003eis\u003c/em\u003e done is in ensuring that constructor functions are called correctly. In JavaScript, calling a function that is intended to be used as a constructor without \u003ccode\u003enew\u003c/code\u003e does not cause a fatal error, but can cause really confusing and unexpected results. This can be guarded against like so:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction MyConstructor(args) {\n    if (!(this instanceof MyConstructor)) {\n         return new MyConstructor(args);\n    }\n    // create object here\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf we ever forget to call \u003ccode\u003eMyConstructor\u003c/code\u003e with \u003ccode\u003enew\u003c/code\u003e (setting \u003ccode\u003ethis\u003c/code\u003e to the function that is currently executing), the function will simply check itself and fix our mistake. Pretty neat!\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eRecursion is usually trotted out a solution to complicated problems, but there are also simple cases where it can be useful. I hope this tutorial has let you see it in a new way!\u003c/p\u003e\n","md":"I have been spending some quality time with [Clojure](http://www.braveclojure.com/), not because I think I'm likely to use it for a real project any time soon, but because both the syntax and behaviour of the language are so different from what I'm used to that I feel like a total n00b again. This is uncomfortable, but it's a good thing: I'm looking at my even my production code in a whole new way.\r\n\r\n**Recursion** is a tricky concept, but it's so ubiquitous in Clojure that you have to get used to it really, really fast. Clojure does not have formal loop structures, and people who are used to functional languages in fact argue that loops are really a [tacky add-on to imperative languages](http://clojure.org/about/functional_programming).\r\n\r\nWhile recursion often feels like it's performing some sort of magic (see [merge sort](https://en.wikipedia.org/wiki/Merge_sort), or any algorithm that walks through tree-like data) it can also have some mundane uses. Sometime practising with the mundane is more illustrative.\r\n\r\nThis post is intended for those who have some experience with programming but who are unfamiliar or somewhat familiar with recursion. It is mostly conceptual but will include some example in JavaScript. I will also include one example in Clojure as it was the place I got started in thinking about all this. Strict familiarity with either language is not a requirement.\r\n\r\n## 1. Basic looping\r\n\r\nOne personal [kata](http://codekata.com/) of mine is writing a function that prints out the Fibonacci series. Here's how it works:\r\n\r\nThe first two numbers in the series are 1 and 1. After that, each number is the sum of the two numbers that came before it. So the third Fibonacci number is 2 (1 + 1), then 3 (1 + 2), then 5 (2 + 3) and we get:\r\n\r\n`1, 1, 2, 3, 5, 8, 13, 21`\r\n\r\nand so on.\r\n\r\nThe Fibonacci series is the basis of such diverse concepts as the [golden mean](https://en.wikipedia.org/wiki/Golden_ratio) and the rhythmic structure of [progressive metal band *Tool*'s masterpiece \"Lateralus\"](https://www.fibonicci.com/fibonacci/tool-lateralus/). It's simple enough to code with a loop, but in Clojure, we can't use a loop. Here's what I came up with:\r\n\r\n```clojure\r\n(defn fibonacci\r\n    ([max sofar]\r\n        (def nextnum (+ (first (rseq sofar)) (second (rseq sofar))))\r\n        (if (\u003c nextnum max)\r\n            (fibonacci max (conj sofar nextnum))\r\n                sofar))\r\n        ([max]\r\n                (fibonacci max [1, 1])))\r\n```\r\n\r\nThe same thing in JavaScript:\r\n\r\n```javascript\r\nfunction makeFibonacci(soFar) {\r\n    var next;\r\n    if (!soFar || soFar.length \u003c 2) {\r\n        soFar = [1, 1];\r\n    }\r\n    next = soFar[soFar.length - 2] + soFar[soFar.length - 1];\r\n    if (next \u003e 1000) {\r\n        return soFar;\r\n    } else {\r\n        soFar.push(next);\r\n        return makeFibonacci(soFar);\r\n    }\r\n}\r\n```\r\n\r\nIn both cases, we're starting by defining a default (1, 1) in case that hasn't been done yet. We generate the next number in the series by adding the last two, then pop it on the end of the array. Then we recur (`recur` in Clojure and calling the function itself in JavaScript) and continue the cycle.\r\n\r\nOne final, really important point: we have an exit strategy. Once the next number is over 1000, we cop out. The real Fibonacci series continues forever, but of course we can't do this in a computer program. Unlike an ordinary loop, however, a recursive loop has to keep track of all of the whole list of calling functions (the call stack), and will eventually just run out of memory. This is the dreaded \"stack overflow\" error.\r\n\r\n## Looping through a list\r\n\r\nLibraries such as Underscore.js contain powerful methods that allow you to transform arrays and objects according to arbitrary functions. Suppose you have an array of numbers, and you want a new array containing the square of each one. You could do this with a loop, but this is prone to errors-of-one and mushes the looping logic together with the transforming logic. An alternative is to use Underscore's `.map`:\r\n\r\n```javascript\r\n_.map([1, 2, 3, 4], function(item) {\r\n    return item * item;\r\n});\r\n// returns [1, 4, 9, 16]\r\n```\r\n\r\nWhile the actual Underscore function just uses a loop, let's implement our own version of using recursion.\r\n\r\n```javascript\r\nfunction myArrayMap(inputArray, f) {\r\n    var outputArray = [];\r\n    function recur(inputArray) {\r\n        if (inputArray.length === 0) {\r\n            return outputArray;\r\n        }\r\n        var head = inputArray[0];\r\n        var tail = inputArray.slice(1);\r\n        outputArray.push(f(head));\r\n        return recur(tail);\r\n    }\r\n    return recur(inputArray);\r\n}\r\n```\r\n\r\nThis shows a useful pattern: wrapping the recurring function in an outer function which sets standard arguments and defines the things the recurring function will need. \r\n\r\nIgnoring the first `if` block for now, the inner recurring function splits the input array into a head (one item) and a tail (the rest) and performs the user-defined function `f` on the head. It pushes the new value onto the output array, then calls itself with the tail (now one item shorter than the input array). As before, there is a bottom-out point: when the input array is empty (zero items in length) we just return the output array.\r\n\r\n## Setting default arguments\r\n\r\nSuppose you are creating a function to initialize a jQuery carousel on the element of your choice. You can pass a selector string as an argument, or you can call the function without arguments and will use the default `.carousel` selector. There are a number of ways to set a default argument, but one that isn't obvious is the simply call the function itself with the default argument in place.\r\n\r\n```javascript\r\nfunction initCarousel(selector) {\r\n    if (!selector) {\r\n        initCarousel('.carousel');\r\n    }\r\n    $(selector).carousel();\r\n}\r\n```\r\n\r\nThis pattern is especially mundane and not common in JavaScript, but one place something similar *is* done is in ensuring that constructor functions are called correctly. In JavaScript, calling a function that is intended to be used as a constructor without `new` does not cause a fatal error, but can cause really confusing and unexpected results. This can be guarded against like so:\r\n\r\n```javascript\r\nfunction MyConstructor(args) {\r\n    if (!(this instanceof MyConstructor)) {\r\n         return new MyConstructor(args);\r\n    }\r\n    // create object here\r\n}\r\n```\r\n\r\nIf we ever forget to call `MyConstructor` with `new` (setting `this` to the function that is currently executing), the function will simply check itself and fix our mistake. Pretty neat!\r\n\r\n## Conclusion\r\n\r\nRecursion is usually trotted out a solution to complicated problems, but there are also simple cases where it can be useful. I hope this tutorial has let you see it in a new way!"}},"publishedDate":{"$date":"2016-04-16T06:00:00.000Z"}}
{"_id":{"$oid":"5802e71a31c9af6010bb4fc0"},"slug":"diy-lazy-load","title":"DIY Lazy Load","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI am constantly looking for practical ways to get all the beautiful images in a design to load without hampering the page load unreasonably.\u003c/p\u003e\n","md":"I am constantly looking for practical ways to get all the beautiful images in a design to load without hampering the page load unreasonably."},"extended":{"html":"\u003cp\u003eI am constantly looking for practical ways to get all the beautiful images in a design to load without hampering the page load unreasonably. While \u003ca href=\"http://www.sitepoint.com/responsive-images-part-1-using-srcset/\"\u003eresponsive images\u003c/a\u003e have been the biggest help, occasionally something else is called for.\u003c/p\u003e\n\u003cp\u003eFor example, the content of carousel slides that are initially invisible can be deferred until the rest of the page has loaded, and the carousel can be started manually only once all the images are obtained. This lets the page load fast, and defers requests for images that aren\u0026#39;t visible anyway. The user\u0026#39;s experience is \u0026quot;enhanced\u0026quot; by starting the carousel once all the required content has been obtained.\u003c/p\u003e\n\u003cp\u003eHow to implement this? While there are several lazy loading plugins available, most of them are based on scrolling which doesn\u0026#39;t match our use case. What I came up with was the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003e\n(function($) {\n  $.fn.deferImageLoading = function(callback) {\n    var group = this;\n    var count = this.length;\n\n    return this.each(function() {\n      var $img = $(this);\n      $(window).load(function() {\n        $img.attr(\u0026#39;src\u0026#39;, $img.data(\u0026#39;src\u0026#39;)).load(function() {\n          count--;\n          if (!count \u0026amp;\u0026amp; $.isFunction(callback)) {\n              callback.call(group);\n          }\n        });\n      });\n    });\n\n  };\n}(jQuery));\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis JQuery method will take every selected element, and \u003cem\u003eafter the page has fully loaded\u003c/em\u003e, replace the src attribute with the data-src attribute, effectively spurring image loading or replacing a low-resolution image with a high-resolution one.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-html\"\u003e\u0026lt;img src=\u0026quot;#\u0026quot; data-src=\u0026quot;high-res.png\u0026quot; class=\u0026quot;defer\u0026quot; /\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003e$(\u0026#39;.defer\u0026#39;).deferImageLoading(function() {\n  // start the carousel (or whatever)\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo enhance this even further, all the controls to access deferred images can be hidden until the callback is called.\u003c/p\u003e\n","md":"I am constantly looking for practical ways to get all the beautiful images in a design to load without hampering the page load unreasonably. While [responsive images](http://www.sitepoint.com/responsive-images-part-1-using-srcset/) have been the biggest help, occasionally something else is called for.\r\n\r\nFor example, the content of carousel slides that are initially invisible can be deferred until the rest of the page has loaded, and the carousel can be started manually only once all the images are obtained. This lets the page load fast, and defers requests for images that aren't visible anyway. The user's experience is \"enhanced\" by starting the carousel once all the required content has been obtained.\r\n\r\nHow to implement this? While there are several lazy loading plugins available, most of them are based on scrolling which doesn't match our use case. What I came up with was the following:\r\n\r\n```javascript\r\n\r\n(function($) {\r\n  $.fn.deferImageLoading = function(callback) {\r\n    var group = this;\r\n    var count = this.length;\r\n\r\n    return this.each(function() {\r\n      var $img = $(this);\r\n      $(window).load(function() {\r\n        $img.attr('src', $img.data('src')).load(function() {\r\n          count--;\r\n          if (!count \u0026\u0026 $.isFunction(callback)) {\r\n              callback.call(group);\r\n          }\r\n        });\r\n      });\r\n    });\r\n\r\n  };\r\n}(jQuery));\r\n```\r\n\r\nThis JQuery method will take every selected element, and *after the page has fully loaded*, replace the src attribute with the data-src attribute, effectively spurring image loading or replacing a low-resolution image with a high-resolution one.\r\n\r\n```html\r\n\u003cimg src=\"#\" data-src=\"high-res.png\" class=\"defer\" /\u003e\r\n```\r\n\r\n```javascript\r\n$('.defer').deferImageLoading(function() {\r\n  // start the carousel (or whatever)\r\n});\r\n```\r\n\r\nTo enhance this even further, all the controls to access deferred images can be hidden until the callback is called."}},"publishedDate":{"$date":"2016-03-22T06:00:00.000Z"}}
{"_id":{"$oid":"5802e7e031c9af6010bb4fc1"},"slug":"how-to-keep-your-promises-javascript-edition","title":"How to keep your promises: JavaScript edition","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eThe first time I needed to access a third-party API on the web I remember doing something like the following (in PHP):\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-php\"\u003e$data = file_get_contents(\u0026#39;http://a/resource/somewhere\u0026#39;);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis has the advantage of being really easy to read: like all other parts of my code, I assign a variable to an expression and expect that it will be filled with a value of some sort. What I never thought about at the time was how much was going on behind the scenes: unlike an basic expression that performs a math operation or comparison, a whole HTTP request and response is going on before \u003ccode\u003e$data\u003c/code\u003e can be filled. During this time, my program pauses and no further code is executed.\u003c/p\u003e\n","md":"The first time I needed to access a third-party API on the web I remember doing something like the following (in PHP):\r\n\r\n```php\r\n$data = file_get_contents('http://a/resource/somewhere');\r\n```\r\n\r\nThis has the advantage of being really easy to read: like all other parts of my code, I assign a variable to an expression and expect that it will be filled with a value of some sort. What I never thought about at the time was how much was going on behind the scenes: unlike an basic expression that performs a math operation or comparison, a whole HTTP request and response is going on before `$data` can be filled. During this time, my program pauses and no further code is executed."},"extended":{"html":"\u003cp\u003eThe first time I needed to access a third-party API on the web I remember doing something like the following (in PHP):\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-php\"\u003e$data = file_get_contents(\u0026#39;http://a/resource/somewhere\u0026#39;);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis has the advantage of being really easy to read: like all other parts of my code, I assign a variable to an expression and expect that it will be filled with a value of some sort. What I never thought about at the time was how much was going on behind the scenes: unlike an basic expression that performs a math operation or comparison, a whole HTTP request and response is going on before \u003ccode\u003e$data\u003c/code\u003e can be filled. During this time, my program pauses and no further code is executed.\u003c/p\u003e\n\u003cp\u003eEnter JavaScript. In a browser, this same operation would be unacceptable: retrieving a resource through AJAX would mean no code can be executed until the response arrives, meaning the the user interface would be  for all intents a purposes frozen. On a Node.js server (which is single-threaded), no new client requests would be processed.\u003c/p\u003e\n\u003cp\u003eInstead, in JavaScript, the equivalent function would accept an additional argument which is the \u003cstrong\u003ecallback function\u003c/strong\u003e, which would execute when the response from the third-party is received. It does not return a value at all. This asynchronous execution has the advantage that slow operation like HTTP requests don\u0026#39;t tie up the processor, but they have the disadvantage that they can quickly get out of hand, as we will see.\u003c/p\u003e\n\u003cp\u003eIn a second pattern, the function does return a value, but it is not the HTTP response itself. Rather, it is an object which can be thought of as a representation of an unknown value. This object is called a promise. A promise has methods called handlers that describe what to do when the promise is either fulfilled or rejected.\u003c/p\u003e\n\u003cp\u003eThis post is not meant to be an exhaustive treatment of promises, but merely an introduction to why I have found them useful. It is intended for those who know some JavaScript but are not experts at writing asynchronous code.\u003c/p\u003e\n\u003cp\u003eI will deal exclusively with the ES6 (Promise/A+) variety. Since they are formally \u003ca href=\"http://caniuse.com/#search=promise\"\u003epart of ES6\u003c/a\u003e, you may need \u003ca href=\"https://github.com/stefanpenner/es6-promise#readme\"\u003ea polyfill\u003c/a\u003e for older browsers. They are standard current version of Nodejs, however.\u003c/p\u003e\n\u003ch2 id=\"examples-wrapping-callbacks-in-a-promise\"\u003eExamples: Wrapping Callbacks in a Promise\u003c/h2\u003e\n\u003cp\u003eLet\u0026#39;s look at perhaps the simplest example of a function that executes an asynchronous callback: \u003ccode\u003esetTimeout\u003c/code\u003e. This function accepts two parameters: a callback to execute when a time interval completes, and a number representing a length of time in milliseconds. So\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003esetTimeout(function() {\n    console.log(\u0026#39;Some time later ...\u0026#39;);\n}, 1000);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003egets the point across.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s wrap write a new function so that we can use a promise to execute a timed event. We\u0026#39;ll call it \u003ccode\u003ewait\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction wait(time) {\n    return new Promise(function(resolve, reject) {\n        setTimeout(function() {\n            resolve(\u0026#39;You kept your Promise!\u0026#39;);\n        }, time);\n    });\n}\n\nwait(1000).then(function(msg) {\n   console.log(msg)\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe key is \u003ccode\u003ereturn new Promise\u003c/code\u003e. To this you pass a function with two parameters: one is function to resolve (fulfil) the promise and the other is function to reject the promise (the reject function is not used in the example above, because there\u0026#39;s really no way for setTimeout to go wrong, but we\u0026#39;ll see more example below that use it). Whatever values are passed to resolve and reject will later be passed to the handlers.\u003c/p\u003e\n\u003cp\u003eNote that we can\u0026#39;t do this for \u003ccode\u003esetInterval\u003c/code\u003e, which executes a recurring event. A promise can be resolved or rejected: after that, it\u0026#39;s gone.\u003c/p\u003e\n\u003cp\u003eThis example is pretty trivial. First of all, there\u0026#39;s no real unknown value that we need the promise to keep track of for us and secondly, there\u0026#39;s virtually no possibility of this promise being rejected.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s look instead at Node\u0026#39;s \u003ccode\u003ehttp.get\u003c/code\u003e, which is basically the equivalent of PHP \u003ccode\u003efile_get_contents\u003c/code\u003e mentioned above.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003ehttp.get(\u0026#39;http://a/resource/somewhere/\u0026#39;, function(response) {\n   // deal with response\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLet\u0026#39;s create a smarter promise:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction requestResource(url) {\n    return new Promise(function(resolve, reject) {\n        http.get(address, function(response) {\n            if (response.status === 200) {\n                 return resolve(response.body);\n            else {\n                 return reject(\u0026#39;Response not OK\u0026#39;);\n            }\n        });\n    });\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe\u0026#39;ve already made our lives easier when we need to handle the promise. For one thing, we are only passing the response body, which might be all we\u0026#39;re going care about later. Secondly, we are rejecting the promise if the status code is not 200 (IRL we\u0026#39;d probably want to a better job and resolve some other codes, but that\u0026#39;s a story for later). We can handle a rejection with the \u003ccode\u003e.catch\u003c/code\u003e method, which works just like \u003ccode\u003e.then\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s use the \u003ca href=\"https://developer.forecast.io/docs/v2\"\u003eDark Sky weather API\u003c/a\u003e to get the current ski conditions\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003erequestResource(\u0026#39;https://api.forecast.io/forecast/APIKEY/50.1149639,-122.9486474\u0026#39;).then(function(res) {   \n    console.log(\u0026#39;The current temperature is \u0026#39; + res.body.currently.temperature);\n}).catch(function(err) {\n    console.log(err)\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNote: you\u0026#39;ll have to use a real API key to make this work. The code will print out the current temperature in Whistler, BC, Canada.\u003c/p\u003e\n\u003ch2 id=\"why-would-you-want-to-do-this-\"\u003eWhy would you want to do this?\u003c/h2\u003e\n\u003cp\u003eAll well and good, but so far, our promises have required us to write a fair bit of code to achieve pretty simple results. Why would you want to use them?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAvoid excessive nesting.\u003c/strong\u003e The most oft-cited advantage of promises is that they avoid the infinitely-nested callbacks that are so common in Node.js programming. In a web server-type application, the callback to respond to an HTTP request itself often contains a callback to query a database:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003erouter.get(\u0026#39;/my-page\u0026#39;, function(req, res) {\n    getSomeDataFromDb(req.someParameter, function(data) {\n        doSomething(data);\n        res.json(data);\n    }\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is two indentations deep before we even get to the meat, and it only involves one database query and no extra processing. On the other hand, we can chain promises to keep each step at the same lexical level as the step before it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003emyPromise.then(function(data) {\n   return doSomething(data);\n}).then(function(newData) {\n    return doSomethingElse(newData) {\n}).then(function(newNewData) {\n    return doSomethingElseElse(newNewData);\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou get the idea. At each step, the return value is the parameter passed to the next .then\u0026#39;s callback.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReturning Promises.\u003c/strong\u003e Even more useful than chaining promises in the same function is returning a promise and doing further processing in some other part of your code. The promise is an object that can be passed between functions. This helps keep functions simple and logical. We have already seen the pattern of returning a promise above. Since the handler (\u003ccode\u003e.then\u003c/code\u003e) also returns a promise, we can tack on more handlers in each function the promise is passed to.\u003c/p\u003e\n\u003cp\u003eCallbacks cannot be chained. A function that executes a callback that it does not itself define must accept that callback as an argument.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction stepOne(callback) {\n    stepTwo(callback);\n}\n\nfunction stepTwo(callback) {    \n    setTimeout(callback, 1000);\n}\n\nstepOne(function() {\n    console.log(\u0026#39;I got there ... eventually\u0026#39;);\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eEasier to keep track of multiple asynchronous events.\u003c/strong\u003e I have found that when \u003cem\u003emultiple\u003c/em\u003e asynchronous events are involved, Promises have a few advantages. First of all, thanks to JavaScript\u0026#39;s scoping rules, the \u003ccode\u003eresolve\u003c/code\u003e and \u003ccode\u003ereject\u003c/code\u003e methods can be more than one level deep when they are executed. Imagine you need to make two database queries, and the second is dependent on the data returned by the first:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction queryDb(params) {\n    return new Promise(resolve, reject) {\n        getDataFromDb(params, function(data) {\n            getMoreDataFromDb(data, function(moreData) {\n                resolve(moreData);\n            });\n         });\n    });\n}\n\nqueryDb.then( ... )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe\u0026#39;ve taken something pretty hairy and wrapped it a function which lets you not worry about the details too much when you use it later.\u003c/p\u003e\n\u003cp\u003eAnother common pattern is returning promises in a \u003ccode\u003ethen\u003c/code\u003e handler:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003emyPromise.then(function(dataOne) {\n    // process dataOne and create another promise\n    return myOtherPromise;\n}).then(function(dataTwo) {\n    // do something with dataTwo\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSomewhat surprisingly (but very usefully), \u003ccode\u003edataTwo\u003c/code\u003e is \u003cem\u003eNOT\u003c/em\u003e \u003ccode\u003emyOtherPromise\u003c/code\u003e itself, but rather the value that \u003ccode\u003emyOtherPromise\u003c/code\u003e resolves to. This lets us be a little bit dumb about creating promises within handlers, secure in the knowledge that the next handler won\u0026#39;t be invoked until the value we care about it known.\u003c/p\u003e\n\u003cp\u003eFinally, if you have several operations and don\u0026#39;t care what order they complete in, \u003ca href=\"https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise/all\"\u003ePromise.all accepts an array of Promises\u003c/a\u003e and creates a new Promise that resolves when all of them complete. This is useful for tying several things together and only proceeding once everything is done.\u003c/p\u003e\n\u003ch2 id=\"gotchas\"\u003eGotchas\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eGotcha the 1st: resolve() is not return.\u003c/strong\u003e It\u0026#39;s important to note that invocation of \u003ccode\u003eresolve\u003c/code\u003e is not the same as \u003ccode\u003ereturn\u003c/code\u003e. In other words, the initial function keeps executing until the end of the function or a return statement is reached. The \u003cem\u003evalue\u003c/em\u003e passed to resolve cannot be modified after calling it, so it\u0026#39;s possible to use promises for quite a while without encountering this little quirk, but it\u0026#39;s an important thing to keep in mind as it can lead to some unexpected behaviour.\u003c/p\u003e\n\u003cp\u003eFor this reason, I always use \u003ccode\u003ereturn resolve()\u003c/code\u003e unless there\u0026#39;s a compelling reason not to.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGotcha the 2nd: Errors that get swallowed.\u003c/strong\u003e We have not yet talked about errors very much. \u003cem\u003eIn many environments, exceptions thrown within a promise \u003ca href=\"http://jamesknelson.com/are-es6-promises-swallowing-your-errors/\"\u003ewill silently disappear\u003c/a\u003e, without even producing an alert in the console.\u003c/em\u003e Obviously this can lead to real frustration.\u003c/p\u003e\n\u003cp\u003eThe standard way to handle errors and rejected promises is with the \u003ccode\u003e.catch\u003c/code\u003e method.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003enew Promise(function(resolve, reject) {\n    throw new Error(\u0026#39;This is an error\u0026#39;);\n}).catch(function(err) {\n  console.log(\u0026#39;An error occurred\u0026#39;);\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe output above will be \u0026#39;An error occurred\u0026#39;, but in most cases, there will no output at all without the \u003ccode\u003e.catch\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFortunately, \u003ccode\u003ecatch\u003c/code\u003e catches all previous errors in the chain, so appending it to the end of a chain will ensure that any errors don\u0026#39;t get swallowed.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGotcha the 3rd: Errors that you miss\u003c/strong\u003e There are in fact two ways to catch errors: the \u003ccode\u003e.catch\u003c/code\u003e we have just seen, and a form of \u003ccode\u003e.then\u003c/code\u003e that accepts two arguments:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003emyPromise.then(function(result) {\n    handleResult(result);\n}, function(err) {\n    handleErr(err);\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe important thing to know about this form is that \u003cem\u003eeither\u003c/em\u003e the first function or the second will be invoked, but never both. So if an error occurs \u003cstrong\u003einside\u003c/strong\u003e the first function passed to \u003ccode\u003e.then\u003c/code\u003e, we need an error handler further down the chain. For this reason, I recommend using \u003ccode\u003e.catch\u003c/code\u003e unless there is a really good reason not to.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003ePromises are a great addition to the JavaScript toolset and make working with asynchronous code a little more fun. This has been a summary of the most important things I\u0026#39;ve encountered: for a really thorough treatment on getting started see \u003ca href=\"http://www.html5rocks.com/en/tutorials/es6/promises/\"\u003ethis post\u003c/a\u003e by Jake Archibald or the \u003ca href=\"http://www.html5rocks.com/en/tutorials/es6/promises/\"\u003eMDN reference page on promises\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"changelog\"\u003eChangelog\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e2016-03-19\u003c/strong\u003e Thanks to Steven Parker I\u0026#39;ve added a couple of clarifications on \u003ccode\u003ereject\u003c/code\u003e and \u003ccode\u003ecatch\u003c/code\u003e.\u003c/p\u003e\n","md":"The first time I needed to access a third-party API on the web I remember doing something like the following (in PHP):\r\n\r\n```php\r\n$data = file_get_contents('http://a/resource/somewhere');\r\n```\r\n\r\nThis has the advantage of being really easy to read: like all other parts of my code, I assign a variable to an expression and expect that it will be filled with a value of some sort. What I never thought about at the time was how much was going on behind the scenes: unlike an basic expression that performs a math operation or comparison, a whole HTTP request and response is going on before `$data` can be filled. During this time, my program pauses and no further code is executed.\r\n\r\nEnter JavaScript. In a browser, this same operation would be unacceptable: retrieving a resource through AJAX would mean no code can be executed until the response arrives, meaning the the user interface would be  for all intents a purposes frozen. On a Node.js server (which is single-threaded), no new client requests would be processed.\r\n\r\nInstead, in JavaScript, the equivalent function would accept an additional argument which is the **callback function**, which would execute when the response from the third-party is received. It does not return a value at all. This asynchronous execution has the advantage that slow operation like HTTP requests don't tie up the processor, but they have the disadvantage that they can quickly get out of hand, as we will see.\r\n\r\nIn a second pattern, the function does return a value, but it is not the HTTP response itself. Rather, it is an object which can be thought of as a representation of an unknown value. This object is called a promise. A promise has methods called handlers that describe what to do when the promise is either fulfilled or rejected.\r\n\r\nThis post is not meant to be an exhaustive treatment of promises, but merely an introduction to why I have found them useful. It is intended for those who know some JavaScript but are not experts at writing asynchronous code.\r\n\r\nI will deal exclusively with the ES6 (Promise/A+) variety. Since they are formally [part of ES6](http://caniuse.com/#search=promise), you may need [a polyfill](https://github.com/stefanpenner/es6-promise#readme) for older browsers. They are standard current version of Nodejs, however.\r\n\r\n## Examples: Wrapping Callbacks in a Promise\r\n\r\nLet's look at perhaps the simplest example of a function that executes an asynchronous callback: `setTimeout`. This function accepts two parameters: a callback to execute when a time interval completes, and a number representing a length of time in milliseconds. So\r\n\r\n```javascript\r\nsetTimeout(function() {\r\n    console.log('Some time later ...');\r\n}, 1000);\r\n```\r\n\r\ngets the point across.\r\n\r\nLet's wrap write a new function so that we can use a promise to execute a timed event. We'll call it `wait`.\r\n\r\n```javascript\r\nfunction wait(time) {\r\n    return new Promise(function(resolve, reject) {\r\n        setTimeout(function() {\r\n            resolve('You kept your Promise!');\r\n        }, time);\r\n    });\r\n}\r\n\r\nwait(1000).then(function(msg) {\r\n   console.log(msg)\r\n});\r\n```\r\n\r\nThe key is `return new Promise`. To this you pass a function with two parameters: one is function to resolve (fulfil) the promise and the other is function to reject the promise (the reject function is not used in the example above, because there's really no way for setTimeout to go wrong, but we'll see more example below that use it). Whatever values are passed to resolve and reject will later be passed to the handlers.\r\n\r\nNote that we can't do this for `setInterval`, which executes a recurring event. A promise can be resolved or rejected: after that, it's gone.\r\n\r\nThis example is pretty trivial. First of all, there's no real unknown value that we need the promise to keep track of for us and secondly, there's virtually no possibility of this promise being rejected.\r\n\r\nLet's look instead at Node's `http.get`, which is basically the equivalent of PHP `file_get_contents` mentioned above.\r\n\r\n```javascript\r\nhttp.get('http://a/resource/somewhere/', function(response) {\r\n   // deal with response\r\n});\r\n```\r\n\r\nLet's create a smarter promise:\r\n\r\n```javascript\r\nfunction requestResource(url) {\r\n    return new Promise(function(resolve, reject) {\r\n        http.get(address, function(response) {\r\n            if (response.status === 200) {\r\n                 return resolve(response.body);\r\n            else {\r\n                 return reject('Response not OK');\r\n            }\r\n        });\r\n    });\r\n}\r\n```\r\n\r\nWe've already made our lives easier when we need to handle the promise. For one thing, we are only passing the response body, which might be all we're going care about later. Secondly, we are rejecting the promise if the status code is not 200 (IRL we'd probably want to a better job and resolve some other codes, but that's a story for later). We can handle a rejection with the `.catch` method, which works just like `.then`.\r\n\r\nLet's use the [Dark Sky weather API](https://developer.forecast.io/docs/v2) to get the current ski conditions\r\n\r\n```javascript\r\nrequestResource('https://api.forecast.io/forecast/APIKEY/50.1149639,-122.9486474').then(function(res) {   \r\n    console.log('The current temperature is ' + res.body.currently.temperature);\r\n}).catch(function(err) {\r\n    console.log(err)\r\n});\r\n```\r\n\r\nNote: you'll have to use a real API key to make this work. The code will print out the current temperature in Whistler, BC, Canada.\r\n\r\n## Why would you want to do this?\r\n\r\nAll well and good, but so far, our promises have required us to write a fair bit of code to achieve pretty simple results. Why would you want to use them?\r\n\r\n**Avoid excessive nesting.** The most oft-cited advantage of promises is that they avoid the infinitely-nested callbacks that are so common in Node.js programming. In a web server-type application, the callback to respond to an HTTP request itself often contains a callback to query a database:\r\n\r\n```javascript\r\nrouter.get('/my-page', function(req, res) {\r\n    getSomeDataFromDb(req.someParameter, function(data) {\r\n        doSomething(data);\r\n        res.json(data);\r\n    }\r\n});\r\n```\r\n\r\nThis is two indentations deep before we even get to the meat, and it only involves one database query and no extra processing. On the other hand, we can chain promises to keep each step at the same lexical level as the step before it:\r\n\r\n```javascript\r\nmyPromise.then(function(data) {\r\n   return doSomething(data);\r\n}).then(function(newData) {\r\n    return doSomethingElse(newData) {\r\n}).then(function(newNewData) {\r\n    return doSomethingElseElse(newNewData);\r\n});\r\n```\r\n\r\nYou get the idea. At each step, the return value is the parameter passed to the next .then's callback.\r\n\r\n**Returning Promises.** Even more useful than chaining promises in the same function is returning a promise and doing further processing in some other part of your code. The promise is an object that can be passed between functions. This helps keep functions simple and logical. We have already seen the pattern of returning a promise above. Since the handler (`.then`) also returns a promise, we can tack on more handlers in each function the promise is passed to.\r\n\r\nCallbacks cannot be chained. A function that executes a callback that it does not itself define must accept that callback as an argument.\r\n\r\n```javascript\r\nfunction stepOne(callback) {\r\n    stepTwo(callback);\r\n}\r\n\r\nfunction stepTwo(callback) {    \r\n    setTimeout(callback, 1000);\r\n}\r\n\r\nstepOne(function() {\r\n    console.log('I got there ... eventually');\r\n});\r\n```\r\n\r\n**Easier to keep track of multiple asynchronous events.** I have found that when *multiple* asynchronous events are involved, Promises have a few advantages. First of all, thanks to JavaScript's scoping rules, the `resolve` and `reject` methods can be more than one level deep when they are executed. Imagine you need to make two database queries, and the second is dependent on the data returned by the first:\r\n\r\n```javascript\r\nfunction queryDb(params) {\r\n    return new Promise(resolve, reject) {\r\n        getDataFromDb(params, function(data) {\r\n            getMoreDataFromDb(data, function(moreData) {\r\n                resolve(moreData);\r\n            });\r\n         });\r\n    });\r\n}\r\n\r\nqueryDb.then( ... )\r\n```\r\n\r\nWe've taken something pretty hairy and wrapped it a function which lets you not worry about the details too much when you use it later.\r\n\r\nAnother common pattern is returning promises in a `then` handler:\r\n\r\n```javascript\r\nmyPromise.then(function(dataOne) {\r\n    // process dataOne and create another promise\r\n    return myOtherPromise;\r\n}).then(function(dataTwo) {\r\n    // do something with dataTwo\r\n});\r\n```\r\n\r\nSomewhat surprisingly (but very usefully), `dataTwo` is *NOT* `myOtherPromise` itself, but rather the value that `myOtherPromise` resolves to. This lets us be a little bit dumb about creating promises within handlers, secure in the knowledge that the next handler won't be invoked until the value we care about it known.\r\n\r\nFinally, if you have several operations and don't care what order they complete in, [Promise.all accepts an array of Promises](https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise/all) and creates a new Promise that resolves when all of them complete. This is useful for tying several things together and only proceeding once everything is done.\r\n\r\n## Gotchas\r\n\r\n**Gotcha the 1st: resolve() is not return.** It's important to note that invocation of `resolve` is not the same as `return`. In other words, the initial function keeps executing until the end of the function or a return statement is reached. The *value* passed to resolve cannot be modified after calling it, so it's possible to use promises for quite a while without encountering this little quirk, but it's an important thing to keep in mind as it can lead to some unexpected behaviour.\r\n\r\nFor this reason, I always use `return resolve()` unless there's a compelling reason not to.\r\n\r\n**Gotcha the 2nd: Errors that get swallowed.** We have not yet talked about errors very much. *In many environments, exceptions thrown within a promise [will silently disappear](http://jamesknelson.com/are-es6-promises-swallowing-your-errors/), without even producing an alert in the console.* Obviously this can lead to real frustration.\r\n\r\nThe standard way to handle errors and rejected promises is with the `.catch` method.\r\n\r\n```javascript\r\nnew Promise(function(resolve, reject) {\r\n    throw new Error('This is an error');\r\n}).catch(function(err) {\r\n  console.log('An error occurred');\r\n});\r\n```\r\n\r\nThe output above will be 'An error occurred', but in most cases, there will no output at all without the `.catch`.\r\n\r\nFortunately, `catch` catches all previous errors in the chain, so appending it to the end of a chain will ensure that any errors don't get swallowed.\r\n\r\n**Gotcha the 3rd: Errors that you miss** There are in fact two ways to catch errors: the `.catch` we have just seen, and a form of `.then` that accepts two arguments:\r\n\r\n```javascript\r\nmyPromise.then(function(result) {\r\n    handleResult(result);\r\n}, function(err) {\r\n    handleErr(err);\r\n});\r\n```\r\n\r\nThe important thing to know about this form is that *either* the first function or the second will be invoked, but never both. So if an error occurs **inside** the first function passed to `.then`, we need an error handler further down the chain. For this reason, I recommend using `.catch` unless there is a really good reason not to.\r\n\r\n## Conclusion\r\n\r\nPromises are a great addition to the JavaScript toolset and make working with asynchronous code a little more fun. This has been a summary of the most important things I've encountered: for a really thorough treatment on getting started see [this post](http://www.html5rocks.com/en/tutorials/es6/promises/) by Jake Archibald or the [MDN reference page on promises](http://www.html5rocks.com/en/tutorials/es6/promises/).\r\n\r\n## Changelog\r\n\r\n**2016-03-19** Thanks to Steven Parker I've added a couple of clarifications on `reject` and `catch`."}},"publishedDate":{"$date":"2016-03-14T06:00:00.000Z"}}
{"_id":{"$oid":"5802e87a31c9af6010bb4fc2"},"slug":"in-the-beginning-was-the-code-and-the-code-gave-life-and-the-code-was-life","title":"In the beginning was the code, and the code gave life, and the code was life","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eThe oldest gene we possess carries the information to make something called the 5S RNA, a component of the ribosome. This molecular machine is responsible for translating a DNA sequence into a protein sequence. The reason this is critical is that chemical properties of DNA are pretty simple: it\u0026#39;s more or less just a carrier for information. Proteins on the other hand, have astoundingly complex chemistry: they can synthesize or break down sugar, create pigments to give us a specific hair colour, give us or prevent cancer. In short: everything.\u003c/p\u003e\n","md":"The oldest gene we possess carries the information to make something called the 5S RNA, a component of the ribosome. This molecular machine is responsible for translating a DNA sequence into a protein sequence. The reason this is critical is that chemical properties of DNA are pretty simple: it's more or less just a carrier for information. Proteins on the other hand, have astoundingly complex chemistry: they can synthesize or break down sugar, create pigments to give us a specific hair colour, give us or prevent cancer. In short: everything."},"extended":{"html":"\u003cfigure\u003e\n\u003cimg src=\"http://res.cloudinary.com/dfxksdivn/image/upload/v1476824513/dna_gqahjf.png\" alt=\"\"\u003e\n\u003ccaption\u003e\nCredit: \u003ca href=\"https://xkcd.com/1605/\"\u003eRandall Munro\u003c/a\u003e, Used under CC BY-NC\n\u003c/caption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eThe oldest gene we possess carries the information to make something called the 5S RNA, a component of the ribosome. This molecular machine is responsible for translating a DNA sequence into a protein sequence. The reason this is critical is that chemical properties of DNA are pretty simple: it\u0026#39;s more or less just a carrier for information. Proteins on the other hand, have astoundingly complex chemistry: they can synthesize or break down sugar, create pigments to give us a specific hair colour, give us or prevent cancer. In short: everything.\u003c/p\u003e\n\u003cp\u003eDNA and protein present the grandmother of all chicken-and-egg problems: one simply cannot exist without the other. DNA depends on specific proteins to replicate, while protein cannot replicate at all and depends on DNA to make more copies of itself. The answer to this apparent paradox comes from the intermediary between these two: RNA. RNA carries information in the same way as DNA, but is someone less stable and more prone to error. However, it can also do a limited amount of the fancy folding-and-chemistry that proteins can. It can be - in the right circumstances - both word and action.\u003c/p\u003e\n\u003cp\u003eLife has exactly one requirement: information capable of making copies of itself. At some time in the very distant past, a molecule that was likely RNA or something related to it, carried the exact chemical properties needed to spam copies of itself. It was both word and action. As this molecule made copies which sometimes contained errors, it became increasingly sophisticated, and the word and action functions eventually became abstracted out to more specialized subcomponents.\u003c/p\u003e\n\u003cp\u003eThis history appears to be repeating itself. The physical world is hard to deal with, but once the process of translating simple signals into pixels, robotic movements, or 3D objects becomes codified, the signals can rapidly become more and more complex. Eventually, they become sophisticated enough that the it defies naive logic: how can the mere expression of language actually \u003cstrong\u003edo\u003c/strong\u003e something? And yet the language needed to turn a sperm and egg into a human being requires orders of magnitude less code than the micro-SD card in your phone.\u003c/p\u003e\n\u003cp\u003eThere\u0026#39;s an unsettling corollary to all this, which is: what happens when software becomes too sophisticated for our human brains to grasp it? Biology certainly exists in this space: most scientists working in the field study only a tiny part of a grand system, or an immensely simplified model of a complex system. Arguably software already exists in this space, as programmers tend to work only at the very top of a rickety pile of abstractions.\u003c/p\u003e\n\u003cp\u003eThe truly disturbing part is that life becomes more sophisticated through \u003cem\u003erandom\u003c/em\u003e change and selection of minute improvements. Programmers think of themselves as smart, but even random change, followed by selection (forking, community growth, adoption of technology by the masses) ought to be enough for software to move forward. Merges are even a kind of sex, allowing improvements that occur in different places to find each other. Will we get to the point where we simply write tests and let the computer randomly generate solutions until it finds the optimal one? (Now, that\u0026#39;s TDD for you). Is it inevitable?\u003c/p\u003e\n","md":"\u003cfigure\u003e\r\n![](http://res.cloudinary.com/dfxksdivn/image/upload/v1476824513/dna_gqahjf.png)\r\n\u003ccaption\u003e\r\nCredit: \u003ca href=\"https://xkcd.com/1605/\"\u003eRandall Munro\u003c/a\u003e, Used under CC BY-NC\r\n\u003c/caption\u003e\r\n\u003c/figure\u003e\r\n\r\nThe oldest gene we possess carries the information to make something called the 5S RNA, a component of the ribosome. This molecular machine is responsible for translating a DNA sequence into a protein sequence. The reason this is critical is that chemical properties of DNA are pretty simple: it's more or less just a carrier for information. Proteins on the other hand, have astoundingly complex chemistry: they can synthesize or break down sugar, create pigments to give us a specific hair colour, give us or prevent cancer. In short: everything.\r\n\r\nDNA and protein present the grandmother of all chicken-and-egg problems: one simply cannot exist without the other. DNA depends on specific proteins to replicate, while protein cannot replicate at all and depends on DNA to make more copies of itself. The answer to this apparent paradox comes from the intermediary between these two: RNA. RNA carries information in the same way as DNA, but is someone less stable and more prone to error. However, it can also do a limited amount of the fancy folding-and-chemistry that proteins can. It can be - in the right circumstances - both word and action.\r\n\r\nLife has exactly one requirement: information capable of making copies of itself. At some time in the very distant past, a molecule that was likely RNA or something related to it, carried the exact chemical properties needed to spam copies of itself. It was both word and action. As this molecule made copies which sometimes contained errors, it became increasingly sophisticated, and the word and action functions eventually became abstracted out to more specialized subcomponents.\r\n\r\nThis history appears to be repeating itself. The physical world is hard to deal with, but once the process of translating simple signals into pixels, robotic movements, or 3D objects becomes codified, the signals can rapidly become more and more complex. Eventually, they become sophisticated enough that the it defies naive logic: how can the mere expression of language actually **do** something? And yet the language needed to turn a sperm and egg into a human being requires orders of magnitude less code than the micro-SD card in your phone.\r\n\r\nThere's an unsettling corollary to all this, which is: what happens when software becomes too sophisticated for our human brains to grasp it? Biology certainly exists in this space: most scientists working in the field study only a tiny part of a grand system, or an immensely simplified model of a complex system. Arguably software already exists in this space, as programmers tend to work only at the very top of a rickety pile of abstractions.\r\n\r\nThe truly disturbing part is that life becomes more sophisticated through *random* change and selection of minute improvements. Programmers think of themselves as smart, but even random change, followed by selection (forking, community growth, adoption of technology by the masses) ought to be enough for software to move forward. Merges are even a kind of sex, allowing improvements that occur in different places to find each other. Will we get to the point where we simply write tests and let the computer randomly generate solutions until it finds the optimal one? (Now, that's TDD for you). Is it inevitable?"}},"publishedDate":{"$date":"2016-01-23T07:00:00.000Z"}}
{"_id":{"$oid":"5802e90331c9af6010bb4fc3"},"slug":"journals-your-domain-is-now-your-reputation-protect-it","title":"Journals: Your domain is now your reputation. Protect it.","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eOne facet of web sites that often confuses clients who have not been involved with the web before is that they have to pay separately for their domain and their hosting. While the different bills can be annoying and seem like a scam, there is very good reason to keep them distinct and one should actually be wary of any \u0026quot;package deals\u0026quot; that sell both at once.\u003c/p\u003e\n","md":"One facet of web sites that often confuses clients who have not been involved with the web before is that they have to pay separately for their domain and their hosting. While the different bills can be annoying and seem like a scam, there is very good reason to keep them distinct and one should actually be wary of any \"package deals\" that sell both at once."},"extended":{"html":"\u003cp\u003eOne facet of web sites that often confuses clients who have not been involved with the web before is that they have to pay separately for their domain and their hosting. While the different bills can be annoying and seem like a scam, there is very good reason to keep them distinct and one should actually be wary of any \u0026quot;package deals\u0026quot; that sell both at once.\u003c/p\u003e\n\u003cp\u003eThe difference is often explained as if the domain is a phone number and the hosting server an actual phone, though I think this analogy is a bit limited as we will see in a moment. As long as these can be purchased separately (and the number simply directed to the phone by your telecom company), it\u0026#39;s possible to get a new phone every couple of years without having to alert all of your contacts that your number has changed. You contacts don\u0026#39;t need to know or care that the hardware you carry in your pocket has changed.\u003c/p\u003e\n\u003cp\u003eThe same is true of hosting: as a company or organization grows, the needs for it\u0026#39;s web hosting will change. Perhaps it simply gets more traffic and needs a dedicated server, or the backend tech running it\u0026#39;s website will change. Or maybe the hosting company just sucks (let\u0026#39;s not go there). In all of these cases, it\u0026#39;s possible to keep the same domain and just direct web traffic to a different physical computer.\u003c/p\u003e\n\u003cp\u003eOne would NOT want to change their domain just to switch servers. Unlike a phone number, a \u003cstrong\u003egood\u003c/strong\u003e domain is a plain-language pneumatic for an organization, as readable by humans as it is by computers. You don\u0026#39;t need to look up anything to contact Facebook. \u003cstrong\u003eA good domain that has built traffic, public knowledge, and search-engine credence over time has equity that can be measured in real monetary value.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eA modified version of this exists for scientific journals, who - in a time where anyone can setup a website that they call a journal and start \u0026quot;publishing\u0026quot; papers - must protect their reputation. John Bohannon, \u003ca href=\"http://www.caseyy.org/predatory-publishers-in-the-light-of-day-where-do-we-go-from-here/\"\u003ewho previously exposed a new underclass of predatory publishers\u003c/a\u003e, reports that in several cases, \u003ca href=\"http://www.sciencemag.org/content/350/6263/903.full\"\u003ethe domain of a journal was \u0026quot;snatched\u0026quot; by predatory entities who then use this domain to fool researchers into publishing in their fake, spoof journal\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eI am utterly astonished by this. The only way to snatch a domain is if the original owner allows it expire. This is one thing for a small business like a hair salon or car mechanic, another one entirely for an academic publisher who\u0026#39;s sole \u0026quot;product\u0026quot; is information and therefore whose \u003cstrong\u003ebusiness in 2015 is web-first, print-second, even if they don\u0026#39;t acknowledge it.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWhile Bohannon implies that these journals have not been doing due diligence in web administration and security, this doesn\u0026#39;t begin to describe it. The domain now \u003cstrong\u003eIS\u003c/strong\u003e the equity and the reputation of the organization - the first identifier a human or a computer associate to an actual entity. to ignore it is not a lack of diligence, it\u0026#39;s total ignorance of how people - even academics - interact with journals in the 21st century.\u003c/p\u003e\n\u003cp\u003ePerhaps this shouldn\u0026#39;t be a surprise for an industry that still seems stuck in the print world, where PDFs are still the primary data format for both manuscripts and publications, that charge by the page and impose strict length limits even for methods and references, that distribute \u0026quot;raw data\u0026quot; in MS Word tables, that demand figures at 600 dpi (as if dpi mattered for 90% of their readers), and that demand archane reference formats. The Science news piece reporting this story \u003ca href=\"http://www.sciencemag.org/content/350/6263/903.full\"\u003einexplicably has two sets of comments: one for mobile and one for desktop\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePerhaps the obsession with print, which has meant death in other industries, has actually helped journals retain their \u003ca href=\"http://svpow.com/2012/03/12/its-not-all-doom-and-gloom-in-academia-at-least-elsevier-are-increasing-their-profits/\"\u003eexceptional profit margins\u003c/a\u003e when they aren\u0026#39;t adding any conceivable value to the scientific process. As long as space remains limited in a particular journal, space in that journal will be perceived to have merit. And nothing matters more to academics than merit. God forbid they have the technology to publish an effectively limitless amount of content every month: written, edited and peer-reviewed by people who don\u0026#39;t even work for them.\u003c/p\u003e\n\u003cp\u003eContrary to Bohannon\u0026#39;s claims, buying a domain when the owner let it expire is not \u0026quot;hijacking.\u0026quot; While Bohannon says \u0026quot;Anyone can buy a Web domain from private registration companies who neither vet nor care whether the purchaser has a \u0026#39;right\u0026#39; to it.\u0026quot; This is, of course, by design; no one has a \u0026quot;right\u0026quot; to any domain a priori. Just like no one has a right be a gatekeeper of scientific truth, a priori.\u003c/p\u003e\n","md":"One facet of web sites that often confuses clients who have not been involved with the web before is that they have to pay separately for their domain and their hosting. While the different bills can be annoying and seem like a scam, there is very good reason to keep them distinct and one should actually be wary of any \"package deals\" that sell both at once.\r\n\r\nThe difference is often explained as if the domain is a phone number and the hosting server an actual phone, though I think this analogy is a bit limited as we will see in a moment. As long as these can be purchased separately (and the number simply directed to the phone by your telecom company), it's possible to get a new phone every couple of years without having to alert all of your contacts that your number has changed. You contacts don't need to know or care that the hardware you carry in your pocket has changed.\r\n\r\nThe same is true of hosting: as a company or organization grows, the needs for it's web hosting will change. Perhaps it simply gets more traffic and needs a dedicated server, or the backend tech running it's website will change. Or maybe the hosting company just sucks (let's not go there). In all of these cases, it's possible to keep the same domain and just direct web traffic to a different physical computer.\r\n\r\nOne would NOT want to change their domain just to switch servers. Unlike a phone number, a **good** domain is a plain-language pneumatic for an organization, as readable by humans as it is by computers. You don't need to look up anything to contact Facebook. **A good domain that has built traffic, public knowledge, and search-engine credence over time has equity that can be measured in real monetary value.**\r\n\r\nA modified version of this exists for scientific journals, who - in a time where anyone can setup a website that they call a journal and start \"publishing\" papers - must protect their reputation. John Bohannon, [who previously exposed a new underclass of predatory publishers](http://www.caseyy.org/predatory-publishers-in-the-light-of-day-where-do-we-go-from-here/), reports that in several cases, [the domain of a journal was \"snatched\" by predatory entities who then use this domain to fool researchers into publishing in their fake, spoof journal](http://www.sciencemag.org/content/350/6263/903.full).\r\n\r\nI am utterly astonished by this. The only way to snatch a domain is if the original owner allows it expire. This is one thing for a small business like a hair salon or car mechanic, another one entirely for an academic publisher who's sole \"product\" is information and therefore whose **business in 2015 is web-first, print-second, even if they don't acknowledge it.**\r\n\r\nWhile Bohannon implies that these journals have not been doing due diligence in web administration and security, this doesn't begin to describe it. The domain now **IS** the equity and the reputation of the organization - the first identifier a human or a computer associate to an actual entity. to ignore it is not a lack of diligence, it's total ignorance of how people - even academics - interact with journals in the 21st century.\r\n\r\nPerhaps this shouldn't be a surprise for an industry that still seems stuck in the print world, where PDFs are still the primary data format for both manuscripts and publications, that charge by the page and impose strict length limits even for methods and references, that distribute \"raw data\" in MS Word tables, that demand figures at 600 dpi (as if dpi mattered for 90% of their readers), and that demand archane reference formats. The Science news piece reporting this story [inexplicably has two sets of comments: one for mobile and one for desktop](http://www.sciencemag.org/content/350/6263/903.full).\r\n\r\nPerhaps the obsession with print, which has meant death in other industries, has actually helped journals retain their [exceptional profit margins](http://svpow.com/2012/03/12/its-not-all-doom-and-gloom-in-academia-at-least-elsevier-are-increasing-their-profits/) when they aren't adding any conceivable value to the scientific process. As long as space remains limited in a particular journal, space in that journal will be perceived to have merit. And nothing matters more to academics than merit. God forbid they have the technology to publish an effectively limitless amount of content every month: written, edited and peer-reviewed by people who don't even work for them.\r\n\r\nContrary to Bohannon's claims, buying a domain when the owner let it expire is not \"hijacking.\" While Bohannon says \"Anyone can buy a Web domain from private registration companies who neither vet nor care whether the purchaser has a 'right' to it.\" This is, of course, by design; no one has a \"right\" to any domain a priori. Just like no one has a right be a gatekeeper of scientific truth, a priori."}},"publishedDate":{"$date":"2015-11-23T07:00:00.000Z"}}
{"_id":{"$oid":"5802e9ad31c9af6010bb4fc4"},"slug":"how-to-choose-your-first-programming-language","title":"How to choose your first programming language","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI do not have Google Analytics on my blog (well, I do, but I seem to have forgotten the account it\u0026#39;s associated with), and when I discovered my mistake, also discovered also that I didn\u0026#39;t really care. If my blog doesn\u0026#39;t have an audience, that\u0026#39;s hardly a reason to stop blogging, and if it does, \u003ca href=\"https://brooksreview.net/author/benbrooks/\"\u003eI don\u0026#39;t need my topics to change based on traffic\u003c/a\u003e. I write mainly for me - if someone else finds it interesting or useful or insightful, that\u0026#39;s great; if not, I\u0026#39;ll try again next time.\u003c/p\u003e\n","md":"I do not have Google Analytics on my blog (well, I do, but I seem to have forgotten the account it's associated with), and when I discovered my mistake, also discovered also that I didn't really care. If my blog doesn't have an audience, that's hardly a reason to stop blogging, and if it does, [I don't need my topics to change based on traffic](https://brooksreview.net/author/benbrooks/). I write mainly for me - if someone else finds it interesting or useful or insightful, that's great; if not, I'll try again next time."},"extended":{"html":"\u003cp\u003eI do not have Google Analytics on my blog (well, I do, but I seem to have forgotten the account it\u0026#39;s associated with), and when I discovered my mistake, also discovered also that I didn\u0026#39;t really care. If my blog doesn\u0026#39;t have an audience, that\u0026#39;s hardly a reason to stop blogging, and if it does, \u003ca href=\"https://brooksreview.net/author/benbrooks/\"\u003eI don\u0026#39;t need my topics to change based on traffic\u003c/a\u003e. I write mainly for me - if someone else finds it interesting or useful or insightful, that\u0026#39;s great; if not, I\u0026#39;ll try again next time.\u003c/p\u003e\n\u003cp\u003eOne recent post I wrote must have garnered some pageviews because I started getting emails asking me to add a link to outside resources. One of these was a page of infographics about different programming languages aimed at helping beginners choose which one to learn. This is, in the traditional, quantitative sense, probably a good topic for a blog-post/infographic, as I\u0026#39;m willing to bet these are highly Googled terms.\u003c/p\u003e\n\u003cp\u003eSo here is my own generically-titled, Buzzfeed-worthy, SEO-whoring blog post about how to get started with your first programming language, no more than 800 words long.\u003c/p\u003e\n\u003cp\u003eIt doesn\u0026#39;t matter which programming language you pick. While there are major differences in the syntax, purpose and utility of programming languages, none of these are important at the beginning. The code you write at first will be absolute shit.\u003c/p\u003e\n\u003cp\u003eDon\u0026#39;t take the wrong way. The code I wrote at the beginning was absolute shit. Even code I wrote a year ago looks like shit to me now. I suspect the same is true of most programmers.\u003c/p\u003e\n\u003cp\u003eTrying to decide between languages is like trying to choose between Blogspot or Wordpress for your first blog: it\u0026#39;s a stalling tactic. A subconscious stalling tactic everyone\u0026#39;s brain employs all the time everyone makes all the time. \u003cstrong\u003eIt creates separation between the decision that we want to do something and the hard work that comes with actually doing it.\u003c/strong\u003e It\u0026#39;s wanting to get healthy and deciding between running shoes or a bike.\u003c/p\u003e\n\u003cp\u003eJust pick one. There are tonnes of great resources out there for beginners in just about any language, including really obscure ones. You\u0026#39;ll discover what you like about it, and what you like about programming in general, and this refinement will help guide your going forward. Or, um, you might discover coding isn\u0026#39;t for you. That\u0026#39;s fine, too. There is a lot more to making software than writing the code.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDon\u0026#39;t let anyone tell you you\u0026#39;re doing it wrong. That you learned the wrong language or code on the wrong type of machine. That\u0026#39;s simple idiocy.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eCoding just to get a job is a lot like blogging to drive website traffic: yes, it can be a very effective strategy, if done right. But without time, without commitment, without discipline, and without love, both you and your audience will be able to tell.\u003c/p\u003e\n","md":"I do not have Google Analytics on my blog (well, I do, but I seem to have forgotten the account it's associated with), and when I discovered my mistake, also discovered also that I didn't really care. If my blog doesn't have an audience, that's hardly a reason to stop blogging, and if it does, [I don't need my topics to change based on traffic](https://brooksreview.net/author/benbrooks/). I write mainly for me - if someone else finds it interesting or useful or insightful, that's great; if not, I'll try again next time.\r\n\r\nOne recent post I wrote must have garnered some pageviews because I started getting emails asking me to add a link to outside resources. One of these was a page of infographics about different programming languages aimed at helping beginners choose which one to learn. This is, in the traditional, quantitative sense, probably a good topic for a blog-post/infographic, as I'm willing to bet these are highly Googled terms.\r\n\r\nSo here is my own generically-titled, Buzzfeed-worthy, SEO-whoring blog post about how to get started with your first programming language, no more than 800 words long.\r\n\r\nIt doesn't matter which programming language you pick. While there are major differences in the syntax, purpose and utility of programming languages, none of these are important at the beginning. The code you write at first will be absolute shit.\r\n\r\nDon't take the wrong way. The code I wrote at the beginning was absolute shit. Even code I wrote a year ago looks like shit to me now. I suspect the same is true of most programmers.\r\n\r\nTrying to decide between languages is like trying to choose between Blogspot or Wordpress for your first blog: it's a stalling tactic. A subconscious stalling tactic everyone's brain employs all the time everyone makes all the time. **It creates separation between the decision that we want to do something and the hard work that comes with actually doing it.** It's wanting to get healthy and deciding between running shoes or a bike.\r\n\r\nJust pick one. There are tonnes of great resources out there for beginners in just about any language, including really obscure ones. You'll discover what you like about it, and what you like about programming in general, and this refinement will help guide your going forward. Or, um, you might discover coding isn't for you. That's fine, too. There is a lot more to making software than writing the code.\r\n\r\n**Don't let anyone tell you you're doing it wrong. That you learned the wrong language or code on the wrong type of machine. That's simple idiocy.**\r\n\r\nCoding just to get a job is a lot like blogging to drive website traffic: yes, it can be a very effective strategy, if done right. But without time, without commitment, without discipline, and without love, both you and your audience will be able to tell."}},"publishedDate":{"$date":"2015-11-10T07:00:00.000Z"}}
{"_id":{"$oid":"5802ea2931c9af6010bb4fc5"},"slug":"the-web-covenant-ad-blockers-are-here-to-stay","title":"The Web Covenant: Ad Blockers are here to stay","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eSince I blogged \u003ca href=\"http://www.caseyy.org/questions-i-have-about-facebooks-instant-articles/\"\u003ea month ago\u003c/a\u003e on the topic of content and page performance, the discussion around ad-blockers has really heated up.\u003c/p\u003e\n","md":"Since I blogged [a month ago](http://www.caseyy.org/questions-i-have-about-facebooks-instant-articles/) on the topic of content and page performance, the discussion around ad-blockers has really heated up.\r\n"},"extended":{"html":"\u003cp\u003eSince I blogged \u003ca href=\"http://www.caseyy.org/questions-i-have-about-facebooks-instant-articles/\"\u003ea month ago\u003c/a\u003e on the topic of content and page performance, the discussion around ad-blockers has really heated up.\u003c/p\u003e\n\u003cp\u003eJames Avery: CEO of Adzerk, using the same comparison to the Napster revolution that I used in my previous post, \u003ca href=\"http://adexchanger.com/data-driven-thinking/ad-blocking-will-keep-growing-until-we-make-ads-better-2/\"\u003eoffers his prediction that ad blocking will keep growing until ads become less creepy and less detrimental to web page performance.\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSam Snelling takes a \u003ca href=\"http://snelling.io/on-ad-blocking\"\u003emore hard-line approach:\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\nThere is no implied contract that you can dictate what I do and do not load. If I want to enable no script, or block cookies, or use a vpn with a rotating ip address, I will. All these things will change your ad revenue.\n\u003c/blockquote\u003e\n\n\u003cp\u003eSeth Godin, one of the founders of \u0026quot;inbound marketing\u0026quot;, \u003ca href=\"http://sethgodin.typepad.com/seths_blog/2015/09/ad-blocking.html\"\u003eargues that\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\nadvertisers have had fifteen years to show self restraint. They\u0026#39;ve had the chance to not secretly track people, set cookies for their own benefit, insert popunders and popovers and poparounds, and mostly, deliver us ads we actually want to see.\n\u003c/blockquote\u003e\n\n\u003cp\u003eAnd that their failure to show \u0026quot;self-restraint\u0026quot; is to blame for the rise in ad blocking popularity.\u003c/p\u003e\n\u003cp\u003eOn the other side of the isle, the Interactive Advertising Bureau is \u003ca href=\"http://adage.com/article/digital/iab-surveys-options-fight-ad-blockers-including-lawsuits/300228/\"\u003eexploring it\u0026#39;s options:\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\nThe ad blockers \u0026quot;are interfering with websites\u0026#39; ability to display all the pixels that are part of that website, arguably there\u0026#39;s some sort of law that prohibits that,\u0026quot; Mr. Moore said. \u0026quot;I\u0026#39;m not by any means a lawyer, but there is work being done to explore whether in fact that may be the case.\u0026quot;\n\u003c/blockquote\u003e\n\n\u003cp\u003eI am also not a lawyer, but I do know a bit about technology, and my professional opinion is that Mr. Moore\u0026#39;s professional opinion is stupid.\u003c/p\u003e\n\u003cp\u003eThe way that the web works, the covenant at the heart of every HTTP request, is that a program on one computer requests some data from a another computer and then uses some algorithms to do something with that data. That program could be a browser that uses the data to create a visual representation of the returned code, but no one ever said it had to be. It could be a screen reader, or the curl function running in a terminal window. Is the IAB going to sue everyone who uses screen readers, who turn JavaScript off, who use non-standard or proxy browsers that get some things wrong, who view their sites on devices with screens that are too small or too large to show the ads properly, or too slow to load all of the content in a timely manner?\u003c/p\u003e\n\u003cp\u003eThere\u0026#39;s a techno-ethical argument in here that users and user agents have the right to do with their HTML and CSS what they wish, and that using an ad blocker isn\u0026#39;t any more immoral than going to the bathroom during the commercials. But even leaving that aside, it makes it glaringly obvious why ad blockers are here to stay: \u003cstrong\u003eonce a web server has dispatched the requested data, it has no say, from a technical standpoint, in what\u0026#39;s done with it.\u003c/strong\u003e Even if ad blockers are immoral, it still isn\u0026#39;t practical to try to stop them.\u003c/p\u003e\n\u003cp\u003eRemember real popup ads, the ones that would open a new browser window when you tried to close them? They are pretty hard to find these days, and not because advertisers began showing restraint. Browser vendors realized that popups created a terrible experience for their users, and began blocking them (and \u003cem\u003ethen\u003c/em\u003e the advertisers began showing restraint). This type of \u0026quot;ad blocking\u0026quot; has been the default in all browsers for years. This next round is really just history repeating itself - with the added urgency that the rise of mobile browsing has made good page performance an even greater concern.\u003c/p\u003e\n","md":"Since I blogged [a month ago](http://www.caseyy.org/questions-i-have-about-facebooks-instant-articles/) on the topic of content and page performance, the discussion around ad-blockers has really heated up.\r\n\r\nJames Avery: CEO of Adzerk, using the same comparison to the Napster revolution that I used in my previous post, [offers his prediction that ad blocking will keep growing until ads become less creepy and less detrimental to web page performance.](http://adexchanger.com/data-driven-thinking/ad-blocking-will-keep-growing-until-we-make-ads-better-2/)\r\n\r\nSam Snelling takes a [more hard-line approach:](http://snelling.io/on-ad-blocking)\r\n\u003cblockquote\u003e\r\nThere is no implied contract that you can dictate what I do and do not load. If I want to enable no script, or block cookies, or use a vpn with a rotating ip address, I will. All these things will change your ad revenue.\r\n\u003c/blockquote\u003e\r\n\r\nSeth Godin, one of the founders of \"inbound marketing\", [argues that](http://sethgodin.typepad.com/seths_blog/2015/09/ad-blocking.html)\r\n\u003cblockquote\u003e\r\nadvertisers have had fifteen years to show self restraint. They've had the chance to not secretly track people, set cookies for their own benefit, insert popunders and popovers and poparounds, and mostly, deliver us ads we actually want to see.\r\n\u003c/blockquote\u003e\r\n\r\nAnd that their failure to show \"self-restraint\" is to blame for the rise in ad blocking popularity.\r\n\r\nOn the other side of the isle, the Interactive Advertising Bureau is [exploring it's options:](http://adage.com/article/digital/iab-surveys-options-fight-ad-blockers-including-lawsuits/300228/)\r\n\u003cblockquote\u003e\r\nThe ad blockers \"are interfering with websites' ability to display all the pixels that are part of that website, arguably there's some sort of law that prohibits that,\" Mr. Moore said. \"I'm not by any means a lawyer, but there is work being done to explore whether in fact that may be the case.\"\r\n\u003c/blockquote\u003e\r\n\r\nI am also not a lawyer, but I do know a bit about technology, and my professional opinion is that Mr. Moore's professional opinion is stupid.\r\n\r\nThe way that the web works, the covenant at the heart of every HTTP request, is that a program on one computer requests some data from a another computer and then uses some algorithms to do something with that data. That program could be a browser that uses the data to create a visual representation of the returned code, but no one ever said it had to be. It could be a screen reader, or the curl function running in a terminal window. Is the IAB going to sue everyone who uses screen readers, who turn JavaScript off, who use non-standard or proxy browsers that get some things wrong, who view their sites on devices with screens that are too small or too large to show the ads properly, or too slow to load all of the content in a timely manner?\r\n\r\nThere's a techno-ethical argument in here that users and user agents have the right to do with their HTML and CSS what they wish, and that using an ad blocker isn't any more immoral than going to the bathroom during the commercials. But even leaving that aside, it makes it glaringly obvious why ad blockers are here to stay: **once a web server has dispatched the requested data, it has no say, from a technical standpoint, in what's done with it.** Even if ad blockers are immoral, it still isn't practical to try to stop them.\r\n\r\nRemember real popup ads, the ones that would open a new browser window when you tried to close them? They are pretty hard to find these days, and not because advertisers began showing restraint. Browser vendors realized that popups created a terrible experience for their users, and began blocking them (and *then* the advertisers began showing restraint). This type of \"ad blocking\" has been the default in all browsers for years. This next round is really just history repeating itself - with the added urgency that the rise of mobile browsing has made good page performance an even greater concern."}},"publishedDate":{"$date":"2015-09-26T06:00:00.000Z"}}
{"_id":{"$oid":"5802eab131c9af6010bb4fc6"},"slug":"5-things-i-learned-building-a-react-and-node-app","title":"5 things I learned building a React and Node app","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eA blog post over at \u003ca href=\"http://blog.teamtreehouse.com/7-web-development-trends-for-2015\"\u003eTreehouse\u003c/a\u003e listed seven web development trends for 2015. At least five of them touched on React, so perhaps the article could be summarized as:\u003c/p\u003e\n\u003cblockquote\u003eReact, React, React, React, baked beans, React, and React.\u003c/blockquote\u003e","md":"A blog post over at [Treehouse](http://blog.teamtreehouse.com/7-web-development-trends-for-2015) listed seven web development trends for 2015. At least five of them touched on React, so perhaps the article could be summarized as:\r\n\r\n\u003cblockquote\u003eReact, React, React, React, baked beans, React, and React.\u003c/blockquote\u003e"},"extended":{"html":"\u003cp\u003eA blog post over at \u003ca href=\"http://blog.teamtreehouse.com/7-web-development-trends-for-2015\"\u003eTreehouse\u003c/a\u003e listed seven web development trends for 2015. At least five of them touched on React, so perhaps the article could be summarized as:\u003c/p\u003e\n\u003cblockquote\u003eReact, React, React, React, baked beans, React, and React.\u003c/blockquote\u003e\n\n\u003cp\u003eJavaScript is hot right now. I am far from an expert on building big stuff with JavaScript, but I thought with the recent release of \u003ca href=\"http://ncbi.site/\"\u003eMonocle\u003c/a\u003e that I could give a little perspective on what I learned from a early release of my first fully-JS project.\u003c/p\u003e\n\u003cp\u003eFor in-depth tutorials on getting a Node or React app running, I would point you to \u003ca href=\"http://cwbuecheler.com/web/tutorials/2013/node-express-mongo/\"\u003eChris Buecheler\u003c/a\u003e, \u003ca href=\"https://scotch.io/tutorials/learning-react-getting-started-and-concepts\"\u003eScotch.io\u003c/a\u003e, or \u003ca href=\"https://www.codementor.io/reactjs/tutorial/react-js-flux-architecture-tutorial\"\u003eCodeMentor\u003c/a\u003e.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBuild tools should be a time saver, not a time sink.\u003c/strong\u003e Monocle is a hobby project, and I quickly found that I was spending more time tweaking my gulpfile than writing actual code that would end up in the app. Not everything has to be perfect at the early stages. Get something that works and move forward. When you get annoyed enough by typing \u003ccode\u003enpm start\u003c/code\u003e and refreshing the browser, then figure out the next steps.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eThere a lot of ways to organize JavaScript code.\u003c/strong\u003e Firstly, JS has a lot of ways to create objects and a lot of different ways to implement inheritance. \u003ca href=\"http://stackoverflow.com/questions/5224295/javascript-the-good-parts-how-to-not-use-new-at-all\"\u003eThis is largely because the language has a classical syntax masking a distinctly non-classical mechanism\u003c/a\u003e. You can go read about this elsewhere, I won\u0026#39;t get into it. Later, Node introduced \u003ccode\u003erequire\u003c/code\u003e (and we have browserify on the front-end) so you can have as many or as few files as you like to organize all those non-classical class declarations. The choices on how to organize code can be overwhelming, especially for inexperienced developers. Again, this was something I just had to decide I had a \u0026quot;good enough\u0026quot; handle on at a certain point and move on with.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eGetting user accounts working with Express is hard.\u003c/strong\u003e This is probably why so many Node tutorials revolve around building things like real-time Twitter streams where sign-in wouldn\u0026#39;t be a requirement. In the really world, most everything on the web that a) has a back-end and b) needs something like Node as opposed to something like WordPress, is going to require accounts. Express leaves the choice of session management and login management tools up to the developer. While I loved the freedom express gives you in most instances, this was one thing that I wished worked out of the box. For a hobby project, I strongly recommend getting familiar with the database tools early before trying to tackle this.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eEmbrace JSX\u003c/strong\u003e. Like every developer before me who has encountered this bizarre mix of HTML and JavaScript, I had my reservations. But trust me: it does work, and it lets you envision front-end components as a unified whole where form fits function. (As a onetime biologist, this didn\u0026#39;t take long to feel natural.)\u003cbr /\u003e\u003cbr /\u003e \u003cimg src=\"http://i.imgur.com/01ofIfU.gif\" alt=\"The first time you see JSX code\" /\u003e\nThe first time you see JSX code.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eNPM Installs can go horribly wrong\u003c/strong\u003e. Monocle is running on a tiny Digital Ocean droplet also hosting this blog and powered by a hamster running on a little wheel (I assume). When I went to deploy it, I could not for the life of me figure out why \u003ccode\u003enpm install\u003c/code\u003e kept terminating without completing. Eventually I figured out that, considering the piddly amount of traffic I was expecting, this was probably the most memory intensive operation that would ever be run here. Eventually I found a tutorial on using swap files and the rest of install went smoothly.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe best thing about being a developer is getting try out new things. This is also its biggest challenge. Even this tiny app uses Express, gulp, React, flux, browserify. It was the most fun I\u0026#39;ve had building for a while.\u003c/p\u003e\n","md":"A blog post over at [Treehouse](http://blog.teamtreehouse.com/7-web-development-trends-for-2015) listed seven web development trends for 2015. At least five of them touched on React, so perhaps the article could be summarized as:\r\n\r\n\u003cblockquote\u003eReact, React, React, React, baked beans, React, and React.\u003c/blockquote\u003e\r\n\r\nJavaScript is hot right now. I am far from an expert on building big stuff with JavaScript, but I thought with the recent release of [Monocle](http://ncbi.site/) that I could give a little perspective on what I learned from a early release of my first fully-JS project.\r\n\r\nFor in-depth tutorials on getting a Node or React app running, I would point you to [Chris Buecheler](http://cwbuecheler.com/web/tutorials/2013/node-express-mongo/), [Scotch.io](https://scotch.io/tutorials/learning-react-getting-started-and-concepts), or [CodeMentor](https://www.codementor.io/reactjs/tutorial/react-js-flux-architecture-tutorial).\r\n\r\n1. **Build tools should be a time saver, not a time sink.** Monocle is a hobby project, and I quickly found that I was spending more time tweaking my gulpfile than writing actual code that would end up in the app. Not everything has to be perfect at the early stages. Get something that works and move forward. When you get annoyed enough by typing `npm start` and refreshing the browser, then figure out the next steps.\r\n\r\n1. **There a lot of ways to organize JavaScript code.** Firstly, JS has a lot of ways to create objects and a lot of different ways to implement inheritance. [This is largely because the language has a classical syntax masking a distinctly non-classical mechanism](http://stackoverflow.com/questions/5224295/javascript-the-good-parts-how-to-not-use-new-at-all). You can go read about this elsewhere, I won't get into it. Later, Node introduced `require` (and we have browserify on the front-end) so you can have as many or as few files as you like to organize all those non-classical class declarations. The choices on how to organize code can be overwhelming, especially for inexperienced developers. Again, this was something I just had to decide I had a \"good enough\" handle on at a certain point and move on with.\r\n\r\n1. **Getting user accounts working with Express is hard.** This is probably why so many Node tutorials revolve around building things like real-time Twitter streams where sign-in wouldn't be a requirement. In the really world, most everything on the web that a) has a back-end and b) needs something like Node as opposed to something like WordPress, is going to require accounts. Express leaves the choice of session management and login management tools up to the developer. While I loved the freedom express gives you in most instances, this was one thing that I wished worked out of the box. For a hobby project, I strongly recommend getting familiar with the database tools early before trying to tackle this.\r\n\r\n1. **Embrace JSX**. Like every developer before me who has encountered this bizarre mix of HTML and JavaScript, I had my reservations. But trust me: it does work, and it lets you envision front-end components as a unified whole where form fits function. (As a onetime biologist, this didn't take long to feel natural.)\u003cbr /\u003e\u003cbr /\u003e \u003cimg src=\"http://i.imgur.com/01ofIfU.gif\" alt=\"The first time you see JSX code\" /\u003e\r\nThe first time you see JSX code.\r\n\r\n1. **NPM Installs can go horribly wrong**. Monocle is running on a tiny Digital Ocean droplet also hosting this blog and powered by a hamster running on a little wheel (I assume). When I went to deploy it, I could not for the life of me figure out why `npm install` kept terminating without completing. Eventually I figured out that, considering the piddly amount of traffic I was expecting, this was probably the most memory intensive operation that would ever be run here. Eventually I found a tutorial on using swap files and the rest of install went smoothly.\r\n\r\nThe best thing about being a developer is getting try out new things. This is also its biggest challenge. Even this tiny app uses Express, gulp, React, flux, browserify. It was the most fun I've had building for a while."}},"publishedDate":{"$date":"2015-09-01T06:00:00.000Z"}}
{"_id":{"$oid":"5802ecd431c9af6010bb4fc7"},"slug":"readability-vs-instant-articles-how-does-content-save-itself","title":"Readability vs Instant Articles: how does Content save itself?","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eWhen I was in University there appeared - quite suddenly - new Thing called Napster, that allowed people to obtain Content (in this case audio files) for free; whereas just a few years before we had to pay for it. Or at least, the process of obtaining for free had previously been arduous enough that many were willing to pay for it.\u003c/p\u003e\n","md":"When I was in University there appeared - quite suddenly - new Thing called Napster, that allowed people to obtain Content (in this case audio files) for free; whereas just a few years before we had to pay for it. Or at least, the process of obtaining for free had previously been arduous enough that many were willing to pay for it."},"extended":{"html":"\u003cp\u003eWhen I was in University there appeared - quite suddenly - new Thing called Napster, that allowed people to obtain Content (in this case audio files) for free; whereas just a few years before we had to pay for it. Or at least, the process of obtaining for free had previously been arduous enough that many were willing to pay for it.\u003c/p\u003e\n\u003cp\u003eThis new Thing, we were told, was dangerous because so much Content was being obtained for free that it was threatening to destabalize an entire industry, and the Content Creators (musicians), failing to be adequately rewarded for their work, would undoubtedly stop Creating.\u003c/p\u003e\n\u003cp\u003eThen, almost as suddenly, a funny thing happened. After Napster disappeared, new ways of getting audio Content for \u003cem\u003ealmost\u003c/em\u003e free appeared, the music industry adjusted to its new normal and we all moved onto other things. The Internet in this instance was like smallpox: decimating an industry when it first arrived, quickly reaching equilibrium when it had been interacting with its hosts long enough. The lesson surely has to be that music fans \u003cem\u003eare\u003c/em\u003e willing to pay for music, just not as much as they once were, and not in formats that are by comparison awkward to use, not to mention carry around.\u003c/p\u003e\n\u003cp\u003eI have often felt the same is true of written content online. I - and I\u0026#39;m not alone in this - believe that content creators (journalists, or whomever) should be compensated, but that spending what we previously would have on newspaper subscriptions \u003cem\u003eonly in one place\u003c/em\u003e doesn\u0026#39;t work for us. We get our content from too many different sources, and so we pay for it the only way that we can - with eyeballs occasionally crossing paths with sponsored ads. I don\u0026#39;t so much mind the ads themselves: they were part of the newspaper industry long before the Internet anyway, but this business model has been slowly killing their industry. Less like smallpox and more like cancer.\u003c/p\u003e\n\u003cp\u003eA fair deal would be to find a way to pay for the content without the ads - ideally from as broad a base of content providers as possible. This is exactly experiment tried by \u003ca href=\"https://www.readability.com/\"\u003eReadability\u003c/a\u003e, a scraping and reformatting service that offered content providers a share of the subscription fees paid to them. The experiment failed - not because people didn\u0026#39;t use the paid version of Readability, \u003ca href=\"http://blog.readability.com/2012/06/announcement/\"\u003ebut because the content providers never showed up to collect their money\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSo imagine my surprise in the discussion surrounding Instant Articles. \u003ca href=\"http://instantarticles.fb.com/\"\u003eInstant Articles allows Facebook to host articles from content providers on their own platform\u003c/a\u003e. When you click on an article in your news feed, you\u0026#39;ll go to the Facebook-scraped version of the article instead of the content provider\u0026#39;s website. And how much is Facebook paying for this privilege? Nothing. The content providers are paying \u003cstrong\u003ethem\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eWhat possible gain could providers get from such a deal? The only possible revenue source is that the providers\u0026#39; ads will display along with the article. The ad-based business model that has been working so \u003cem\u003epoorly\u003c/em\u003e can only get worse (because the providers lose control of their own content, and with it the ability to link within their own site). The proposed advantage is that articles will load faster and have a more streamlined user experience than on the providers own website.\u003c/p\u003e\n\u003cp\u003eThis is of course exactly what Readability offered: the only difference being that Readability was paying \u003cem\u003ethem\u003c/em\u003e. It\u0026#39;s hard to escape the conclusion that content providers have in fact dug their own grave: they have created such terrible experiences for users that they are effectively paying Facebook to solve it for them. \u003c/p\u003e\n\u003cp\u003eThe main counter argument to this is that \u003ca href=\"http://www.theverge.com/2015/7/20/9002721/the-mobile-web-sucks\"\u003ethe web is just bad\u003c/a\u003e: slow and ill-suited for mobile. The Facebook app (or apps), at least on mobile, will be able to keep users in the native world when they navigate to an Instant Article, avoiding all the web\u0026#39;s problems. I can\u0026#39;t buy this. The web is, at it\u0026#39;s heart, a document delivery system, and there is nothing about reading a news article that needs to be heavy-weight or over-engineered. Of course if you ignore page performance mobile users will be the first to feel the pain. \u003ca href=\"http://ponyfoo.com/articles/fast-forwarding-the-web-platform\"\u003eOf course if you abuse the web, the web will perform poorly.\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eReadability made sense, was fair, and failed. Instant Articles is insane, unfair, and will probably succeed, if only because of the size and power of Facebook. (Yes, Google Reader also failed. But Google never interupted anyone\u0026#39;s web browsing with an offer to view the article on Reader). How do we save this?\u003c/p\u003e\n","md":"When I was in University there appeared - quite suddenly - new Thing called Napster, that allowed people to obtain Content (in this case audio files) for free; whereas just a few years before we had to pay for it. Or at least, the process of obtaining for free had previously been arduous enough that many were willing to pay for it.\r\n\r\nThis new Thing, we were told, was dangerous because so much Content was being obtained for free that it was threatening to destabalize an entire industry, and the Content Creators (musicians), failing to be adequately rewarded for their work, would undoubtedly stop Creating.\r\n\r\nThen, almost as suddenly, a funny thing happened. After Napster disappeared, new ways of getting audio Content for *almost* free appeared, the music industry adjusted to its new normal and we all moved onto other things. The Internet in this instance was like smallpox: decimating an industry when it first arrived, quickly reaching equilibrium when it had been interacting with its hosts long enough. The lesson surely has to be that music fans *are* willing to pay for music, just not as much as they once were, and not in formats that are by comparison awkward to use, not to mention carry around.\r\n\r\nI have often felt the same is true of written content online. I - and I'm not alone in this - believe that content creators (journalists, or whomever) should be compensated, but that spending what we previously would have on newspaper subscriptions *only in one place* doesn't work for us. We get our content from too many different sources, and so we pay for it the only way that we can - with eyeballs occasionally crossing paths with sponsored ads. I don't so much mind the ads themselves: they were part of the newspaper industry long before the Internet anyway, but this business model has been slowly killing their industry. Less like smallpox and more like cancer.\r\n\r\nA fair deal would be to find a way to pay for the content without the ads - ideally from as broad a base of content providers as possible. This is exactly experiment tried by [Readability](https://www.readability.com/), a scraping and reformatting service that offered content providers a share of the subscription fees paid to them. The experiment failed - not because people didn't use the paid version of Readability, [but because the content providers never showed up to collect their money](http://blog.readability.com/2012/06/announcement/).\r\n\r\nSo imagine my surprise in the discussion surrounding Instant Articles. [Instant Articles allows Facebook to host articles from content providers on their own platform](http://instantarticles.fb.com/). When you click on an article in your news feed, you'll go to the Facebook-scraped version of the article instead of the content provider's website. And how much is Facebook paying for this privilege? Nothing. The content providers are paying **them**.\r\n\r\nWhat possible gain could providers get from such a deal? The only possible revenue source is that the providers' ads will display along with the article. The ad-based business model that has been working so *poorly* can only get worse (because the providers lose control of their own content, and with it the ability to link within their own site). The proposed advantage is that articles will load faster and have a more streamlined user experience than on the providers own website.\r\n\r\nThis is of course exactly what Readability offered: the only difference being that Readability was paying *them*. It's hard to escape the conclusion that content providers have in fact dug their own grave: they have created such terrible experiences for users that they are effectively paying Facebook to solve it for them. \r\n\r\nThe main counter argument to this is that [the web is just bad](http://www.theverge.com/2015/7/20/9002721/the-mobile-web-sucks): slow and ill-suited for mobile. The Facebook app (or apps), at least on mobile, will be able to keep users in the native world when they navigate to an Instant Article, avoiding all the web's problems. I can't buy this. The web is, at it's heart, a document delivery system, and there is nothing about reading a news article that needs to be heavy-weight or over-engineered. Of course if you ignore page performance mobile users will be the first to feel the pain. [Of course if you abuse the web, the web will perform poorly.](http://ponyfoo.com/articles/fast-forwarding-the-web-platform)\r\n\r\nReadability made sense, was fair, and failed. Instant Articles is insane, unfair, and will probably succeed, if only because of the size and power of Facebook. (Yes, Google Reader also failed. But Google never interupted anyone's web browsing with an offer to view the article on Reader). How do we save this?"}},"publishedDate":{"$date":"2015-08-11T06:00:00.000Z"}}
{"_id":{"$oid":"5802ed5731c9af6010bb4fc8"},"slug":"why-i-am-against-mandatory-vaccinations","title":"Why I am against mandatory vaccinations","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eYou knew it would start to happen eventually. \u003ca href=\"http://www.cbc.ca/news/california-makes-vaccines-mandatory-for-schoolchildren-no-religious-exemptions-1.3133625\"\u003eCalifornia has passed a law effectively making vaccines mandatory\u003c/a\u003e, and \u003ca href=\"http://www.cbc.ca/news/canada/british-columbia/mandatory-childhood-vaccinations-supported-by-majority-in-b-c-and-alberta-poll-1.3106259\"\u003epolls suggest other jurisdictions may follow suit\u003c/a\u003e. California has essentially said that a minority of opponents should no longer be able to threaten the safety of the majority of vaccinators, let alone their own children. Perhaps the days of the anti-vaccine scourge are finally numbered. I, however, do not want it to happen this way.\u003c/p\u003e\n","md":"You knew it would start to happen eventually. [California has passed a law effectively making vaccines mandatory](http://www.cbc.ca/news/california-makes-vaccines-mandatory-for-schoolchildren-no-religious-exemptions-1.3133625), and [polls suggest other jurisdictions may follow suit](http://www.cbc.ca/news/canada/british-columbia/mandatory-childhood-vaccinations-supported-by-majority-in-b-c-and-alberta-poll-1.3106259). California has essentially said that a minority of opponents should no longer be able to threaten the safety of the majority of vaccinators, let alone their own children. Perhaps the days of the anti-vaccine scourge are finally numbered. I, however, do not want it to happen this way."},"extended":{"html":"\u003cp\u003eYou knew it would start to happen eventually. \u003ca href=\"http://www.cbc.ca/news/california-makes-vaccines-mandatory-for-schoolchildren-no-religious-exemptions-1.3133625\"\u003eCalifornia has passed a law effectively making vaccines mandatory\u003c/a\u003e, and \u003ca href=\"http://www.cbc.ca/news/canada/british-columbia/mandatory-childhood-vaccinations-supported-by-majority-in-b-c-and-alberta-poll-1.3106259\"\u003epolls suggest other jurisdictions may follow suit\u003c/a\u003e. California has essentially said that a minority of opponents should no longer be able to threaten the safety of the majority of vaccinators, let alone their own children. Perhaps the days of the anti-vaccine scourge are finally numbered. I, however, do not want it to happen this way.\u003c/p\u003e\n\u003cp\u003eTo be sure, I am vaccine zealot. I deliberately avoid, unfollow, and unfriend the anti-vax crowd, not because I don\u0026#39;t think they have a right to their opinion (they do), but because I find their deliberate, ignorant endangerment of public safety so repugnant that it interferes with my ability to think about other things. You cannot win an argument with an anti-vaxxer. Any data you cite, and actual evidence you might use in support of your argument is pharmeceutical company progoganda, which you\u0026#39;ve swallowed whole because you are sheeple. It\u0026#39;s lose-lose. Better not to play.\u003c/p\u003e\n\u003cp\u003eThe absurdity of the anti-vaxx movement can be revealed in one simple statement: \u0026quot;We aren\u0026#39;t anti-vaccine. We want safer schedules\u0026quot;. \u003cstrong\u003eIf you don\u0026#39;t believe the science, how would you go about designing a safer schedule?\u003c/strong\u003e What metric would you use to decide when a schedule is safe? When every study concludes that their is no measurable risk from the current schedule, how will you measure the reduction in the risk you think is there (even when it isn\u0026#39;t)?\u003c/p\u003e\n\u003cp\u003eI would personally benefit from mandatory vaccines. My daughter has an egg allery and getting a flu shot is an all-day event. How much simpler would it be to shuck the yearly ritual and trust in herd immunity instead.\u003c/p\u003e\n\u003cp\u003eI don\u0026#39;t want it to happen this way. Mandatory vaccinations, for all the good they will do, will no doubt convince the true believers that the pharmaceutical companies are even more powerful and influential than they ever imagined, that they have so much control over everyone\u0026#39;s lives that they can even force children to get needles stuck in them against their parents\u0026#39; own objections. And this would be very, very bad.\u003c/p\u003e\n\u003cp\u003eLast spring, a published study claiming that \u003ca href=\"http://io9.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800\"\u003echocolate helps you lose weight was published in a peer-reviewed scientific journal by journalist John Bohannon\u003c/a\u003e. The study, which was conducted on real human subjects and collected real data, was so deliberately flawed that it could not have actually been peer-reviewed, at least not by anyone knowledgable enough to be called a \u0026quot;peer\u0026quot;. Nevertheless - not surprisingly given the subject and conclusion - media outlets jumped all over it.\u003c/p\u003e\n\u003cp\u003eThe existence of the anti-vaccine movement is not the disease: it is the symptom of a much deeper problem. The movement traces it origins to a single, thoroughly discredited study published in the highly reputable journal The Lancet. We can talk about the failures in the editorial process that allowed it to get published way back in 1993. But the fact remains that, with tens of thousands of papers published in the biomedical literature each year, it WILL happen again.\u003c/p\u003e\n\u003cp\u003eIn fact, the very act of \u0026quot;publication\u0026quot; is so much easier and cheaper than it was in 1993 that it no doubt will happen MORE. Many scientific journals do not even offer a print version, do not copy edit, and in fact do little more than convert one type of PDF (manuscript) into another (pupblication). Yes, they oversee peer review, but they don\u0026#39;t DO it (in the overwhelming majority of cases, the peers are unpaid volunteers).\u003c/p\u003e\n\u003cp\u003eI believe that the rapid, cheap, and easy transmission of scientific knowledge is ultimately a good thing, and the benefits outweigh the costs. But whether you agree with me is moot: this mode of communication is here to stay. There will always be bad papers. There will always be bad journals. There will always be bottom-feeding media outlets willing to publish anything that seems like a good story, without fact-checking it.\u003c/p\u003e\n\u003cp\u003eThe simple reality is that the public will have to get used to bad information being out there. How we filter out the bad information from the good is a difficult question, but it\u0026#39;s one that I think we\u0026#39;re beginning to glimpse an answer to. While the Internet allows anyone to lie, it also talks back. Hack science writers like \u003ca href=\"http://www.slate.com/articles/health_and_science/science/2013/10/malcolm_gladwell_critique_david_and_goliath_misrepresents_the_science.html\"\u003eMalcolm Gladwell\u003c/a\u003e, \u003ca href=\"http://mediadecoder.blogs.nytimes.com/2012/07/30/jonah-lehrer-resigns-from-new-yorker-after-making-up-dylan-quotes-for-his-book/?_r=0\"\u003eJonah Lehrer\u003c/a\u003e and \u003ca href=\"http://www.slate.com/articles/health_and_science/science/2014/05/troublesome_inheritance_critique_nicholas_wade_s_dated_assumptions_about.html\"\u003eNicholas Wade\u003c/a\u003e can exposed as the lying frauds they are \u003cem\u003ebecause the conversation doesn\u0026#39;t end they publish\u003c/em\u003e. Felissa Wolfe-Simon, who one day might have leveraged her deeply-flawed \u003cem\u003eScience\u003c/em\u003e paper into a tenure-track job, was stopped in her tracks when \u003ca href=\"http://rrresearch.fieldofscience.com/2010/12/arsenic-associated-bacteria-nasas.html\"\u003eshe couldn\u0026#39;t answer her critics\u003c/a\u003e. And true scientific frauds are exposed every day through channels like \u003ca href=\"https://pubpeer.com/\"\u003ePubPeer\u003c/a\u003e, because the number of people who can peer-review a paper jumped from three to several hundred.\u003c/p\u003e\n\u003cp\u003eI am pro-vaccine not because I have studied that particular sub-field in great detail, but because the consensus of experts is overwhelmingly pro-vaccine. I have been around scientists long enough to know that most are NOT paid off by pharmaceutical companies and that a conspiracy among more than a handful of them is laughable. Mostly, I understand the scientific method well to understand how this trust in consensus differs from simple argument from authority.\u003c/p\u003e\n\u003cp\u003eI really have a great deal of faith in people\u0026#39;s ability to think for themselves. The Internet is still new - very new in the timescale of human history. We\u0026#39;ll get there. Have patience.\u003c/p\u003e\n","md":"You knew it would start to happen eventually. [California has passed a law effectively making vaccines mandatory](http://www.cbc.ca/news/california-makes-vaccines-mandatory-for-schoolchildren-no-religious-exemptions-1.3133625), and [polls suggest other jurisdictions may follow suit](http://www.cbc.ca/news/canada/british-columbia/mandatory-childhood-vaccinations-supported-by-majority-in-b-c-and-alberta-poll-1.3106259). California has essentially said that a minority of opponents should no longer be able to threaten the safety of the majority of vaccinators, let alone their own children. Perhaps the days of the anti-vaccine scourge are finally numbered. I, however, do not want it to happen this way.\r\n\r\nTo be sure, I am vaccine zealot. I deliberately avoid, unfollow, and unfriend the anti-vax crowd, not because I don't think they have a right to their opinion (they do), but because I find their deliberate, ignorant endangerment of public safety so repugnant that it interferes with my ability to think about other things. You cannot win an argument with an anti-vaxxer. Any data you cite, and actual evidence you might use in support of your argument is pharmeceutical company progoganda, which you've swallowed whole because you are sheeple. It's lose-lose. Better not to play.\r\n\r\nThe absurdity of the anti-vaxx movement can be revealed in one simple statement: \"We aren't anti-vaccine. We want safer schedules\". **If you don't believe the science, how would you go about designing a safer schedule?** What metric would you use to decide when a schedule is safe? When every study concludes that their is no measurable risk from the current schedule, how will you measure the reduction in the risk you think is there (even when it isn't)?\r\n\r\nI would personally benefit from mandatory vaccines. My daughter has an egg allery and getting a flu shot is an all-day event. How much simpler would it be to shuck the yearly ritual and trust in herd immunity instead.\r\n\r\nI don't want it to happen this way. Mandatory vaccinations, for all the good they will do, will no doubt convince the true believers that the pharmaceutical companies are even more powerful and influential than they ever imagined, that they have so much control over everyone's lives that they can even force children to get needles stuck in them against their parents' own objections. And this would be very, very bad.\r\n\r\nLast spring, a published study claiming that [chocolate helps you lose weight was published in a peer-reviewed scientific journal by journalist John Bohannon](http://io9.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800). The study, which was conducted on real human subjects and collected real data, was so deliberately flawed that it could not have actually been peer-reviewed, at least not by anyone knowledgable enough to be called a \"peer\". Nevertheless - not surprisingly given the subject and conclusion - media outlets jumped all over it.\r\n\r\nThe existence of the anti-vaccine movement is not the disease: it is the symptom of a much deeper problem. The movement traces it origins to a single, thoroughly discredited study published in the highly reputable journal The Lancet. We can talk about the failures in the editorial process that allowed it to get published way back in 1993. But the fact remains that, with tens of thousands of papers published in the biomedical literature each year, it WILL happen again.\r\n\r\nIn fact, the very act of \"publication\" is so much easier and cheaper than it was in 1993 that it no doubt will happen MORE. Many scientific journals do not even offer a print version, do not copy edit, and in fact do little more than convert one type of PDF (manuscript) into another (pupblication). Yes, they oversee peer review, but they don't DO it (in the overwhelming majority of cases, the peers are unpaid volunteers).\r\n\r\nI believe that the rapid, cheap, and easy transmission of scientific knowledge is ultimately a good thing, and the benefits outweigh the costs. But whether you agree with me is moot: this mode of communication is here to stay. There will always be bad papers. There will always be bad journals. There will always be bottom-feeding media outlets willing to publish anything that seems like a good story, without fact-checking it.\r\n\r\nThe simple reality is that the public will have to get used to bad information being out there. How we filter out the bad information from the good is a difficult question, but it's one that I think we're beginning to glimpse an answer to. While the Internet allows anyone to lie, it also talks back. Hack science writers like [Malcolm Gladwell](http://www.slate.com/articles/health_and_science/science/2013/10/malcolm_gladwell_critique_david_and_goliath_misrepresents_the_science.html), [Jonah Lehrer](http://mediadecoder.blogs.nytimes.com/2012/07/30/jonah-lehrer-resigns-from-new-yorker-after-making-up-dylan-quotes-for-his-book/?_r=0) and [Nicholas Wade](http://www.slate.com/articles/health_and_science/science/2014/05/troublesome_inheritance_critique_nicholas_wade_s_dated_assumptions_about.html) can exposed as the lying frauds they are *because the conversation doesn't end they publish*. Felissa Wolfe-Simon, who one day might have leveraged her deeply-flawed *Science* paper into a tenure-track job, was stopped in her tracks when [she couldn't answer her critics](http://rrresearch.fieldofscience.com/2010/12/arsenic-associated-bacteria-nasas.html). And true scientific frauds are exposed every day through channels like [PubPeer](https://pubpeer.com/), because the number of people who can peer-review a paper jumped from three to several hundred.\r\n\r\nI am pro-vaccine not because I have studied that particular sub-field in great detail, but because the consensus of experts is overwhelmingly pro-vaccine. I have been around scientists long enough to know that most are NOT paid off by pharmaceutical companies and that a conspiracy among more than a handful of them is laughable. Mostly, I understand the scientific method well to understand how this trust in consensus differs from simple argument from authority.\r\n\r\nI really have a great deal of faith in people's ability to think for themselves. The Internet is still new - very new in the timescale of human history. We'll get there. Have patience."}},"publishedDate":{"$date":"2015-07-01T06:00:00.000Z"}}
{"_id":{"$oid":"5802edb231c9af6010bb4fc9"},"slug":"the-new-peer-review-ecosystem","title":"The new peer review ecosystem","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI\u0026#39;ve blogged previously about the \u003ca href=\"/damn-you-reviewer-3-and-1-and-2/\"\u003eproblems I have with peer-review\u003c/a\u003e, especially about how \u003ca href=\"/clay-shirkys-cognitive-surplus-and-the-open-science-movement/\"\u003elower publication costs would seem to make pre-publication review unnecessary\u003c/a\u003e.\u003c/p\u003e\n","md":"I've blogged previously about the [problems I have with peer-review](/damn-you-reviewer-3-and-1-and-2/), especially about how [lower publication costs would seem to make pre-publication review unnecessary](/clay-shirkys-cognitive-surplus-and-the-open-science-movement/)."},"extended":{"html":"\u003cp\u003eI\u0026#39;ve blogged previously about the \u003ca href=\"/damn-you-reviewer-3-and-1-and-2/\"\u003eproblems I have with peer-review\u003c/a\u003e, especially about how \u003ca href=\"/clay-shirkys-cognitive-surplus-and-the-open-science-movement/\"\u003elower publication costs would seem to make pre-publication review unnecessary\u003c/a\u003e. But others have put it much better than me:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.michaeleisen.org/blog/?p=694#sthash.2dm7iUOr.dpuf\"\u003eFrom Michael Eisen\u0026#39;s blog:\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e[Peer review] is conservative, cumbersome, capricious and intrusive. It slows down the communication of new ideas and discoveries, while failing to accomplish most of what it purports to do. And, worst of all, the mythical veneer of peer review has created the perception that a handful of journals stand as gatekeepers of success in science, ceding undue power to them, and thereby stifling innovation in scientific communication.\u003c/blockquote\u003e\n\n\u003cp\u003e\u003ca href=\"http://breast-cancer-research.com/content/12/S4/S13\"\u003eFrom the journal \u003cem\u003eBreast Cancer Research:\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003ePeer review ... is an ineffective, slow, expensive, biased, inefficient, anti-innovatory ... easily abused lottery.\u003c/blockquote\u003e\n\n\u003cp\u003eThese are just the opinions of the authors, of course, but I think few would argue that the system needs a shake-up, at the very least. Here are some the ideas being tried out in the wild:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://f1000research.com/about\"\u003eF1000Research\u003c/a\u003e switches the ordering of peer-review and publication. Papers are accepted after a simple \u0026quot;sanity check\u0026quot; by the editors, and published (i.e. put online) immediately. Reviews are published alongside the paper as they come in. However, the paper is not indexed in PubMed until the reviewers are satisfied, so it does bare some similarity of pre-publication review, as well.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://about.scienceopen.com/how-does-it-work/\"\u003eScienceOpen\u003c/a\u003e also reviews after publication. They additionally focus on giving reviewers credit for their work, which should increase the quality of review in at least two ways. First, clever reviewers can be identified by their insight, and the removal of anonymity should discourage unhelpful \u0026quot;review trolls\u0026quot;.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.plosone.org/static/reviewerGuidelines#criteria\"\u003ePLOS One\u003c/a\u003e practices pre-publication peer-review, but asks reviewers not to consider the \u0026quot;impact\u0026quot; or \u0026quot;importance\u0026quot; of publications, instead focusing solely on the technical soundness of the paper. This sounds like common sense, actually. Even for glamour journals, I had always believed that the appropriateness of the paper should be the editors\u0026#39; call, and I\u0026#39;ve been continually surprised in my professional life at how much sway reviewers have in this area.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pubpeer.com/about\"\u003ePubPeer\u003c/a\u003e is not a journal at all, but indexes publications so that readers can leave comments on them. As Eisen points out, \u003ca href=\"http://www.michaeleisen.org/blog/?p=694\"\u003eserious technical problems are usually discovered long after publication\u003c/a\u003e, not before. More than any other group, PubPeer has made it clear that scientific communication is now a two-way street: \u003ca href=\"http://news.sciencemag.org/health/2014/02/high-profile-stem-cell-papers-under-fire\"\u003ereaders talk back\u003c/a\u003e. In a startling inability to accept this reality, \u003ca href=\"http://www.wired.com/2014/12/pubpeer-fights-for-anonymity/\"\u003ea prominent cancer researcher recently sued PubPeer\u0026#39;s anonymous readers for defamation\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.ncbi.nlm.nih.gov/pubmedcommons/faq/\"\u003ePubMed Commons\u003c/a\u003e is a forum for comments, just like PubPeer, but reviewers are not anonymous (in fact, they must have a published paper in the PubMed database). A possible advantage is that comments are displayed next to the PubMed abstract, the most commonly-used literature search tool in the biomedical field.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://axiosreview.org/the-process/why-axios/\"\u003eAxios Review\u003c/a\u003e has perhaps the most innovative idea: they are a private company that will charge authors a fee to solicit reviews. By performing the review first, they can better judge which journals are likely to accept the paper. Then they pass the paper and the reviews along to various target journals. This speeds up the publication process by wasting less time.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOne last idea which deserves special mention is \u003cem\u003eNature Publishing Group\u0026#39;s\u003c/em\u003e recently announced plan to \u003ca href=\"http://blogs.nature.com/ofschemesandmemes/2015/03/27/further-experiments-in-peer-review\"\u003efast-track peer review for authors that pay a fee\u003c/a\u003e. For sure, both Axios and \u003cem\u003eNature\u003c/em\u003e have identified a pain-point and found a solution driven by market incentives. The fact that both are making a buck should not cause us to dismiss them out-of-hand. While this promises to solve only one problem with peer-review in its current form, a greater diversity of ideas is probably for the best as we figure out what will work going forward. Because the one thing we know \u003cem\u003ewon\u0026#39;t\u003c/em\u003e work anymore is what we have now.\u003c/p\u003e\n\u003cp\u003eI apologize if I missed anyone: please chime in in the comments.\u003c/p\u003e\n","md":"I've blogged previously about the [problems I have with peer-review](/damn-you-reviewer-3-and-1-and-2/), especially about how [lower publication costs would seem to make pre-publication review unnecessary](/clay-shirkys-cognitive-surplus-and-the-open-science-movement/). But others have put it much better than me:\r\n\r\n[From Michael Eisen's blog:](http://www.michaeleisen.org/blog/?p=694#sthash.2dm7iUOr.dpuf)\r\n\u003cblockquote\u003e[Peer review] is conservative, cumbersome, capricious and intrusive. It slows down the communication of new ideas and discoveries, while failing to accomplish most of what it purports to do. And, worst of all, the mythical veneer of peer review has created the perception that a handful of journals stand as gatekeepers of success in science, ceding undue power to them, and thereby stifling innovation in scientific communication.\u003c/blockquote\u003e\r\n\r\n[From the journal *Breast Cancer Research:*](http://breast-cancer-research.com/content/12/S4/S13)\r\n\u003cblockquote\u003ePeer review ... is an ineffective, slow, expensive, biased, inefficient, anti-innovatory ... easily abused lottery.\u003c/blockquote\u003e\r\n\r\nThese are just the opinions of the authors, of course, but I think few would argue that the system needs a shake-up, at the very least. Here are some the ideas being tried out in the wild:\r\n\r\n- [F1000Research](http://f1000research.com/about) switches the ordering of peer-review and publication. Papers are accepted after a simple \"sanity check\" by the editors, and published (i.e. put online) immediately. Reviews are published alongside the paper as they come in. However, the paper is not indexed in PubMed until the reviewers are satisfied, so it does bare some similarity of pre-publication review, as well.\r\n- [ScienceOpen](http://about.scienceopen.com/how-does-it-work/) also reviews after publication. They additionally focus on giving reviewers credit for their work, which should increase the quality of review in at least two ways. First, clever reviewers can be identified by their insight, and the removal of anonymity should discourage unhelpful \"review trolls\".\r\n- [PLOS One](http://www.plosone.org/static/reviewerGuidelines#criteria) practices pre-publication peer-review, but asks reviewers not to consider the \"impact\" or \"importance\" of publications, instead focusing solely on the technical soundness of the paper. This sounds like common sense, actually. Even for glamour journals, I had always believed that the appropriateness of the paper should be the editors' call, and I've been continually surprised in my professional life at how much sway reviewers have in this area.\r\n- [PubPeer](https://pubpeer.com/about) is not a journal at all, but indexes publications so that readers can leave comments on them. As Eisen points out, [serious technical problems are usually discovered long after publication](http://www.michaeleisen.org/blog/?p=694), not before. More than any other group, PubPeer has made it clear that scientific communication is now a two-way street: [readers talk back](http://news.sciencemag.org/health/2014/02/high-profile-stem-cell-papers-under-fire). In a startling inability to accept this reality, [a prominent cancer researcher recently sued PubPeer's anonymous readers for defamation](http://www.wired.com/2014/12/pubpeer-fights-for-anonymity/).\r\n- [PubMed Commons](http://www.ncbi.nlm.nih.gov/pubmedcommons/faq/) is a forum for comments, just like PubPeer, but reviewers are not anonymous (in fact, they must have a published paper in the PubMed database). A possible advantage is that comments are displayed next to the PubMed abstract, the most commonly-used literature search tool in the biomedical field.\r\n- [Axios Review](https://axiosreview.org/the-process/why-axios/) has perhaps the most innovative idea: they are a private company that will charge authors a fee to solicit reviews. By performing the review first, they can better judge which journals are likely to accept the paper. Then they pass the paper and the reviews along to various target journals. This speeds up the publication process by wasting less time.\r\n\r\nOne last idea which deserves special mention is *Nature Publishing Group's* recently announced plan to [fast-track peer review for authors that pay a fee](http://blogs.nature.com/ofschemesandmemes/2015/03/27/further-experiments-in-peer-review). For sure, both Axios and *Nature* have identified a pain-point and found a solution driven by market incentives. The fact that both are making a buck should not cause us to dismiss them out-of-hand. While this promises to solve only one problem with peer-review in its current form, a greater diversity of ideas is probably for the best as we figure out what will work going forward. Because the one thing we know *won't* work anymore is what we have now.\r\n\r\nI apologize if I missed anyone: please chime in in the comments."}},"publishedDate":{"$date":"2015-04-27T06:00:00.000Z"}}
{"_id":{"$oid":"5802ee0b31c9af6010bb4fca"},"slug":"book-review-web-development-with-node-and-express","title":"Book Review: Web Development  with Node and Express","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eEven among the bewilidering array of backend web languages and frameworks, Node.js stands alone. It isn\u0026#39;t a language - it\u0026#39;s just an implementation of Javascript, and is it isn\u0026#39;t really a framework, either. At it\u0026#39;s most basic level, it feels more like a Javascript API for configuring a server. \u003c/p\u003e\n","md":"Even among the bewilidering array of backend web languages and frameworks, Node.js stands alone. It isn't a language - it's just an implementation of Javascript, and is it isn't really a framework, either. At it's most basic level, it feels more like a Javascript API for configuring a server. "},"extended":{"html":"\u003cp\u003eEven among the bewilidering array of backend web languages and frameworks, Node.js stands alone. It isn\u0026#39;t a language - it\u0026#39;s just an implementation of Javascript, and is it isn\u0026#39;t really a framework, either. At it\u0026#39;s most basic level, it feels more like a Javascript API for configuring a server. \u003c/p\u003e\n\u003cp\u003eExpress is integral to most Node applications in that it  sits on top and enforces a more familiar MVC-like structure. At the heart of Express are routes - functions that take an HTTP request and turn it into a response. They are (almost) equivalent to Views in Django and felt much more familiar to me. Add in database interaction on one side and HTML templating on the other and you have everything you need.\u003c/p\u003e\n\u003cp\u003eChris Bucheler (\u003ca href=\"https://twitter.com/cwbuecheler\"\u003e@cwbucheler\u003c/a\u003e) has a \u003ca href=\"http://cwbuecheler.com/web/tutorials/2013/node-express-mongo/\"\u003ebeautiful tutorial\u003c/a\u003e putting the whole stack togther into a functioning website. If he could have written a 306 page book, I\u0026#39;m sure it would have told me all I need to know to get started with Node.\u003c/p\u003e\n\u003cp\u003eBut he didn\u0026#39;t. Instead, \u0026quot;Node and Express\u0026quot; is meandering, and  frustratingly thin where it counts. For example, a chapter on \u0026quot;Security\u0026quot; devotes 18 pages to HTTPS, the basics of authentication, problems with the overabundance of passwords on the Internet (and introduces OAuth as a strategic alternative), before getting into how to set up basic authentication (using the npm module passport). These are no doubt important issues, but they aren\u0026#39;t critical reading for people who have experience with other platforms and/or who just need to get a prototype up and running. \u003c/p\u003e\n\u003cp\u003eAnother chapter is called Persistence and covers that topic in a somewhat academic way, which would be fine if it wasn\u0026#39;t the \u003cem\u003eonly\u003c/em\u003e information on interacting with MongoDB in the whole book. Mongo peculiarities like atomic queries and upserts are glossed over so fast that you can\u0026#39;t do much apart from reproduce the examples in the book.\u003c/p\u003e\n\u003cp\u003ePart of this isn\u0026#39;t so much a flaw in the book as it is the challenge of the source material. By design, Node (and Express) don\u0026#39;t have many particular dependencies. So Mongo, passport and similar resources that tend to get used with Express are not really part of Express itself. This means that, strictly speaking, they might be \u0026quot;out of scope\u0026quot; as far as a book on Express is concerned.\u003c/p\u003e\n\u003cp\u003eStill, while the modularity of Node is wise (I don\u0026#39;t like Jade, and am glad Express doesn\u0026#39;t force it on you), there has to some concession for those of us just starting out. I could use a bit more on Mongo to build even a really simple Express app, and I suspect most beginning Node developers are in the same boat.\u003c/p\u003e\n\u003cp\u003e\u0026quot;Web Development with Node and Express: Leveraging the Javascipt Stack\u0026quot; is written by Ethan Brown, published by O\u0026#39;Rielly, and available at \u003ca href=\"http://www.amazon.com/Web-Development-Node-Express-Leveraging/dp/1491949309/\"\u003eAmazon\u003c/a\u003e.\u003c/p\u003e\n","md":"Even among the bewilidering array of backend web languages and frameworks, Node.js stands alone. It isn't a language - it's just an implementation of Javascript, and is it isn't really a framework, either. At it's most basic level, it feels more like a Javascript API for configuring a server. \r\n\r\nExpress is integral to most Node applications in that it  sits on top and enforces a more familiar MVC-like structure. At the heart of Express are routes - functions that take an HTTP request and turn it into a response. They are (almost) equivalent to Views in Django and felt much more familiar to me. Add in database interaction on one side and HTML templating on the other and you have everything you need.\r\n\r\nChris Bucheler ([@cwbucheler](https://twitter.com/cwbuecheler)) has a [beautiful tutorial](http://cwbuecheler.com/web/tutorials/2013/node-express-mongo/) putting the whole stack togther into a functioning website. If he could have written a 306 page book, I'm sure it would have told me all I need to know to get started with Node.\r\n\r\nBut he didn't. Instead, \"Node and Express\" is meandering, and  frustratingly thin where it counts. For example, a chapter on \"Security\" devotes 18 pages to HTTPS, the basics of authentication, problems with the overabundance of passwords on the Internet (and introduces OAuth as a strategic alternative), before getting into how to set up basic authentication (using the npm module passport). These are no doubt important issues, but they aren't critical reading for people who have experience with other platforms and/or who just need to get a prototype up and running. \r\n\r\nAnother chapter is called Persistence and covers that topic in a somewhat academic way, which would be fine if it wasn't the *only* information on interacting with MongoDB in the whole book. Mongo peculiarities like atomic queries and upserts are glossed over so fast that you can't do much apart from reproduce the examples in the book.\r\n\r\nPart of this isn't so much a flaw in the book as it is the challenge of the source material. By design, Node (and Express) don't have many particular dependencies. So Mongo, passport and similar resources that tend to get used with Express are not really part of Express itself. This means that, strictly speaking, they might be \"out of scope\" as far as a book on Express is concerned.\r\n\r\nStill, while the modularity of Node is wise (I don't like Jade, and am glad Express doesn't force it on you), there has to some concession for those of us just starting out. I could use a bit more on Mongo to build even a really simple Express app, and I suspect most beginning Node developers are in the same boat.\r\n\r\n\"Web Development with Node and Express: Leveraging the Javascipt Stack\" is written by Ethan Brown, published by O'Rielly, and available at [Amazon](http://www.amazon.com/Web-Development-Node-Express-Leveraging/dp/1491949309/)."}},"publishedDate":{"$date":"2015-04-15T06:00:00.000Z"}}
{"_id":{"$oid":"5802eeed31c9af6010bb4fcb"},"slug":"where-as-once-i-was-blind","title":"Where as once I was blind","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eOnce, there was zealotry, and anger, and war. Once, humans were petty and closed-minded, unable to accept to accept that the world could be different from how they saw it.\u003c/p\u003e\n\u003cp\u003eNo one knows where The Dress came from. No one knows who\u0026#39;s Dress it was. No one knows who made it, or whether it was ever a real dress, or just a picture. But when we saw it, we truly saw for the first time.\u003c/p\u003e\n","md":"Once, there was zealotry, and anger, and war. Once, humans were petty and closed-minded, unable to accept to accept that the world could be different from how they saw it.\r\n\r\nNo one knows where The Dress came from. No one knows who's Dress it was. No one knows who made it, or whether it was ever a real dress, or just a picture. But when we saw it, we truly saw for the first time.\r\n"},"extended":{"html":"\u003cp\u003eOnce, there was zealotry, and anger, and war. Once, humans were petty and closed-minded, unable to accept to accept that the world could be different from how they saw it.\u003c/p\u003e\n\u003cp\u003eNo one knows where The Dress came from. No one knows who\u0026#39;s Dress it was. No one knows who made it, or whether it was ever a real dress, or just a picture. But when we saw it, we truly saw for the first time.\u003c/p\u003e\n\u003cp\u003eThis was in the Year One, of course, but we didn\u0026#39;t call it the Year One. At that time it was called 2015 AD, but AD didn\u0026#39;t mean \u0026quot;after the Dress\u0026quot; as it does now. I don\u0026#39;t recall what it did mean.\u003c/p\u003e\n\u003cp\u003eBefore the Dress, many people believed that their view of the world was the only one that mattered. Some even went so far as to say that all those who disagreed with them would suffer eternally after they died. The Dress taught us that God can take many forms, that there are many paths to understanding.\u003c/p\u003e\n\u003cp\u003eBefore the Dress, to govern a democratic Nation you had to convince voters that your politcal opponents would destroy everything they loved, because their view of the world was so wrong-headed. The Dress taught us to govern by consensus and compromise, whenever possible.\u003c/p\u003e\n\u003cp\u003eBefore the Dress, we believed that those who told us things that didn\u0026#39;t fit our personal experience were liars, or were victims of propoganda, or motivated by profit. Because of the Dress, we learned to accept science and deductive reasoning, even when the results were strange or uncomforatable. \u003c/p\u003e\n\u003cp\u003eWhen we first saw the Dress, we were confused. Our blindness prevented us from perceiving what what was right in front of us. But then, we were saved.\u003c/p\u003e\n","md":"Once, there was zealotry, and anger, and war. Once, humans were petty and closed-minded, unable to accept to accept that the world could be different from how they saw it.\r\n\r\nNo one knows where The Dress came from. No one knows who's Dress it was. No one knows who made it, or whether it was ever a real dress, or just a picture. But when we saw it, we truly saw for the first time.\r\n\r\nThis was in the Year One, of course, but we didn't call it the Year One. At that time it was called 2015 AD, but AD didn't mean \"after the Dress\" as it does now. I don't recall what it did mean.\r\n\r\nBefore the Dress, many people believed that their view of the world was the only one that mattered. Some even went so far as to say that all those who disagreed with them would suffer eternally after they died. The Dress taught us that God can take many forms, that there are many paths to understanding.\r\n\r\nBefore the Dress, to govern a democratic Nation you had to convince voters that your politcal opponents would destroy everything they loved, because their view of the world was so wrong-headed. The Dress taught us to govern by consensus and compromise, whenever possible.\r\n\r\nBefore the Dress, we believed that those who told us things that didn't fit our personal experience were liars, or were victims of propoganda, or motivated by profit. Because of the Dress, we learned to accept science and deductive reasoning, even when the results were strange or uncomforatable. \r\n\r\nWhen we first saw the Dress, we were confused. Our blindness prevented us from perceiving what what was right in front of us. But then, we were saved."}},"publishedDate":{"$date":"2015-02-28T07:00:00.000Z"}}
{"_id":{"$oid":"5802f09331c9af6010bb4fcc"},"slug":"adding-a-custom-snazzy-map-to-wordpress","title":"Adding a custom Snazzy Map to WordPress","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eDesigners are incurable perfectionists. They always seem to want things that push just beyond what the current tools we as developers have available.\u003c/p\u003e\n\u003cp\u003eUntil recently, outside widgets like Google Maps gave us a line in the sand. So that blue that Google uses for water doesn\u0026#39;t quite match the blue in the logo? Too bad. Either use what we\u0026#39;ve got, or scrap that map and make a JPG.\u003c/p\u003e\n","md":"Designers are incurable perfectionists. They always seem to want things that push just beyond what the current tools we as developers have available.\r\n\r\nUntil recently, outside widgets like Google Maps gave us a line in the sand. So that blue that Google uses for water doesn't quite match the blue in the logo? Too bad. Either use what we've got, or scrap that map and make a JPG."},"extended":{"html":"\u003cp\u003eDesigners are incurable perfectionists. They always seem to want things that push just beyond what the current tools we as developers have available.\u003c/p\u003e\n\u003cp\u003eUntil recently, outside widgets like Google Maps gave us a line in the sand. So that blue that Google uses for water doesn\u0026#39;t quite match the blue in the logo? Too bad. Either use what we\u0026#39;ve got, or scrap that map and make a JPG.\u003c/p\u003e\n\u003cp\u003eWell, designers can celebrate (and developers curse) the arrival of Snazzy Maps. \u003ca href=\"https://snazzymaps.com/editor\"\u003eSnazzyMaps\u003c/a\u003e (an Edmonton company!) allows you to build your own styles using a WYSIWYG editor, then export the style information as JSON code. This can be interpreted by the Google Maps JavaScript API to apply the same styling to any map.\u003c/p\u003e\n\u003cp\u003eHere I will go over how to integrate a Google Map with custom styling into a WordPress site, but much of what I include will apply to any website. There are also a couple of premium plugins that work with SnazzyMaps, but I prefer the home-baked solution below.\u003c/p\u003e\n\u003cp\u003eHere are a \u003ca href=\"http://www.k-brolinen.com/contact-us/\"\u003ecouple\u003c/a\u003e \u003ca href=\"http://www.ascensionchiro.ca/\"\u003edifferent\u003c/a\u003e \u003ca href=\"http://www.seventhstreetdental.ca/\"\u003eexamples\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"le-html\"\u003eLe HTML\u003c/h2\u003e\n\u003cp\u003eFirst off, we need to create a container for our Google Map. Generally, this is just a div with an explicit width and height (because it will be empty to start) and an ID (or class) to act as a JavaScript hook.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-markup\"\u003e\u0026lt;div id=\u0026quot;the-map\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNote that you usually need to add an explicit height for this element in CSS, since it\u0026#39;s empty when the page loads.\u003c/p\u003e\n\u003ch2 id=\"le-javascript\"\u003eLe JavaScript\u003c/h2\u003e\n\u003cp\u003eFirst we need to include both the Google Javascript file and a custom Javascript file to fire the API. The best way to do this in WordPress is to use \u003ccode\u003ewp_enqueue_script\u003c/code\u003e. \u003c/p\u003e\n\u003cp\u003eIn \u003ccode\u003efunctions.php\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-php\"\u003e\u0026lt;?php\n    add_action(\u0026#39;wp_enqueue_scripts\u0026#39;, \u0026#39;my_enqueue_scripts\u0026#39;);\n    function my_enqueue_scripts() {\n        wp_enqueue_script(\u0026#39;google-maps\u0026#39;, \u0026#39;https://maps.googleapis.com/maps/api/js?v=3\u0026amp;sensor=false\u0026#39;, array(), null, true);\n        wp_enqueue_script(\u0026#39;script\u0026#39;, get_stylesheet_directory_uri() . \u0026#39;/js/script.js\u0026#39;, array(\u0026#39;google-maps\u0026#39;), null, true);\n    }\n?\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe second enqueued script will be our main javascript file used for setting up Google maps. Calling the Google Maps API is extremely simple, depending on the level of customization. The biggest thing to decide at this stage is where the map will be centered and how \u0026quot;zoomed-in\u0026quot; it will be. The full documentation for including a Google map can be found at \u003ca href=\"https://developers.google.com/maps/documentation/javascript/tutorial\"\u003edevelopers.google.com\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIn \u003ccode\u003escript.js\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction makeMap() {\n  var map = new google.maps.Map(document.getElementById(\u0026#39;the-map\u0026#39;), {\n      center : new google.maps.LatLng(49.278094, -122.919883),\n      zoom : 13,\n      mapTypeId : google.maps.MapTypeId.ROADMAP,\n      disableDefaultUI: true\n  });\n  var marker = new google.maps.Marker({\n      position : new google.maps.LatLng(49.278094, -122.919883)\n  });\n  marker.setMap(map);\n}\ngoogle.maps.event.addDomListener(window, \u0026#39;load\u0026#39;, makeMap);\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"adding-snazzymaps-styling\"\u003eAdding SnazzyMaps Styling\u003c/h2\u003e\n\u003cp\u003eCustom styles can be passed directly into the Google maps object. Snazzy maps outputs these styles as JSON code which can be parsed in JavaScript and passed in. But where should the JSON code go? Javascript generally doesn\u0026#39;t like multi-line strings, and the compressed JSON is going to be ugly. Adding it directly to a JS file combines style and functionality, something that developers should try to avoid.\u003c/p\u003e\n\u003cp\u003eThere are probably several good ways of accomplishing this, but I want to share one method that achieves very clean seperation of information. It uses the little known WordPress function \u003ccode\u003ewp_localize_script\u003c/code\u003e. This is an extremely useful function which allows us to pass data from PHP to JavaScript without awkwardly storing it in HTML (for example, in a hidden element).\u003c/p\u003e\n\u003cp\u003eLets copy and paste the JSON from SnazzyMaps into a file called \u003ccode\u003emap_style.json\u003c/code\u003e and save it in the same directory as \u003ccode\u003efunctions.php\u003c/code\u003e. Then, lets add to our \u003ccode\u003emy_enqueue_scripts\u003c/code\u003e function:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-php\"\u003e\u0026lt;?php\n    add_action(\u0026#39;wp_enqueue_scripts\u0026#39;, \u0026#39;my_enqueue_scripts\u0026#39;);\n    function my_enqueue_scripts() {\n        wp_enqueue_script(\u0026#39;google-maps\u0026#39;, \u0026#39;https://maps.googleapis.com/maps/api/js?v=3\u0026amp;sensor=false\u0026#39;, array(), null, true);\n        wp_enqueue_script(\u0026#39;script\u0026#39;, get_stylesheet_directory_uri() . \u0026#39;/js/script.js\u0026#39;, array(\u0026#39;google-maps\u0026#39;), null, true);\n        wp_localize_script( \u0026#39;script\u0026#39;, \u0026#39;wpGlobals\u0026#39;, array(\n            \u0026#39;mapOptions\u0026#39; =\u0026gt; file_get_contents( dirname(__FILE__) . \u0026#39;/map_style.json\u0026#39; )\n          ) );\n    }\n?\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLoad the relevant page, then open up a console and type \u003ccode\u003ewpGlobals\u003c/code\u003e. The console should return \u003ccode\u003e{ mapOptions :\u003c/code\u003e and then a long string representing the map styles we created. Finally, let\u0026#39;s modify the Javascript code from above:\u003c/p\u003e\n\u003cp\u003eIn \u003ccode\u003escript.js\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003efunction makeMap() {\n  var snazzyMap = JSON.parse(wpGlobals.mapOptions);\n  var map = new google.maps.Map(document.getElementById(\u0026#39;the-map\u0026#39;), {\n      center : new google.maps.LatLng(49.278094, -122.919883),\n      zoom : 13,\n      mapTypeId : google.maps.MapTypeId.ROADMAP,\n      disableDefaultUI: true,\n      styles : snazzyMap\n  });\n  var marker = new google.maps.Marker({\n      position : new google.maps.LatLng(49.278094, -122.919883)\n  });\n  marker.setMap(map);\n}\ngoogle.maps.event.addDomListener(window, \u0026#39;load\u0026#39;, makeMap);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eUPDATE FEB 26th: Big thanks to David Rizzuto (\u003ca href=\"https://twitter.com/davidrizzuto\"\u003e@davidrizutto\u003c/a\u003e) for his comments below. I\u0026#39;ve fixed a couple of mistakes and clarified some other things.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eUPDATE SEPT 8th: Additional thanks to @teejK who noticed I was using the experimental version of Google Maps.\u003c/strong\u003e\u003c/p\u003e\n","md":"Designers are incurable perfectionists. They always seem to want things that push just beyond what the current tools we as developers have available.\r\n\r\nUntil recently, outside widgets like Google Maps gave us a line in the sand. So that blue that Google uses for water doesn't quite match the blue in the logo? Too bad. Either use what we've got, or scrap that map and make a JPG.\r\n\r\nWell, designers can celebrate (and developers curse) the arrival of Snazzy Maps. [SnazzyMaps](https://snazzymaps.com/editor) (an Edmonton company!) allows you to build your own styles using a WYSIWYG editor, then export the style information as JSON code. This can be interpreted by the Google Maps JavaScript API to apply the same styling to any map.\r\n\r\nHere I will go over how to integrate a Google Map with custom styling into a WordPress site, but much of what I include will apply to any website. There are also a couple of premium plugins that work with SnazzyMaps, but I prefer the home-baked solution below.\r\n\r\nHere are a [couple](http://www.k-brolinen.com/contact-us/) [different](http://www.ascensionchiro.ca/) [examples](http://www.seventhstreetdental.ca/).\r\n\r\n## Le HTML\r\n\r\nFirst off, we need to create a container for our Google Map. Generally, this is just a div with an explicit width and height (because it will be empty to start) and an ID (or class) to act as a JavaScript hook.\r\n\r\n```markup\r\n\u003cdiv id=\"the-map\"\u003e\u003c/div\u003e\r\n```\r\n\r\nNote that you usually need to add an explicit height for this element in CSS, since it's empty when the page loads.\r\n\r\n\r\n## Le JavaScript\r\n\r\nFirst we need to include both the Google Javascript file and a custom Javascript file to fire the API. The best way to do this in WordPress is to use `wp_enqueue_script`. \r\n\r\nIn `functions.php`:\r\n\r\n```php\r\n\u003c?php\r\n    add_action('wp_enqueue_scripts', 'my_enqueue_scripts');\r\n    function my_enqueue_scripts() {\r\n        wp_enqueue_script('google-maps', 'https://maps.googleapis.com/maps/api/js?v=3\u0026sensor=false', array(), null, true);\r\n        wp_enqueue_script('script', get_stylesheet_directory_uri() . '/js/script.js', array('google-maps'), null, true);\r\n    }\r\n?\u003e\r\n```\r\n\r\nThe second enqueued script will be our main javascript file used for setting up Google maps. Calling the Google Maps API is extremely simple, depending on the level of customization. The biggest thing to decide at this stage is where the map will be centered and how \"zoomed-in\" it will be. The full documentation for including a Google map can be found at [developers.google.com](https://developers.google.com/maps/documentation/javascript/tutorial).\r\n\r\nIn `script.js`:\r\n\r\n```javascript\r\nfunction makeMap() {\r\n  var map = new google.maps.Map(document.getElementById('the-map'), {\r\n      center : new google.maps.LatLng(49.278094, -122.919883),\r\n      zoom : 13,\r\n      mapTypeId : google.maps.MapTypeId.ROADMAP,\r\n      disableDefaultUI: true\r\n  });\r\n  var marker = new google.maps.Marker({\r\n      position : new google.maps.LatLng(49.278094, -122.919883)\r\n  });\r\n  marker.setMap(map);\r\n}\r\ngoogle.maps.event.addDomListener(window, 'load', makeMap);\r\n```\r\n\r\n## Adding SnazzyMaps Styling\r\n\r\nCustom styles can be passed directly into the Google maps object. Snazzy maps outputs these styles as JSON code which can be parsed in JavaScript and passed in. But where should the JSON code go? Javascript generally doesn't like multi-line strings, and the compressed JSON is going to be ugly. Adding it directly to a JS file combines style and functionality, something that developers should try to avoid.\r\n\r\nThere are probably several good ways of accomplishing this, but I want to share one method that achieves very clean seperation of information. It uses the little known WordPress function `wp_localize_script`. This is an extremely useful function which allows us to pass data from PHP to JavaScript without awkwardly storing it in HTML (for example, in a hidden element).\r\n\r\nLets copy and paste the JSON from SnazzyMaps into a file called `map_style.json` and save it in the same directory as `functions.php`. Then, lets add to our `my_enqueue_scripts` function:\r\n\r\n```php\r\n\u003c?php\r\n    add_action('wp_enqueue_scripts', 'my_enqueue_scripts');\r\n    function my_enqueue_scripts() {\r\n        wp_enqueue_script('google-maps', 'https://maps.googleapis.com/maps/api/js?v=3\u0026sensor=false', array(), null, true);\r\n        wp_enqueue_script('script', get_stylesheet_directory_uri() . '/js/script.js', array('google-maps'), null, true);\r\n        wp_localize_script( 'script', 'wpGlobals', array(\r\n        \u0009'mapOptions' =\u003e file_get_contents( dirname(__FILE__) . '/map_style.json' )\r\n          ) );\r\n    }\r\n?\u003e\r\n```\r\n\r\nLoad the relevant page, then open up a console and type `wpGlobals`. The console should return `{ mapOptions : ` and then a long string representing the map styles we created. Finally, let's modify the Javascript code from above:\r\n\r\nIn `script.js`:\r\n\r\n```javascript\r\nfunction makeMap() {\r\n  var snazzyMap = JSON.parse(wpGlobals.mapOptions);\r\n  var map = new google.maps.Map(document.getElementById('the-map'), {\r\n      center : new google.maps.LatLng(49.278094, -122.919883),\r\n      zoom : 13,\r\n      mapTypeId : google.maps.MapTypeId.ROADMAP,\r\n      disableDefaultUI: true,\r\n      styles : snazzyMap\r\n  });\r\n  var marker = new google.maps.Marker({\r\n      position : new google.maps.LatLng(49.278094, -122.919883)\r\n  });\r\n  marker.setMap(map);\r\n}\r\ngoogle.maps.event.addDomListener(window, 'load', makeMap);\r\n```\r\n\r\n**UPDATE FEB 26th: Big thanks to David Rizzuto ([@davidrizutto](https://twitter.com/davidrizzuto)) for his comments below. I've fixed a couple of mistakes and clarified some other things.**\r\n\r\n**UPDATE SEPT 8th: Additional thanks to @teejK who noticed I was using the experimental version of Google Maps.**"}},"publishedDate":{"$date":"2015-02-15T07:00:00.000Z"}}
{"_id":{"$oid":"5802f11931c9af6010bb4fcd"},"slug":"nature-gives-everyone-free-beer","title":"Nature gives everyone free beer","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eMost political movements are composed of individuals whose goals are similar enough to work towards a common outcome, but which are nevertheless distinct. The soundest way to defeat a movement is usually not through brute force, but to expose these distinctions in such a way that the individuals simply fragment, when they begin to believe their interests were not so common, after all.\u003c/p\u003e\n","md":"Most political movements are composed of individuals whose goals are similar enough towork towards a common outcome, but which are nevertheless distinct. The soundest way to defeat a movement is usually not through brute force, but to expose these distinctionsin such a way that the individuals simply fragment, when they begin to believe their interests were not so common, after all."},"extended":{"html":"\u003cp\u003eMost political movements are composed of individuals whose goals are similar enough to work towards a common outcome, but which are nevertheless distinct. The soundest way to defeat a movement is usually not through brute force, but to expose these distinctions in such a way that the individuals simply fragment, when they begin to believe their interests were not so common, after all.\u003c/p\u003e\n\u003cp\u003eThe \u0026quot;Open Access\u0026quot; movement does not have one single goal. In \u003ca href=\"http://book.openingscience.org/basics_background/open_science_one_term_five_schools_of_thought.html\"\u003eOpen Science: One Term, Five Schools of Thought\u003c/a\u003e, Benedikt Fecher and Sascha Friesike identify five distinct paradigms of open access which may sound broadly similar, but which when given particular implementations of the paradigm by particular publishers, can differ on whether that implementation has really helped with their particular goal. Historically, one important distinction has been between \u0026quot;green open access\u0026quot; (as implemented by repositories such as PubMed Central) and \u0026quot;gold open access\u0026quot; (as implemented by journals like PLOS and many others). Put simply, while most papers in PubMed Central are free to read on the web, they are still copyrighted.\u003c/p\u003e\n\u003cp\u003eLast week, \u003cem\u003eNature\u003c/em\u003e announced a new paradigm which we might call \u0026quot;red open access\u0026quot;. It essentially means that papers will be \u0026quot;readable\u0026quot; by anyone if one of the following is true: 1) someone who already has a subscription to \u003cem\u003eNature\u003c/em\u003e sends you a link, or 2) a link appears in a news article or blog post published by one of one hundred different news organizations to which \u003cem\u003eNature\u003c/em\u003e will grant this privilege. And when I say \u0026quot;readble\u0026quot; I mean do mean read-only: no printing, no sharing, no saving in any format except the one given. To gatekeep this, \u003cem\u003eNature\u003c/em\u003e will employ the \u003ca href=\"https://www.readcube.com/\"\u003eReadCube\u003c/a\u003e software, designed to organize and mark-up PDFs. So I presume that consumers will be restricted to on-screen reading of a format that was designed for printed publications.\u003c/p\u003e\n\u003cp\u003eWe have a basic conflict now between two different goals of the open access movement. To borrow terms from the open source software community, the conflict is between \u003cem\u003efree speech\u003c/em\u003e and \u003cem\u003efree beer\u003c/em\u003e. \u003cem\u003eNature\u003c/em\u003e is allowing some people to read some papers published in their journals for free - as in free beer. They still \u0026quot;own\u0026quot; the paper. They (severely) restrict what can be done with it. They retain their role as the gatekeeper of what is legitimate, published, prestigious science and what isn\u0026#39;t.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIt is a bad deal to happily accept the free beer as a consolation prize for free speech.\u003c/strong\u003e Yes, there is an argument that the public should be able to read the research they pay for. But they should also \u0026quot;own\u0026quot; it. It\u0026#39;s stupid not to allow them to reuse it in anyway they see fit as long as the original source is credited. Now we have a situation where ways in which this science can be used is restricted in weird and arbitrary ways. Even worse, one hundred news organizations will apparently be chosen by \u003ci\u003eNature\u003c/i\u003e to distribute the free beer as they see fit (we might refer to these as \u0026quot;The Anointed Ones\u0026quot;). This seems to conflict pretty strongly with the values at the heart of the open access movement, for which the democratization of knowledge should always be the primary concern.\u003c/p\u003e\n\u003cp\u003eI believe the writing is on the wall for traditional publishers. I think this is mainly a gambit for \u003cem\u003eNature \u003c/em\u003eto delay what they know is inevitable. But I also think that the culture of academic science changes far too slowly for no good reason. When it comes to this particular \u0026quot;gift\u0026quot;, it\u0026#39;s time to send it back.\u003c/p\u003e\n","md":"Most political movements are composed of individuals whose goals are similar enough towork towards a common outcome, but which are nevertheless distinct. The soundest way to defeat a movement is usually not through brute force, but to expose these distinctionsin such a way that the individuals simply fragment, when they begin to believe their interests were not so common, after all.\r\n\r\nThe \"Open Access\" movement does not have one single goal. In \u003ca href=\"http://book.openingscience.org/basics_background/open_science_one_term_five_schools_of_thought.html\"\u003eOpen Science: One Term, Five Schools of Thought\u003c/a\u003e,Benedikt Fecher and Sascha Friesike identifyfive distinct paradigms of open access which may sound broadly similar, but which when given particular implementations of the paradigm by particularpublishers, can differ on whether that implementation has really helped with their particular goal. Historically, one important distinction has been between \"green open access\" (as implemented by repositories such as PubMed Central) and \"gold open access\" (as implemented by journals like PLOS and many others). Put simply, while most papers in PubMed Central are free to read on the web, they are still copyrighted.\r\n\r\nLast week, \u003cem\u003eNature\u003c/em\u003e announced a new paradigm which we might call \"red open access\". It essentially means that papers will be \"readable\"by anyone if one of the following is true: 1) someone who already has a subscription to \u003cem\u003eNature\u003c/em\u003esends you a link, or 2) a link appears in a news article or blog post published by one of one hundred different news organizations to which\u003cem\u003eNature\u003c/em\u003e will grant this privilege. And when I say \"readble\" I mean do mean read-only: no printing, no sharing, no saving in any format except the one given. To gatekeep this, \u003cem\u003eNature\u003c/em\u003e will employ the \u003ca href=\"https://www.readcube.com/\"\u003eReadCube\u003c/a\u003e software, designed to organize and mark-up PDFs. So I presume that consumers will be restricted to on-screen reading of a format that was designed for printed publications.\r\n\r\nWe have a basic conflict now between two different goals of the open access movement. To borrow terms from the open source software community, the conflict is between \u003cem\u003efree speech\u003c/em\u003e and \u003cem\u003efree beer\u003c/em\u003e. \u003cem\u003eNature\u003c/em\u003e is allowing some people to read some papers published in their journals for free - as in free beer. They still \"own\" the paper. They (severely) restrict what can be done with it. They retain their role as the gatekeeper of what is legitimate, published, prestigious science and what isn't.\r\n\r\n\u003cstrong\u003eIt is a bad dealto happily accept the free beer as a consolation prize for free speech.\u003c/strong\u003e Yes, there is an argument that the public should be able to read the research they pay for. But they should also \"own\" it. It's stupid not to allow them to reuse it in anyway they see fit as long as the original source is credited.Now we have a situation where ways in whichthis science can be used is restricted in weird and arbitrary ways. Even worse,one hundred news organizations will apparently be chosen by \u003ci\u003eNature\u003c/i\u003e to distribute the free beer as they see fit (we might refer to these as \"The Anointed Ones\").This seems to conflict pretty strongly with the values at the heart of the open access movement, for which the democratization of knowledge should always be the primary concern.\r\n\r\nI believe the writing is on the wall for traditional publishers. I think this is mainly a gambit for\u003cem\u003eNature\u003c/em\u003eto delay what they know is inevitable. But I also think that the culture ofacademic science changes far too slowly for no good reason. When it comes tothis particular \"gift\", it's time to send it back."}},"publishedDate":{"$date":"2014-12-11T07:00:00.000Z"}}
{"_id":{"$oid":"5802f14f31c9af6010bb4fce"},"slug":"not-your-fathers-prejudice","title":"Not your father's prejudice","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eIn our information overloaded age, censorship no longer works as well as it used to. From the NSA, to Ferguson, to \u003ca href=\"http://www.preposterousuniverse.com/blog/2013/10/12/dont-start-none-wont-be-none/\"\u003eDNLee\u003c/a\u003e, to \u003ca href=\"http://www.cbc.ca/news/technology/muzzling-of-federal-scientists-widespread-survey-suggests-1.2128859\"\u003eattempts to muzzle reports on climate change\u003c/a\u003e, we see one theme recurring over and over again: people using channels previously inaccessible to them to tell their stories. Attempts to silence them have only made the story all the more compelling, made it spread faster and further, as it did for DNLee.\u003c/p\u003e\n","md":"In our information overloaded age, censorship no longer works as well as it used to. From the NSA, to Ferguson, to \u003ca href=\"http://www.preposterousuniverse.com/blog/2013/10/12/dont-start-none-wont-be-none/\"\u003eDNLee\u003c/a\u003e, to \u003ca href=\"http://www.cbc.ca/news/technology/muzzling-of-federal-scientists-widespread-survey-suggests-1.2128859\"\u003eattempts to muzzle reports on climate change\u003c/a\u003e, we see one theme recurring over and over again:people using channels previously inaccessible to them to tell their stories. Attempts to silence them have only made the story all the more compelling, made it spread faster and further, as it did for DNLee."},"extended":{"html":"\u003cp\u003eIn our information overloaded age, censorship no longer works as well as it used to. From the NSA, to Ferguson, to \u003ca href=\"http://www.preposterousuniverse.com/blog/2013/10/12/dont-start-none-wont-be-none/\"\u003eDNLee\u003c/a\u003e, to \u003ca href=\"http://www.cbc.ca/news/technology/muzzling-of-federal-scientists-widespread-survey-suggests-1.2128859\"\u003eattempts to muzzle reports on climate change\u003c/a\u003e, we see one theme recurring over and over again: people using channels previously inaccessible to them to tell their stories. Attempts to silence them have only made the story all the more compelling, made it spread faster and further, as it did for DNLee.\u003c/p\u003e\n\u003cp\u003eThis is undeniably a good thing. But we are seeing something arise in its place: the flood of irrelevant or useless information to drown out the signal within the noise. \u0026quot;Climategate\u0026quot; - \u003ca href=\"https://www.youtube.com/watch?v=vuQLvK6kxeU\"\u003ea scandal manufactured by pulling microscopic bits of emails pulled from years-worth of correspondence\u003c/a\u003e, and then quoting them out of context - added far more confusion to the climate change \u0026quot;debate\u0026quot; than did any attempt at blanket censorship. In Ferguson, the timed reveals of Mike Brown\u0026#39;s pot use and shoplifting somehow masqueraded as information relevant to understanding his death.\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003eSociological questions: about the success of minorities and women in technical fields or within the academy, about economic development in poor countries, or poor communities in rich countries, or about the prevalence of sexual assault just about anywhere - are hard questions. They are hard from a technical standpoint because they involve complex systems with millions or interacting components, where the answer can change depending on what exactly what question you ask, and what you include in your sample. They are also hard because they are emotionally charged, and the pre-existing biases of the researcher - which we all have because we are all human beings - can affect the outcome.\u003c/p\u003e\n\u003cp\u003eI believe it is the responsibility of scientists and science communicators to be honest about the limits and caveats of their work. As I have written before, full disclosure and honesty can open up conversations that ultimately reveal deeper truth. The way NOT to do it is to it prepend idle speculation and personal biases with some science to make it look as though everything you have to say is backed by research.\u003c/p\u003e\n\u003cp\u003eThe best recent example of this is Nicholas Wade\u0026#39;s book \u0026quot;A Troublesome Inheritance\u0026quot; (I will not provide a link), in which he devotes five chapters to an ultimately irrelevant primer on human genetics, only to veer into purely speculative writing about sociological differences between races. The irrelevant and obvious \u0026quot;science\u0026quot; really amounts to the fact that people from geographically close locations share more genes than people from geographically distant locations. This is used as a smokescreen to give Wade space to speculate -without evidence - \u003ca href=\"http://www.nytimes.com/2014/05/16/books/nicholas-wades-a-troublesome-inheritance.html\"\u003ethat race explains all sorts of sociological differences\u003c/a\u003e, from poor economic development in African countries to the fact that \u0026quot;Jews are good at capitalism.\u0026quot;\u003c/p\u003e\n\u003cp\u003eToday we see another example of this in \u003ca href=\"http://www.nytimes.com/2014/11/02/opinion/sunday/academic-science-isnt-sexist.html?_r=0\"\u003eWendy M. Williams and Stephen J. Cici\u0026#39;s New York Times op-ed\u003c/a\u003e \u0026quot;Academic Science Isn\u0026#39;t Sexist.\u0026quot; The article includes a link to a \u003ca href=\"http://www.psychologicalscience.org/pdf/Women-Academic-Science.pdf\"\u003ePDF of their \u0026quot;forthcoming\u0026quot; paper\u003c/a\u003e \u0026quot;Women in Academic Science: A Changing Landscape\u0026quot; (I have to wonder how they pulled this off. Normally papers are embargoed from media coverage until publication. And normally, scientists don\u0026#39;t cover their \u003cem\u003eown\u003c/em\u003e work in a New York Times op-ed). Like Wade\u0026#39;s book, the article really consists of two parts. The first is (somewhat) grounded in science:\u003c/p\u003e\n\u003cp\u003e\u003cblockquote\u003eThey are more likely to receive hiring offers, are paid roughly the same (in 14 of 16 comparisons across the eight fields), are generally tenured and promoted at the same rate (except in economics), remain in their fields at roughly the same rate, have their grants funded and articles accepted as often and are about as satisfied with their jobs. Articles published by women are cited as often as those by men. In sum, with a few exceptions, the world of academic science in math-based fields today reflects gender fairness, rather than gender bias.\u003c/blockquote\u003e\nFirst, as noted by \u003ca href=\"http://www.emilywillinghamphd.com/2014/11/academic-science-is-sexist-we-do-have.html\"\u003eEmily Willingham\u003c/a\u003e, the caveats \u0026quot;roughly\u0026quot;, \u0026quot;generally\u0026quot;, and \u0026quot;about\u0026quot; refer to real, statistically-significant differences between men and women. The honest assessment of the data would be to say that they found evidence of institutional sexism, but that it was - \u003cstrong\u003ein their opinion\u003c/strong\u003e - a small effect.\u003c/p\u003e\n\u003cp\u003eFrom there, the op-ed veers into pure speculation.\u003c/p\u003e\n\u003cp\u003e\u003cblockquote\u003eAs children, girls tend to show more interest in living things (such as people and animals), while boys tend to prefer playing with machines and building things. As adolescents, girls express less interest in careers like engineering and computer science.\u003c/blockquote\u003e\nWhat? This assertion is not based on the paper - at all. There is no citation or link, and I\u0026#39;m well aware this isn\u0026#39;t taken for granted by sociologists, educators or anyone. There is no warning that we\u0026#39;ve moved from discussing something that\u0026#39;s at least partially grounded in research to something that appears to be purely an opinion.\u003c/p\u003e\n\u003cp\u003eFurthermore, as \u003ca href=\"http://phylogenomics.blogspot.ca/2014/10/the-flawed-and-offensive-logic-of.html\"\u003eJonathon Eisen points out\u003c/a\u003e, the fact that tenure, promotion, pay, and peer-review appear to be (almost) fair says nothing about workplace harassment, mistreatment, abuse, etc. etc. etc. They did not look at these issues, and \u003ca href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4100871/\"\u003eother (actual) evidence paints a very different picture\u003c/a\u003e (why not mention this hard data, especially when they don\u0026#39;t have any?). Yet Cici and Williams seem to lump both these types of issues together. Evidence that pay has at least come a long way toward equalization is hardly evidence that there is no sexual abuse or harassment in academic science.\u003c/p\u003e\n\u003cp\u003eFor me, the op-ed can be summarized by its final sentence: \u0026quot;We are not your father\u0026#39;s academy anymore.\u0026quot; The word \u0026quot;we\u0026quot; is very revealing: perhaps the authors - part of the academy themselves - feel some frustration at \u003ca href=\"http://pankisseskafka.com/\"\u003epeople\u003c/a\u003e \u003ca href=\"http://beangirls.blogspot.ca/2013/03/on-leaving-scientific-research-again.html\"\u003ewho\u003c/a\u003e \u003ca href=\"http://biochembelle.com/2013/04/07/when-the-odds-beat-you/\"\u003ejust\u003c/a\u003e \u003ca href=\"http://deepseanews.com/2013/02/19294/\"\u003ewon\u0026#39;t\u003c/a\u003e \u003ca href=\"http://www.ethanperlstein.com/postdocalypse-now/\"\u003eshut\u003c/a\u003e \u003ca href=\"http://www.economist.com/node/17723223\"\u003eup\u003c/a\u003e \u003ca href=\"http://www.bostonglobe.com/metro/2014/10/04/glut-postdoc-researchers-stirs-quiet-crisis-science/HWxyErx9RNIW17khv0MWTN/story.html\"\u003eabout\u003c/a\u003e \u003ca href=\"http://chronicle.com/article/The-Shadow-Scholar/125329/\"\u003ethe\u003c/a\u003e \u003ca href=\"http://www.slate.com/articles/life/education/2014/08/william_deresiewicz_and_rebecca_schuman_discuss_his_book_excellent_sheep.html\"\u003eproblems\u003c/a\u003e \u003ca href=\"http://www.nytimes.com/2014/09/20/opinion/science-has-a-sexual-assault-problem.html\"\u003einherent\u003c/a\u003e \u003ca href=\"http://www.theatlantic.com/magazine/archive/2005/01/lost-in-the-meritocracy/303672/\"\u003ein\u003c/a\u003e \u003ca href=\"http://www.theguardian.com/higher-education-network/blog/2014/mar/15/women-science-research-university-discrimination-academics-anonymous\"\u003ethe\u003c/a\u003e \u003ca href=\"http://www.pnas.org/content/111/16/5773.abstract\"\u003ecurrent\u003c/a\u003e \u003ca href=\"http://www.nytimes.com/2013/10/06/magazine/why-are-there-still-so-few-women-in-science.html?pagewanted=all\"\u003esystem\u003c/a\u003e. Perhaps it is not your father\u0026#39;s sexism: there\u0026#39;s no pin-up girls in the lab and Francis Crick isn\u0026#39;t going to grope you and steal your data (but only because he\u0026#39;s dead). But with the new censorship comes the new prejudice: the prejudice that attempts to disguise itself with the thinnest veneer of data. The prejudice that pretends that some progress means we\u0026#39;ve come far enough, or perhaps too far.\u003c/p\u003e\n\u003cp\u003eI\u0026#39;ll close with this video of Neil DeGrasse Tyson, in response to a question about why women are badly represented in the sciences. \u0026quot;Before you start talking about genetic differences [or lifestyle choices, for that matter], you\u0026#39;ve gotta come up with a system where there\u0026#39;s equal opportunity. Then we can have that conversation.\u0026quot;\u003c/p\u003e\n\u003cp\u003e[embed]\u003ca href=\"https://www.youtube.com/watch?v=z7ihNLEDiuM[/embed\"\u003ehttps://www.youtube.com/watch?v=z7ihNLEDiuM[/embed\u003c/a\u003e]\u003c/p\u003e\n","md":"In our information overloaded age, censorship no longer works as well as it used to. From the NSA, to Ferguson, to \u003ca href=\"http://www.preposterousuniverse.com/blog/2013/10/12/dont-start-none-wont-be-none/\"\u003eDNLee\u003c/a\u003e, to \u003ca href=\"http://www.cbc.ca/news/technology/muzzling-of-federal-scientists-widespread-survey-suggests-1.2128859\"\u003eattempts to muzzle reports on climate change\u003c/a\u003e, we see one theme recurring over and over again:people using channels previously inaccessible to them to tell their stories. Attempts to silence them have only made the story all the more compelling, made it spread faster and further, as it did for DNLee.\r\n\r\nThis is undeniably a good thing. But we are seeing something arise in its place: the flood of irrelevant or useless information to drown out the signal within the noise. \"Climategate\" - \u003ca href=\"https://www.youtube.com/watch?v=vuQLvK6kxeU\"\u003ea scandal manufactured by pullingmicroscopic bits of emails pulled from years-worth of correspondence\u003c/a\u003e, and then quoting them out of context - added far more confusion to the climate change \"debate\" than did any attempt at blanket censorship. In Ferguson, the timed reveals of Mike Brown's pot use and shoplifting somehow masqueraded as information relevant to understanding his death.\r\n\r\n\u003c!--more--\u003e\r\n\r\nSociological questions: about the success of minorities and women intechnical fields or within the academy, about economic development in poor countries, or poor communities in rich countries, or about the prevalence of sexual assault just about anywhere - are hard questions. They are hard from a technical standpoint because they involve complex systems with millions or interacting components, where the answer can change depending on what exactly what question you ask, and what you include in your sample. They are also hard because they are emotionally charged, and the pre-existing biases of the researcher - which we all have because we are all human beings - can affect the outcome.\r\n\r\nI believe it is the responsibility of scientists and science communicators to be honest about the limits and caveats of theirwork. As I have written before, full disclosure and honesty can open up conversations that ultimately reveal deeper truth. The way NOT to do it is to itprepend idle speculation and personal biases with some science to make it look as though everything you have to say is backed by research.\r\n\r\nThe best recent example of this is Nicholas Wade's book \"A Troublesome Inheritance\" (I will not provide a link), in which hedevotes five chapters to an ultimately irrelevant primer on human genetics, only to veer into purely speculative writing about sociological differences between races. The irrelevant and obvious \"science\"really amounts to the fact thatpeople from geographically close locations share more genes than people from geographically distant locations. This is used as a smokescreen to give Wade space to speculate -without evidence - \u003ca href=\"http://www.nytimes.com/2014/05/16/books/nicholas-wades-a-troublesome-inheritance.html\"\u003ethat raceexplains all sorts of sociological differences\u003c/a\u003e, from poor economic development in African countries to the fact that \"Jews are good at capitalism.\"\r\n\r\nToday we see another example of this in \u003ca href=\"http://www.nytimes.com/2014/11/02/opinion/sunday/academic-science-isnt-sexist.html?_r=0\"\u003eWendy M. Williams and Stephen J. Cici's New York Times op-ed\u003c/a\u003e \"Academic Science Isn't Sexist.\" The article includes a link to a \u003ca href=\"http://www.psychologicalscience.org/pdf/Women-Academic-Science.pdf\"\u003ePDF of their \"forthcoming\" paper\u003c/a\u003e \"Women in Academic Science: A Changing Landscape\" (I have to wonder how they pulled this off. Normally papers are embargoed from media coverage until publication. And normally, scientists don't cover their\u003cem\u003eown\u003c/em\u003e work in a New York Times op-ed). Like Wade's book, the article really consists of two parts. The first is (somewhat) grounded in science:\r\n\u003cblockquote\u003eThey are more likely to receive hiring offers, are paid roughly the same (in 14 of 16 comparisons across the eight fields), are generally tenured and promoted at the same rate (except in economics), remain in their fields at roughly the same rate, have their grants funded and articles accepted as often and are about as satisfied with their jobs. Articles published by women are cited as often as those by men. In sum, with a few exceptions, the world of academic science in math-based fields today reflects gender fairness, rather than gender bias.\u003c/blockquote\u003e\r\nFirst, as noted by \u003ca href=\"http://www.emilywillinghamphd.com/2014/11/academic-science-is-sexist-we-do-have.html\"\u003eEmily Willingham\u003c/a\u003e,the caveats \"roughly\", \"generally\", and \"about\" refer to real, statistically-significant differences between men and women. The honest assessment of the data would be to say that they foundevidenceof institutional sexism, but that it was - \u003cstrong\u003ein their opinion\u003c/strong\u003e - a small effect.\r\n\r\nFrom there, the op-ed veers into pure speculation.\r\n\u003cblockquote\u003eAs children, girls tend to show more interest in living things (such as people and animals), while boys tend to prefer playing with machines and building things. As adolescents, girls express less interest in careers like engineering and computer science.\u003c/blockquote\u003e\r\nWhat? This assertion is not based on the paper - at all. There is no citation or link,and I'mwell aware this isn't taken for granted by sociologists, educators or anyone. There is no warning that we've moved from discussing something that's at least partially grounded in research to something that appears to be purely an opinion.\r\n\r\nFurthermore, as \u003ca href=\"http://phylogenomics.blogspot.ca/2014/10/the-flawed-and-offensive-logic-of.html\"\u003eJonathon Eisen points out\u003c/a\u003e, the fact that tenure, promotion, pay, and peer-review appear to be (almost) fair says nothing about workplace harassment, mistreatment, abuse, etc. etc. etc. They did not look at these issues, and \u003ca href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4100871/\"\u003eother (actual) evidence paints a very different picture\u003c/a\u003e(why not mention this hard data, especially when they don't have any?). Yet Cici and Williams seem to lump both these types of issues together. Evidence that pay has at least come a long way toward equalization is hardly evidence that there is no sexual abuse or harassment in academic science.\r\n\r\nFor me, theop-ed can be summarized by its final sentence: \"We are not your father's academy anymore.\"The word \"we\" is very revealing: perhaps the authors - part of the academy themselves - feel some frustration at \u003ca href=\"http://pankisseskafka.com/\"\u003epeople\u003c/a\u003e \u003ca href=\"http://beangirls.blogspot.ca/2013/03/on-leaving-scientific-research-again.html\"\u003ewho\u003c/a\u003e\u003ca href=\"http://biochembelle.com/2013/04/07/when-the-odds-beat-you/\"\u003ejust\u003c/a\u003e \u003ca href=\"http://deepseanews.com/2013/02/19294/\"\u003ewon't\u003c/a\u003e \u003ca href=\"http://www.ethanperlstein.com/postdocalypse-now/\"\u003eshut\u003c/a\u003e \u003ca href=\"http://www.economist.com/node/17723223\"\u003eup\u003c/a\u003e\u003ca href=\"http://www.bostonglobe.com/metro/2014/10/04/glut-postdoc-researchers-stirs-quiet-crisis-science/HWxyErx9RNIW17khv0MWTN/story.html\"\u003eabout\u003c/a\u003e\u003ca href=\"http://chronicle.com/article/The-Shadow-Scholar/125329/\"\u003ethe\u003c/a\u003e \u003ca href=\"http://www.slate.com/articles/life/education/2014/08/william_deresiewicz_and_rebecca_schuman_discuss_his_book_excellent_sheep.html\"\u003eproblems\u003c/a\u003e \u003ca href=\"http://www.nytimes.com/2014/09/20/opinion/science-has-a-sexual-assault-problem.html\"\u003einherent\u003c/a\u003e \u003ca href=\"http://www.theatlantic.com/magazine/archive/2005/01/lost-in-the-meritocracy/303672/\"\u003ein\u003c/a\u003e \u003ca href=\"http://www.theguardian.com/higher-education-network/blog/2014/mar/15/women-science-research-university-discrimination-academics-anonymous\"\u003ethe\u003c/a\u003e \u003ca href=\"http://www.pnas.org/content/111/16/5773.abstract\"\u003ecurrent\u003c/a\u003e \u003ca href=\"http://www.nytimes.com/2013/10/06/magazine/why-are-there-still-so-few-women-in-science.html?pagewanted=all\"\u003esystem\u003c/a\u003e. Perhaps it is not your father's sexism: there's no pin-up girls in the lab and Francis Crick isn't going to grope you and steal your data (but only because he's dead). But with the new censorship comes the new prejudice: the prejudice that attempts to disguise itself with the thinnest veneer of data. The prejudice that pretends that some progress means we've come far enough, or perhaps too far.\r\n\r\nI'll close with this videoof Neil DeGrasse Tyson, in response to a question aboutwhy women are badly represented in the sciences. \"Before you start talking about genetic differences [or lifestyle choices, for that matter], you've gotta come up with a system where there's equal opportunity. Then we can have that conversation.\"\r\n\r\n[embed]https://www.youtube.com/watch?v=z7ihNLEDiuM[/embed]"}},"publishedDate":{"$date":"2014-12-11T07:00:00.000Z"}}
{"_id":{"$oid":"5802f22431c9af6010bb4fcf"},"slug":"bookshelf-php-cookbook","title":"Bookshelf: PHP Cookbook","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eMost negative reviews of programming books are written by people the book is not for. So let\u0026#39;s get that out of the way, first.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThis book is not an introduction to programming.\u003c/li\u003e\n\u003cli\u003eThis book is not an introduction to PHP.\u003c/li\u003e\n\u003cli\u003eThis book is not for people who hate PHP or think it\u0026#39;s not a \u0026quot;real\u0026quot; programming language.\u003c/li\u003e\n\u003cli\u003eThis book is not the PHP Manual.\u003c/li\u003e\n\u003c/ul\u003e\n","md":"Most negative reviews of programming books are written by people the book is not for. So let's get that out of the way, first.\r\n\r\n- This book is not an introduction to programming.\r\n- This book is not an introduction to PHP.\r\n- This book is not for people who hate PHP or think it's not a \"real\" programming language.\r\n- This book is not the PHP Manual."},"extended":{"html":"\u003cp\u003eMost negative reviews of programming books are written by people the book is not for. So let\u0026#39;s get that out of the way, first.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThis book is not an introduction to programming.\u003c/li\u003e\n\u003cli\u003eThis book is not an introduction to PHP.\u003c/li\u003e\n\u003cli\u003eThis book is not for people who hate PHP or think it\u0026#39;s not a \u0026quot;real\u0026quot; programming language.\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eThis book is not the PHP Manual.\u003c/p\u003e\n\u003cp\u003e\u0026quot;Cookbooks\u0026quot; represent something in between the manual and an overview of the language. Certain use cases for PHP are covered in enough detail to someone moderately familiar with the language a jumping-off point to get more information. For example, did you know: \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eYou can chain PHP methods, just like in JavaScript? Eg. \u003ccode\u003e$orange = $fruit-\u0026gt;;get(\u0026#39;citrus\u0026#39;)-\u0026gt;;peel();\u003c/code\u003e. See page 207.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003eYou can sort non-standards-compliant HTML with a single, built-in PHP function? See page 419.\u003c/li\u003e\n\u003cli\u003eHow to serve a RESTful API (without a library) that accepts all the right methods and returns the correct response codes? That\u0026#39;s chapter 15.\u003c/li\u003e\n\u003cli\u003eHow to use the command line to test bits of code? That\u0026#39;s Chapter 26.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis is a \u003cem\u003elong\u003c/em\u003e book, and it\u0026#39;s not meant to be read cover-to-cover, nor is it meant to be a replacement for the manual. It is not exhaustive. One disappointment for me what that lots of new stuff was not covered. PHP5 includes (and will include) features like namespaces, anonymous functions, and promises that are standard in other languages but are opening up whole new design patterns to PHP developers. That would have been perfect for the format of this book but was not included. Hopefully they\u0026#39;ll appear in the fourth edition.\u003c/p\u003e\n","md":"\r\nMost negative reviews of programming books are written by people the book is not for. So let's get that out of the way, first.\r\n\r\n- This book is not an introduction to programming.\r\n- This book is not an introduction to PHP.\r\n- This book is not for people who hate PHP or think it's not a \"real\" programming language.\r\n- This book is not the PHP Manual.\r\n\r\n \"Cookbooks\" represent something in between the manual and an overview of the language. Certain use cases for PHP are covered in enough detail to someone moderately familiar with the language a jumping-off point to get more information. For example, did you know: \r\n \r\n- You can chain PHP methods, just like in JavaScript? Eg. `$orange = $fruit-\u003e;get('citrus')-\u003e;peel();`. See page 207.\r\n- You can sort non-standards-compliant HTML with a single, built-in PHP function? See page 419.\r\n- How to serve a RESTful API (without a library) that accepts all the right methods and returns the correct response codes? That's chapter 15.\r\n- How to use the command line to test bits of code? That's Chapter 26.\r\n\r\nThis is a *long* book, and it's not meant to be read cover-to-cover, nor is it meant to be a replacement for the manual. It is not exhaustive. One disappointment for me what that lots of new stuff was not covered. PHP5 includes (and will include) features like namespaces, anonymous functions, and promises that are standard in other languages but are opening up whole new design patterns to PHP developers. That would have been perfect for the format of this book but was not included. Hopefully they'll appear in the fourth edition."}},"publishedDate":{"$date":"2014-10-22T06:00:00.000Z"}}
{"_id":{"$oid":"5802f27731c9af6010bb4fd0"},"slug":"phd-population-control-the-same-old-excuses","title":"PhD population control: the same old excuses ...","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eThere\u0026#39;s another discussion going on over at DrugMonkey about \u003ca href=\"http://scientopia.org/blogs/drugmonkey/2014/09/13/a-simple-question-or-two-on-training-graduate-students/\"\u003eprofessors training more than their \u0026quot;replacement number\u0026quot;\u003c/a\u003e of graduate students.\u003c/p\u003e\n","md":"\r\nThere's another discussion going on over at DrugMonkey about [professors training more than their \"replacement number\"](http://scientopia.org/blogs/drugmonkey/2014/09/13/a-simple-question-or-two-on-training-graduate-students/) of graduate students."},"extended":{"html":"\u003cp\u003eThere\u0026#39;s another discussion going on over at DrugMonkey about \u003ca href=\"http://scientopia.org/blogs/drugmonkey/2014/09/13/a-simple-question-or-two-on-training-graduate-students/\"\u003eprofessors training more than their \u0026quot;replacement number\u0026quot;\u003c/a\u003e of graduate students. I\u0026#39;m personally not sure that replacement (as in, each professor trains one grad student over the course of their entire career) should be the goal, but I do that the PhD glut needs to be addressed, and in a meaningful way. Here are some of the arguments I hear against \u0026quot;academic birth control\u0026quot;, and my thoughts on them: \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. Even if they don\u0026#39;t go the academic route, PhDs generally end up in good jobs anyway.\u003c/strong\u003e \u003ca href=\"http://www.caseyy.org/blog/what-fraction-of-phd-training-is-wasted-the-hidden-variable/\" title=\"What fraction of PhD training is wasted? A hidden variable in the debate\"\u003eI\u0026#39;ve blogged about this before\u003c/a\u003e, and the tl;dr version is that it forgets to measure opportunity cost. Getting into a good grad school requires well-above average grades, and therefore the people in these programs are positioned to do well with or without the PhD. There\u0026#39;s a second, more sinister level which is that - compared to our contemporaries in medicine and law - people entering PhD programs are disproportionately white and middle-class. A few years ago this actually spurred the NIH to actively demand that more minorities be recruited into graduate programs (if anyone has a link for this please comment; I remember it being a huge issue around 2006-2009). As \u003ca href=\"http://scientopia.org/blogs/drugmonkey/2014/09/10/npr-on-the-nih-grant-situation#div-comment-354387\"\u003eDr. Becca puts it\u003c/a\u003e:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003emost people you talk to in scientific careers have a comparatively large amount of social and financial capital in their lives. Basically, scientists disproportionately are the sort of people who are likely to see many options other than grocer because of their peer groups, because they have an economic cushion, and sometimes directly because of their family/social connections. ... I suspect it\u0026#39;s also a reason that things have actually gotten very bad indeed in scientific careers, without people hardly noticing for a surprisingly long time. \u003cem\u003eEnough\u003c/em\u003e people who got chewed up and spit out by the academic science racket landed on their feet that people thought it had something to do with Majickal SuperUnicornSmartnessSnowflake TransferableSkills we all develop, instead of the aristocracy looking after it\u0026#39;s own.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e2. Encouraging people into science is the right thing to do for society.\u003c/strong\u003e This used to give me pause until I thought about it in a very specific way: let\u0026#39;s suppose that human capital, that having the best, smartest, most driven people would really advance basic science (and no, I don\u0026#39;t think this is a given. To start, it presupposes that there isn\u0026#39;t some other limiting resource ...). Wouldn\u0026#39;t the scientific mission be better served by trying to keep the people it \u003cstrong\u003edoes\u003c/strong\u003e have rather than recruit a new crop every 6-10 years? Sure they might cost a little more in terms of annual salary (but not much, when you consider the tuition money-laundering scheme most universities in the US have set up), but they\u0026#39;re already trained. \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. No promises were made. We aren\u0026#39;t press ganging students into service.\u003c/strong\u003e Fair enough. I suppose it comes down to a question of personal ethics. The law profession has a similar problem, in which the number of graduates far outstrips the number of jobs, but schools are ill-served by being honest about this because they would then lose enrolment and tuition. PhD programs aren\u0026#39;t taking anyone\u0026#39;s money, they are just taking some years and earning potential. I believe that this is wrong, but I recognize that it\u0026#39;s more of a grey area. Americans in particular are fond of the whole \u0026quot;personal responsibility\u0026quot; argument, even to an extreme (as in: it\u0026#39;s your fault went into that program/bought a house you couldn\u0026#39;t afford/didn\u0026#39;t read the fine print on the waiver). \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. Grad school is a good way to learn how to think for yourself.\u003c/strong\u003e This should be the function of undergraduate programs, as opposed to teaching legions of students how to fill out scantron forms.\u003c/p\u003e\n","md":"\r\nThere's another discussion going on over at DrugMonkey about [professors training more than their \"replacement number\"](http://scientopia.org/blogs/drugmonkey/2014/09/13/a-simple-question-or-two-on-training-graduate-students/) of graduate students. I'm personally not sure that replacement (as in, each professor trains one grad student over the course of their entire career) should be the goal, but I do that the PhD glut needs to be addressed, and in a meaningful way. Here are some of the arguments I hear against \"academic birth control\", and my thoughts on them: \r\n\r\n**1. Even if they don't go the academic route, PhDs generally end up in good jobs anyway.** [I've blogged about this before](http://www.caseyy.org/blog/what-fraction-of-phd-training-is-wasted-the-hidden-variable/ \"What fraction of PhD training is wasted? A hidden variable in the debate\"), and the tl;dr version is that it forgets to measure opportunity cost. Getting into a good grad school requires well-above average grades, and therefore the people in these programs are positioned to do well with or without the PhD. There's a second, more sinister level which is that - compared to our contemporaries in medicine and law - people entering PhD programs are disproportionately white and middle-class. A few years ago this actually spurred the NIH to actively demand that more minorities be recruited into graduate programs (if anyone has a link for this please comment; I remember it being a huge issue around 2006-2009). As [Dr. Becca puts it](http://scientopia.org/blogs/drugmonkey/2014/09/10/npr-on-the-nih-grant-situation#div-comment-354387):\r\n\r\n\u003e most people you talk to in scientific careers have a comparatively large amount of social and financial capital in their lives. Basically, scientists disproportionately are the sort of people who are likely to see many options other than grocer because of their peer groups, because they have an economic cushion, and sometimes directly because of their family/social connections. ... I suspect it's also a reason that things have actually gotten very bad indeed in scientific careers, without people hardly noticing for a surprisingly long time. *Enough* people who got chewed up and spit out by the academic science racket landed on their feet that people thought it had something to do with Majickal SuperUnicornSmartnessSnowflake TransferableSkills we all develop, instead of the aristocracy looking after it's own.\r\n\r\n**2. Encouraging people into science is the right thing to do for society.** This used to give me pause until I thought about it in a very specific way: let's suppose that human capital, that having the best, smartest, most driven people would really advance basic science (and no, I don't think this is a given. To start, it presupposes that there isn't some other limiting resource ...). Wouldn't the scientific mission be better served by trying to keep the people it **does** have rather than recruit a new crop every 6-10 years? Sure they might cost a little more in terms of annual salary (but not much, when you consider the tuition money-laundering scheme most universities in the US have set up), but they're already trained. \r\n\r\n**3. No promises were made. We aren't press ganging students into service.** Fair enough. I suppose it comes down to a question of personal ethics. The law profession has a similar problem, in which the number of graduates far outstrips the number of jobs, but schools are ill-served by being honest about this because they would then lose enrolment and tuition. PhD programs aren't taking anyone's money, they are just taking some years and earning potential. I believe that this is wrong, but I recognize that it's more of a grey area. Americans in particular are fond of the whole \"personal responsibility\" argument, even to an extreme (as in: it's your fault went into that program/bought a house you couldn't afford/didn't read the fine print on the waiver). \r\n\r\n**4. Grad school is a good way to learn how to think for yourself.** This should be the function of undergraduate programs, as opposed to teaching legions of students how to fill out scantron forms."}},"publishedDate":{"$date":"2014-09-14T06:00:00.000Z"}}
{"_id":{"$oid":"5802f30a31c9af6010bb4fd1"},"slug":"i-am-not-a-scientist-anymore-and-so-can-you","title":"I am not a scientist anymore (And so can you!)","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI have had a half-baked post in my mind now about my new job (yay!) and about what it means for my self-identity (at least career-wise), but I never did manage to figure out the right angle for it. I haven\u0026#39;t started at the job yet, and I tend not to be a person who looks back, so reflecting on my life in academia seemed a bit pointless, while I didn\u0026#39;t have anything at all to write about the future. \u003c/p\u003e\n","md":"\r\nI have had a half-baked post in my mind now about my new job (yay!) and about what it means for my self-identity (at least career-wise), but I never did manage to figure out the right angle for it. I haven't started at the job yet,and I tend not to be a person who looks back, so reflecting on my life in academia seemed a bit pointless, while I didn't have anything at all to write about the future. "},"extended":{"html":"\u003cp\u003eI have had a half-baked post in my mind now about my new job (yay!) and about what it means for my self-identity (at least career-wise), but I never did manage to figure out the right angle for it. I haven\u0026#39;t started at the job yet, and I tend not to be a person who looks back, so reflecting on my life in academia seemed a bit pointless, while I didn\u0026#39;t have anything at all to write about the future. \u003c/p\u003e\n\u003cp\u003eSo, without an angle, without editorial, soapboxing, or comment, here is my story: \u003c/p\u003e\n\u003cp\u003eI\u0026#39;ve written previously about \u003ca href=\"http://www.caseyy.org/blog/consciously-uncoupling-from-academia/ \u0026quot;Consciously uncoupling from academia\u0026quot;\"\u003ehow I determined academia was not for me\u003c/a\u003e, but this leads to the obvious question: what else can I do? Industry has been the traditional exit route for generations of PhD holders. In my training, I have probably spent more time at the bench than time doing data analysis, writing, teaching and other activities put together, so it seems like a direct application of my skillset. The problem was that I was seeking a way into this field at the height of the recession, and I had friends from grad school who had spent \u003cem\u003eyears\u003c/em\u003e unemployed by looking only in industry. Biotech and pharma layoffs have become commonplace stories, and people who do get hired (into research positions) usually meet very specific criteria (ie, their thesis was on a particular enzyme that a drug company suddenly started working with). It\u0026#39;s an understatement to say that I had not planned my graduate work or either of my postdocs with this in mind, and so I felt shut out of this world. Geography was also a major factor: without a visa to work in the US private sector I was trying to \u0026quot;network\u0026quot; from afar, or network locally with people who likely would not be able to hire me even if they wanted to. \u003c/p\u003e\n\u003cp\u003eWhile I felt that I had a suite of well-honed soft skills (a good handle on the process of scientific inquiry is not something that comes overnight), I had no hard skills that anyone was interested in. I can\u0026#39;t understate how depressing or disorienting this was. I had spent ten years in \u0026quot;training\u0026quot; for something that didn\u0026#39;t exist. \u003c/p\u003e\n\u003cp\u003eI decided at this point that my soft-skills were something that would give me a leg up in a lot of industries, and that - if I could find an entry route somewhere - I needn\u0026#39;t feel that my training had been a waste of time. I had grad-school friends who had done further degrees: in law, medicine, or policy, as a way to find an entry into a completely new profession. I wanted to do that. But I wanted to do it without going to school. \u003c/p\u003e\n\u003cp\u003eAnd so I discovered the Internet. More properly, I discovered that the values at the heart of the world-wide web, from Tim Berners-Lee to Maru, were \u003ca href=\"http://www.caseyy.org/clay-shirkys-cognitive-surplus-and-the-open-science-movement/ \u0026quot;Clay Shirkys Cognitive Surplus and the open science movement\u0026quot;\"\u003eremarkably compatible with the values that had drawn me to academia in the first place\u003c/a\u003e. I became a scientist to push the frontiers of human knowledge, for its own sake, but discovered that the incentive structure at the heart of the profession was pushing that knowledge in increasingly irrelevant directions, not to mention actively preventing the reuse and dissemination of that knowledge. On the flipside, it was possible to build increasingly sophisticated web products using building blocks that are freely disseminated, and possible to pick up the know-how to implement them, at no charge. \u003c/p\u003e\n\u003cp\u003eFast forward two years, and last week - somewhat to my surprise - I was hired as a web developer at a small firm. It is an entry level job, with a corresponding salary, and something that I technically could have gotten out of college. I am certain, however, that the development skills I taught myself evenings and weekends (while also employed as a postdoc, not to mention having a kid) turned out to be more valuable than what I learned in six years of grad school and four years and as postdoc. \u003c/p\u003e\n\u003cp\u003eIt did take a fair bit of discipline, and my productivity as a scientist certainly suffered, not spending all those evenings and weekends in the lab. But here we come to the crux of this issue, where I reveal my soapbox (tricked you!). What would all those evenings and weekends have bought me? What is point of \u003ca href=\"http://sciencecareers.sciencemag.org/career_magazine/previous_issues/articles/2014_07_21/caredit.a1400184\"\u003eencouraging postdocs to \u0026quot;think happy thoughts\u0026quot;\u003c/a\u003e when anyone with \u003ca href=\"http://scientopia.org/blogs/blather/2013/02/07/simple-math-for-the-special-snowflakes/\"\u003ehalf a brain can see that the math is stacked against them\u003c/a\u003e? How can we ignore the perverse incentives facing young scientists when \u003ca href=\"http://www.washingtonpost.com/business/economy/doubts-about-johns-hopkins-research-have-gone-unanswered-scientist-says/2013/03/11/52822cba-7c84-11e2-82e8-61a46c2cde3d_story.html\"\u003ethe results are right there in front of us\u003c/a\u003e? Oddly, the biggest reaction I\u0026#39;ve got to leaving science altogether has been genuine surprise that I would pursue a career which uses so little of my training. These reactions have run the gamut from real curiosity to bemusement to dismay. My only response is a little mental shrug of my shoulders: if education feels like it\u0026#39;s holding me back, I have every right to discard it. It\u0026#39;s my life.\u003c/p\u003e\n","md":"\r\nI have had a half-baked post in my mind now about my new job (yay!) and about what it means for my self-identity (at least career-wise), but I never did manage to figure out the right angle for it. I haven't started at the job yet,and I tend not to be a person who looks back, so reflecting on my life in academia seemed a bit pointless, while I didn't have anything at all to write about the future. \r\n\r\nSo, without an angle, without editorial, soapboxing, or comment, here is my story: \r\n\r\nI've written previously about [how I determined academia was not for me](http://www.caseyy.org/blog/consciously-uncoupling-from-academia/ \u0026quot;Consciously uncoupling from academia\u0026quot;), but this leads to the obvious question: what else can I do? Industry has been the traditional exit route for generations of PhD holders. In my training, I have probably spent more time at the bench than time doing data analysis, writing, teaching and other activities put together, so it seems like a direct application of my skillset. The problem was that I was seeking a way into this field at the height of the recession, and I had friends from grad school who had spent *years* unemployed by looking only inindustry. Biotech and pharma layoffs have become commonplace stories, and people who do get hired (into research positions) usually meetvery specific criteria (ie, their thesis was on a particular enzyme that a drug company suddenly started working with). It's an understatement to say that I had not planned my graduate work or either of my postdocs with this in mind, and so I felt shut out of this world. Geography was also a major factor: without a visa to work in the US private sector I was trying to \u0026quot;network\u0026quot; from afar, or network locally with people who likely would not be able to hire me even if they wanted to. \r\n\r\nWhile I felt that I had a suite of well-honed soft skills (a good handle on the process of scientific inquiry is not something that comes overnight), I had no hard skills that anyone was interested in. I can't understatehow depressing or disorienting this was. I had spent ten years in \u0026quot;training\u0026quot; for something that didn't exist. \r\n\r\nI decided at this point that my soft-skills were something that would give me a leg up in a lot of industries, and that - if I could find an entry route somewhere - I needn't feel that my training had been a waste of time. I had grad-school friends who had done further degrees: in law, medicine, or policy, as a way to find an entry into a completely new profession. I wanted to do that. But I wanted to do it without going to school. \r\n\r\nAnd so I discovered the Internet. More properly, I discovered that the values at the heart of the world-wide web, from Tim Berners-Lee to Maru, were [remarkably compatible with the values that had drawn me to academia in the first place](http://www.caseyy.org/clay-shirkys-cognitive-surplus-and-the-open-science-movement/ \u0026quot;Clay Shirkys Cognitive Surplus and the open science movement\u0026quot;). I became a scientist to push the frontiers of human knowledge, for its own sake, but discovered that the incentive structure at the heart of the profession was pushing that knowledge in increasingly irrelevant directions, not to mentionactively preventing the reuse and dissemination of that knowledge. On the flipside, it was possible to build increasingly sophisticated webproducts using building blocks that are freely disseminated, and possible to pick up the know-how to implement them, at no charge. \r\n\r\nFast forward two years, andlast week - somewhat to my surprise - I was hired as a web developer at a small firm. It is an entry level job, with a corresponding salary, and something that I technically could have gotten out of college. I am certain, however, that the development skills I taught myself evenings and weekends (while also employed as a postdoc, not to mention having a kid) turned out to be more valuable than what I learned in six years of grad school and four years and as postdoc. \r\n\r\nIt did take a fair bit of discipline, and my productivity as a scientist certainly suffered, not spending all those evenings and weekends in the lab. But here we come to the crux of this issue, where I reveal my soapbox (tricked you!). What would all those evenings and weekends have bought me? What is point of [encouraging postdocs to \u0026quot;think happy thoughts\u0026quot;](http://sciencecareers.sciencemag.org/career_magazine/previous_issues/articles/2014_07_21/caredit.a1400184)when anyone with [half a brain can see that the math is stacked against them](http://scientopia.org/blogs/blather/2013/02/07/simple-math-for-the-special-snowflakes/)? How can we ignore the perverse incentives facing young scientists when [the results are right there in front of us](http://www.washingtonpost.com/business/economy/doubts-about-johns-hopkins-research-have-gone-unanswered-scientist-says/2013/03/11/52822cba-7c84-11e2-82e8-61a46c2cde3d_story.html)? Oddly, the biggest reaction I've got to leaving science altogether has been genuine surprise that I would pursue a career which uses so little of my training. These reactions haverun the gamut from real curiosity to bemusement to dismay. My only response is a little mental shrug of my shoulders: if education feels like it's holding me back, I have everyright to discard it. It's my life."}},"publishedDate":{"$date":"2014-07-31T06:00:00.000Z"}}
{"_id":{"$oid":"5802f3b431c9af6010bb4fd2"},"slug":"on-the-emptiness-of-failed-replications-the-best-parts","title":"On the emptiness of failed replications: the best parts","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI\u0026#39;ve had essentially no time for reading lately as I\u0026#39;m doing SAHD thing, moving into a new house, and coding like a maniac whenever I get a spare hour, but there was so much buzz on Twitter around Jason Mitchell\u0026#39;s essay \u003ca href=\"http://wjh.harvard.edu/~jmitchel/writing/failed_science.htm\"\u003eabout replication studies in social psychology\u003c/a\u003e that I had to take a half-hour to read it. And for all that is holy, let me just say: What. The. Fuck. That\u0026#39;s 30 min of my life I can\u0026#39;t get back. I will replicate the highlights below so that you don\u0026#39;t have to read it yourself.\u003c/p\u003e\n","md":"\r\nI've had essentially no time for reading lately as I'm doing SAHD thing, moving into a new house, and coding like a maniac whenever I get a spare hour, but there was so much buzz on Twitter around Jason Mitchell's essay [about replication studies in social psychology](http://wjh.harvard.edu/~jmitchel/writing/failed_science.htm) that I had to take a half-hour to read it. And for all that is holy, let me just say: What. The. Fuck. That's 30 min of my life I can't get back.I will replicate the highlights below so that you don't have to read it yourself."},"extended":{"html":"\u003cp\u003eI\u0026#39;ve had essentially no time for reading lately as I\u0026#39;m doing SAHD thing, moving into a new house, and coding like a maniac whenever I get a spare hour, but there was so much buzz on Twitter around Jason Mitchell\u0026#39;s essay \u003ca href=\"http://wjh.harvard.edu/~jmitchel/writing/failed_science.htm\"\u003eabout replication studies in social psychology\u003c/a\u003e that I had to take a half-hour to read it. And for all that is holy, let me just say: What. The. Fuck. That\u0026#39;s 30 min of my life I can\u0026#39;t get back. I will replicate the highlights below so that you don\u0026#39;t have to read it yourself:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cspan style=\"color: #000000;\"\u003eAlthough the notion that negative findings deserve equal treatment may hold intuitive appeal, the very foundation of science rests on a profound asymmetry between positive and negative claims.  \u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eSuppose I assert the existence of some phenomenon, and you deny it; for example, I claim that some non-white swans exist, and you claim that none do (i.e., that no swans exist that are any color other than white).  Whatever our \u003cem\u003ea priori\u003c/em\u003e beliefs about the phenomenon, from an inductive standpoint, your negative claim (of nonexistence) is infinitely more tenuous than mine.  A single positive example is sufficient to falsify the assertion that something does not exist; one colorful swan is all it takes to rule out the impossibility that swans come in more than one color.  In contrast, negative examples can never establish the nonexistence of a phenomenon, because the next instance might always turn up a counterexample.  Prior to the turn of the 17\u003csup\u003eth\u003c/sup\u003e century, Europeans did indeed assume that all swans were white.  When European explorers observed black swans in Australia, this negative belief was instantly and permanently confuted.  Note the striking asymmetry here: a single positive finding (of a non-white swan) had more evidentiary value than millennia of negative observations.  What more, it is clear that the null claim cannot be reinstated by additional negative observations: rounding up trumpet after trumpet of white swans does not rescue the claim that no non-white swans exists [sic].\u003c/span\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e The graduate caucus of the ecology department at my undergrad institution published a handbook with a cover image that was just the text \u0026quot;p = 0.06\u0026quot; in huge, friendly letters. Ecology data can take ages to collect, and the right-of-passage of many graduate students was to go through months of collection, analyze the data, and get a (barely) non-significant result. Generally speaking, the scientific hierarchy does not reward non-significant results, and Mitchell tells us why: people who get them are just incompetent scientists. \u003c/p\u003e\n\u003cp\u003eMitchell\u0026#39;s implicit assumption - throughout the essay - is that all statistical effects are real, even though the very nature of frequentist statistics forces us to accept that some percentage of positive results are false. Mitchell does not seem to understand statistics or the scientific method. He is searching for swans. \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cspan style=\"color: #000000;\"\u003e[Other replication proponents agree that] any small number of failed experiments cannot dislodge a positive finding, but argues that we can nevertheless learn something important from the \u003c/span\u003e\u003cem\u003edistribution\u003c/em\u003e\u003cspan style=\"color: #000000;\"\u003e of effect sizes obtained using similar methods.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e  \u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eHowever, for most of the reasons above, such distributions will mainly describe the potency of our methods and those who use them, not the \u0026quot;realness\u0026quot; of an effect.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e  \u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eTo illustrate this, imagine that I ask a hundred people each to experimentally determine the relation between the temperature and pressure of a gas.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e  \u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eAlthough the \u0026quot;actual\u0026quot; relation is perfectly linear, the group will generate a distribution of effect sizes, and this distribution will depend entirely on the experimental skill of the researchers: a hundred physics graduate students using state-of-the-art equipment will generate a different distribution than a group of seventh-graders working out of their kitchens.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e  \u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eIn other words, distributions of effect sizes are no less dependent on the experimenters generating them than are single-point estimates. \u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e \u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eSuch distributions can, in a limited way, tell us something about the efficacy of experimenters and their methods, but they cannot be dispositive about whether a phenomenon \u0026quot;exists\u0026quot; or not. A repository of all attempted experiments might benefit our field, but only in the limited way of suggesting which methodsand experimentersmay be more or less robust, and not by bearing on the existence of a phenomenon.\u003c/span\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe pharmaceutical industry will be \u003ca href=\"https://www.ted.com/talks/ben_goldacre_what_doctors_don_t_know_about_the_drugs_they_prescribe\"\u003every relieved\u003c/a\u003e. The lowest p-values are just the most \u0026quot;right\u0026quot;. \u003c/p\u003e\n\u003cp\u003eAnd finally, the problem: \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cspan style=\"color: #292f33;\"\u003eHow do we identify replications that fail simply because of undetected experimenter error?\u003c/span\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eUh, do it again? \u003c/p\u003e\n\u003cp\u003eI agree with Mitchell about one thing: one should not do replication studies in an attempt to smear the original authors. If a replication \u0026quot;fails\u0026quot; (a poor word, because it does not distinguish between the experiment being done badly and being done well but failing to find a positive effect), something is fishy, and both groups should work together to find out what happened. That advances science. If they can\u0026#39;t, so be it. Working at the bleeding edge of knowledge means that some things \u0026quot;might\u0026quot; be true. \u003c/p\u003e\n\u003cp\u003eIt\u0026#39;s not even the idea that experiments should not be replicated that bugs me, it\u0026#39;s the idea that null results have no value. It\u0026#39;s the idea that negative results can be the result of error, but positive results can\u0026#39;t. In my own scientific experience, this is simply \u003ca href=\"http://www.caseyy.org/blog/rivers-vs-lakes-of-information-are-scientific-papers-the-news-or-the-encyclopedia/\" title=\"Rivers vs lakes of information: are scientific papers the news or the encyclopedia?\"\u003enot the case\u003c/a\u003e (admittedly in a different field, but from my limited knowledge isn\u0026#39;t social psychology more likely to be subject to systemic biases than fields where the research subject is not also a person?) Publication bias, the idea that positive results should be celebrated while negative ones are useless, has led to a host of problems across multiple fields, including incentivizing the fraud that Mitchell thinks is so rare.\u003c/p\u003e\n","md":"\r\nI've had essentially no time for reading lately as I'm doing SAHD thing, moving into a new house, and coding like a maniac whenever I get a spare hour, but there was so much buzz on Twitter around Jason Mitchell's essay [about replication studies in social psychology](http://wjh.harvard.edu/~jmitchel/writing/failed_science.htm) that I had to take a half-hour to read it. And for all that is holy, let me just say: What. The. Fuck. That's 30 min of my life I can't get back.I will replicate the highlights below so that you don't have to read it yourself:\r\n\r\n\u003e \u003cspan style=\"color: #000000;\"\u003eAlthough the notion that negative findings deserve equal treatment may hold intuitive appeal, the very foundation of science rests on a profound asymmetry between positive and negative claims.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eSuppose I assert the existence of some phenomenon, and you deny it; for example, I claim that some non-white swans exist, and you claim that none do (i.e., that no swans exist that are any color other than white).Whatever our*a priori*beliefs about the phenomenon, from an inductive standpoint, your negative claim (of nonexistence) is infinitely more tenuous than mine.A single positive example is sufficient to falsify the assertion that something does not exist; one colorful swan is all it takes to rule out the impossibility that swans come in more than one color.In contrast, negative examples can never establish the nonexistence of a phenomenon, because the next instance might always turn up a counterexample.Prior to the turn of the 17\u003csup\u003eth\u003c/sup\u003ecentury, Europeans did indeed assume that all swans were white.When European explorers observed black swans in Australia, this negative belief was instantly and permanently confuted.Note the striking asymmetry here: a single positive finding (of a non-white swan) had more evidentiary value than millennia of negative observations.What more, it is clear that the null claim cannot be reinstated by additional negative observations: rounding up trumpet after trumpet of white swans does not rescue the claim that no non-white swans exists [sic].\u003c/span\u003e\r\n\r\n The graduate caucus of the ecologydepartment at my undergrad institution published a handbook with acover image that was just the text \"p = 0.06\" in huge, friendly letters. Ecology data can take ages to collect, and the right-of-passage of many graduate students was to go through months of collection, analyze the data, and get a (barely) non-significant result. Generally speaking, the scientific hierarchy does not reward non-significant results, and Mitchell tells us why: people who get them are just incompetent scientists. \r\n \r\nMitchell's implicit assumption - throughout the essay - is that all statistical effects are real, even though the very nature of frequentist statistics forces us to accept that some percentage of positive results are false. Mitchell does not seem to understand statistics or the scientific method. He is searching for swans. \r\n\r\n\u003e \u003cspan style=\"color: #000000;\"\u003e[Other replication proponents agree that] any small number of failed experiments cannot dislodge a positive finding, but argues that we can nevertheless learn something important from the\u003c/span\u003e*distribution*\u003cspan style=\"color: #000000;\"\u003eof effect sizes obtained using similar methods.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eHowever, for most of the reasons above, such distributions will mainly describe the potency of our methods and those who use them, not the \"realness\" of an effect.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eTo illustrate this, imagine that I ask a hundred people each to experimentally determine the relation between the temperature and pressure of a gas.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eAlthough the \"actual\" relation is perfectly linear, the group will generate a distribution of effect sizes, and this distribution will depend entirely on the experimental skill of the researchers: a hundred physics graduate students using state-of-the-art equipment will generate a different distribution than a group of seventh-graders working out of their kitchens.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eIn other words, distributions of effect sizes are no less dependent on the experimenters generating them than are single-point estimates.\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003e\u003c/span\u003e\u003cspan style=\"color: #000000;\"\u003eSuch distributions can, in a limited way, tell us something about the efficacy of experimenters and their methods, but they cannot be dispositive about whether a phenomenon \"exists\" or not. A repository of all attempted experiments might benefit our field, but only in the limited way of suggesting which methodsand experimentersmay be more or less robust, and not by bearing on the existence of a phenomenon.\u003c/span\u003e\r\n\r\nThe pharmaceutical industry will be [very relieved](https://www.ted.com/talks/ben_goldacre_what_doctors_don_t_know_about_the_drugs_they_prescribe). The lowestp-values are just the most \"right\". \r\n\r\nAnd finally, the problem: \r\n\r\n\u003e \u003cspan style=\"color: #292f33;\"\u003eHow do we identify replications that fail simply because of undetected experimenter error?\u003c/span\u003e\r\n\r\nUh, do it again? \r\n\r\nI agree with Mitchell about one thing: one should not do replication studies in an attempt to smear the original authors. If a replication \"fails\" (a poor word, because it does not distinguish between the experiment being done badly and being done well but failing to find a positive effect), something is fishy, and both groups should work together to find out what happened. That advances science. If they can't, so be it. Working at the bleedingedge of knowledge meansthat some things \"might\" be true. \r\n\r\nIt's not even the idea that experiments should not be replicated that bugs me, it's the idea that null results have no value. It's the idea that negative resultscan be the result of error, but positive results can't. In my own scientific experience, this is simply [not the case](http://www.caseyy.org/blog/rivers-vs-lakes-of-information-are-scientific-papers-the-news-or-the-encyclopedia/ \"Rivers vs lakes of information: are scientific papers the news or the encyclopedia?\")(admittedly in a different field, but from my limited knowledge isn't social psychologymore likely to be subject to systemic biases than fields where the research subject is not also a person?) Publication bias, the idea that positive results should be celebrated while negative ones are useless, has led to a host of problems across multiple fields, including incentivizing the fraud that Mitchell thinks is so rare."}},"publishedDate":{"$date":"2014-07-04T06:00:00.000Z"}}
{"_id":{"$oid":"5802f47231c9af6010bb4fd3"},"slug":"damn-you-reviewer-3-and-1-and-2","title":"Damn you reviewer #3! And #1 and #2 ...","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eCharles Greenberg made the following comment on my previous post \u003ca href=\"http://www.caseyy.org/blog/clay-shirkys-cognitive-surplus-and-the-open-science-movement/\" title=\"Clay Shirkys Cognitive Surplus and the open science movement\"\u003ecomparing the open science movement to the open-source software movement and Wikipedia\u003c/a\u003e:\u003c/p\u003e\n","md":"\r\nCharles Greenberg made the following comment on my previous post [comparing the open science movement to the open-source software movement and Wikipedia](http://www.caseyy.org/blog/clay-shirkys-cognitive-surplus-and-the-open-science-movement/ \"Clay Shirkys Cognitive Surplus and the open science movement\"):"},"extended":{"html":"\u003cp\u003eCharles Greenberg made the following comment on my previous post \u003ca href=\"http://www.caseyy.org/blog/clay-shirkys-cognitive-surplus-and-the-open-science-movement/\" title=\"Clay Shirkys Cognitive Surplus and the open science movement\"\u003ecomparing the open science movement to the open-source software movement and Wikipedia\u003c/a\u003e:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eput everything out there and let the record correct itself in an age of search engine optimization and offshore pay-per-click opportunities is really not a well thought out proposition. All the places where you can see alt-metric assessment of quality continue to rely upon a first pass of editorial oversight and basic peer review. This co-exists with the explosion of dirt cheap and even predatory publishing that increases the quantity of the record. Wheres the incentive to correct the record? Perhaps providing new vehicles of post-peer review that in themselves offer academic status or credit, rather than mechanically derived metrics that offer something, yet nothing explicit. Faculty of 1000 is (was) an attempt to do this, yet do we end up with a credible record? Does anyone get good or useful credit for being a Faculty of 1000 reviewer?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e Perhaps the language \u0026quot;let the record correct itself\u0026quot; was a bit flippant. I\u0026#39;m not advocating a \u003cem\u003elassaiz faire\u003c/em\u003e approach to peer-review, I\u0026#39;m simply saying that with publication as prevalent as it is, the ability to publish is no longer the bottleneck it once was, and so bad papers \u003cstrong\u003ewill get published.\u003c/strong\u003e The question now is how we sort the bad papers from the good. Altmetrics and open review aren\u0026#39;t just possible now, they\u0026#39;re necessary, because any other method of assessing quality depends on trusting decisions that are made in secret. \u003c/p\u003e\n\u003cp\u003eI just got reviews on my last paper, and they are terrible. Out of three reviewers, two of them hated the paper and the third thought it was OK. I\u0026#39;ve left my postdoc lab, the actual content of the paper is not going to change much. \u003c/p\u003e\n\u003cp\u003eAnd you know what? Nobody doubts that it will eventually be published: not the editor, not my former boss, who\u0026#39;s done this sort of thing before many times, and probably not the reviewers themselves. And not me. It will go to a different journal, a \u0026quot;lesser journal\u0026quot;, in more or less it\u0026#39;s current form, after we spend days wrangling with the text to see what we can keep and what we have to ditch. Since it will be published anyway, this process is a stupid waste of time. It\u0026#39;s not a great piece of work: there are things we could have done if we\u0026#39;d had more time, but it contains data and insights that might be useful. It should be published, or the time I spent working on it was just wasted. We delivered the best we could with the time and resources we had. \u003c/p\u003e\n\u003cp\u003eAnd now we have to spend more time on something that has been done, that will be published, just to make sure it gets the right amount of points so the people who are keeping score are satisfied. There is literally no other purpose to this exercise.\u003c/p\u003e\n","md":"\r\nCharles Greenberg made the following comment on my previous post [comparing the open science movement to the open-source software movement and Wikipedia](http://www.caseyy.org/blog/clay-shirkys-cognitive-surplus-and-the-open-science-movement/ \"Clay Shirkys Cognitive Surplus and the open science movement\"):\r\n\r\n\u003e put everything out there and let the record correct itself in an age of search engine optimization and offshore pay-per-click opportunities is really not a well thought out proposition. All the places where you can see alt-metric assessment of quality continue to rely upon a first pass of editorial oversight and basic peer review. This co-exists with the explosion of dirt cheap and even predatory publishing that increases the quantity of the record. Wheres the incentive to correct the record? Perhaps providing new vehicles of post-peer review that in themselves offer academic status or credit, rather than mechanically derived metrics that offer something, yet nothing explicit. Faculty of 1000 is (was) an attempt to do this, yet do we end up with a credible record? Does anyone get good or useful credit for being a Faculty of 1000 reviewer?\r\n\r\n Perhaps the language \"let the record correct itself\" was a bit flippant. I'm not advocating a *lassaiz faire*approach to peer-review, I'm simply saying that withpublication as prevalent as it is, the ability to publishis no longer the bottleneck it once was, and so bad papers**will get published.** The question now is how we sort the bad papers from the good. Altmetrics and open review aren't just possible now, they're necessary, because any other method of assessing quality depends on trusting decisions that are made in secret. \r\n\r\nI just got reviews on my last paper, and they are terrible.Out of three reviewers, two of them hated the paper and the third thought it was OK. I've left my postdoc lab, the actual content of the paper is not going to change much. \r\n\r\nAnd you know what? Nobody doubts that itwill eventually be published: not the editor, not my former boss, who's done this sort of thing before many times, and probably not the reviewers themselves. And not me. It will go to a different journal, a \"lesser journal\", in more or less it's current form, after we spend days wrangling with the text to see what we can keep and what we have to ditch. Since it will be published anyway, this process is a stupid waste of time. It's not a great piece of work:there are things we could have done if we'd had more time, but it contains data and insights that might be useful. It should be published, or the time I spent working on it wasjust wasted. We delivered the best we could with the time and resources we had. \r\n\r\nAnd now we have to spend more time on something that has been done, that will be published, just to make sure it gets the right amount of points so the people who are keeping score are satisfied. There is literally no other purpose to this exercise."}},"publishedDate":{"$date":"2014-07-14T06:00:00.000Z"}}
{"_id":{"$oid":"5802f4b131c9af6010bb4fd4"},"slug":"pnas-envy","title":"PNAS envy","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eLast week, \u003cem\u003eNature\u003c/em\u003e published \u003ca href=\"http://www.nature.com/news/scientific-publishing-the-inside-track-1.15424\"\u003ea news item analyzing the use of the so-called \u0026quot;contributed\u0026quot;\u003c/a\u003e track at \u003cem\u003eProceedings of the National Academy of Science\u003c/em\u003es (also called PNAS). For those who aren\u0026#39;t aware, members of the National Academy of Sciences \u0026quot;can submit up to four papers per year to [PNAS], through the \u0026#39;contributed\u0026#39; publication track. This unusual process allows authors to choose who will review their paper and how to respond to those reviewers\u0026#39; comments.\u0026quot; \u003c/p\u003e\n","md":"\r\nLast week,*Nature*published [a news item analyzing the use of the so-called \"contributed\"](http://www.nature.com/news/scientific-publishing-the-inside-track-1.15424) track at*Proceedings of the National Academy of Science*s (also called PNAS). For those who aren't aware,members of the National Academy of Sciences \"can submit up to four papers per year to [PNAS], through the 'contributed' publication track. This unusual process allows authors to choose who will review their paper and how to respond to those reviewers' comments.\" "},"extended":{"html":"\u003cp\u003eLast week, \u003cem\u003eNature\u003c/em\u003e published \u003ca href=\"http://www.nature.com/news/scientific-publishing-the-inside-track-1.15424\"\u003ea news item analyzing the use of the so-called \u0026quot;contributed\u0026quot;\u003c/a\u003e track at \u003cem\u003eProceedings of the National Academy of Science\u003c/em\u003es (also called PNAS). For those who aren\u0026#39;t aware, members of the National Academy of Sciences \u0026quot;can submit up to four papers per year to [PNAS], through the \u0026#39;contributed\u0026#39; publication track. This unusual process allows authors to choose who will review their paper and how to respond to those reviewers\u0026#39; comments.\u0026quot; \u003c/p\u003e\n\u003cp\u003eYup, senior scientists get to bypass peer-review, or at least use a version of it unavailable to the steerage of the research world. 98% of contributed papers are accepted at PNAS, compared to 18% of \u0026quot;direct\u0026quot; submissions, and attract fewer citations. The contributed tracks\u0026#39; \u0026quot;power users\u0026quot; (who have submitted at close to the maximum allowable rate for the past decade) claim that this version of peer-review is not a \u0026quot;free ride\u0026quot;, although the lack of transparency in the publication process in general makes this a hard claim to verify. But there are also noble reasons for choosing the contributed track:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e[M]any of the contributed track\u0026#39;s power users believe that increased competition for space in high-profile journals has allowed editors and reviewers to become more demanding. Being able to publish four high-profile papers with much less grief than the usual high-prestige journal  that\u0026#39;s worth something, says Snyder. Some of the power users, including Snyder and Mak, add that the contributed track benefits postdoctoral researchers or students in their laboratories who are searching for jobs and need high-profile publications more quickly than the review time at \u003cem\u003eNature\u003c/em\u003e or \u003cem\u003eScience\u003c/em\u003e would allow. Complaints about nitpicking reviews at \u003cem\u003eNature\u003c/em\u003e and \u003cem\u003eScience\u003c/em\u003e go hand-in-hand with the charge that the editors at these journals are in thrall to trendy areas of research. Very often what seems to be fashionable is not very good science, says Croce.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e And all this time I\u0026#39;d been thinking that the greybeards are protecting the publication status-quo because they\u0026#39;re experienced enough to navigate it. But it turns out: they\u0026#39;re just as frustrated with the peer-review system as everyone else is! So they publish in PNAS. How do we expect change when the people in power are insulated from the problems of everyone else? And are any of these \u0026quot;power users\u0026quot; as concerned about the pain of publishing in a glam journal for non-NAS members as they are about how it might affect their own postdocs? And lastly, how do you defend the claim that this is not an old boys club?\u003c/p\u003e\n","md":"\r\nLast week,*Nature*published [a news item analyzing the use of the so-called \"contributed\"](http://www.nature.com/news/scientific-publishing-the-inside-track-1.15424) track at*Proceedings of the National Academy of Science*s (also called PNAS). For those who aren't aware,members of the National Academy of Sciences \"can submit up to four papers per year to [PNAS], through the 'contributed' publication track. This unusual process allows authors to choose who will review their paper and how to respond to those reviewers' comments.\" \r\n\r\nYup, senior scientists get to bypass peer-review, or at least use a version of it unavailable to the steerage of the research world. 98% of contributed papers are accepted at PNAS, compared to 18% of \"direct\" submissions, and attract fewer citations. The contributed tracks' \"power users\" (who have submitted at close to the maximum allowable rate for the past decade) claim that this version of peer-review is not a \"free ride\", althoughthe lack of transparency in thepublication process in general makes this a hard claim to verify. But there are also noble reasons for choosing the contributed track:\r\n\r\n\u003e [M]any of the contributed track's power users believe that increased competition for space in high-profile journals has allowed editors and reviewers to become more demanding. Being able to publish four high-profile papers with much less grief than the usual high-prestige journal  that's worth something, says Snyder. Some of the power users, including Snyder and Mak, add that the contributed track benefits postdoctoral researchers or students in their laboratories who are searching for jobs and need high-profile publications more quickly than the review time at*Nature*or*Science*would allow. Complaints about nitpicking reviews at*Nature*and*Science*go hand-in-hand with the charge that the editors at these journals are in thrall to trendy areas of research. Very often what seems to be fashionable is not very good science, says Croce.\r\n\r\n And all this time I'd been thinking that the greybeards are protecting the publication status-quo because they're experienced enough to navigate it. But it turns out: they're just as frustrated with the peer-review system as everyone else is! So they publish in PNAS. How do we expect change when the people in power are insulated from the problems of everyone else? And are any of these \"power users\" as concernedabout the pain of publishing in a glam journal fornon-NAS membersas they are about how it might affecttheir own postdocs?And lastly, how do you defend the claim that this is not an old boys club?"}},"publishedDate":{"$date":"2014-06-04T06:00:00.000Z"}}
{"_id":{"$oid":"5802f50431c9af6010bb4fd5"},"slug":"clay-shirkys-cognitive-surplus-and-the-open-science-movement","title":"Clay Shirky's \"Cognitive Surplus\" and the open science movement","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI recently finished Clay Shirkey\u0026#39;s \u0026quot;Cognitive Surplus\u0026quot; and there are a number of great points in here relevant to the open science movement. This might seem a little surprising given the central thesis of the book: for academics, contributing to knowledge creation and dissemination is not really \u0026quot;surplus\u0026quot;, it\u0026#39;s their job. Nevertheless, the values at the heart of the open source software movement, Wikipedia, and so on, are really the inspiration for open science, with the added kick that if so much has been done by people working for free, a class of professionals paid to contribute to human knowledge should be able to do even more.\u003c/p\u003e\n","md":"\r\nI recently finished Clay Shirkey's \"Cognitive Surplus\" and there are a number of great points in here relevant to the open science movement. This might seem a little surprising given the central thesis of the book: for academics, contributing to knowledge creation and dissemination is not really \"surplus\", it's their job. Nevertheless, the values at the heart of the open source software movement, Wikipedia, and so on, are really the inspiration for open science, with the added kick that if somuch has been doneby people working for free, a class of professionals paid to contribute to human knowledge should be able to do even more."},"extended":{"html":"\u003cp\u003eI recently finished Clay Shirkey\u0026#39;s \u0026quot;Cognitive Surplus\u0026quot; and there are a number of great points in here relevant to the open science movement. This might seem a little surprising given the central thesis of the book: for academics, contributing to knowledge creation and dissemination is not really \u0026quot;surplus\u0026quot;, it\u0026#39;s their job. Nevertheless, the values at the heart of the open source software movement, Wikipedia, and so on, are really the inspiration for open science, with the added kick that if so much has been done by people working for free, a class of professionals paid to contribute to human knowledge should be able to do even more.\u003c/p\u003e\n\u003cp\u003eHere are some key quotes from the book relevant to open access and open science:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCuriously, an organization that commits to helping society manage a problem also commits itself to the preservation of that same problem, as its institutional existence hinges on society\u0026#39;s continued need for its management.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e The examples of this we are currently seeing include the tension between the hospitality industry and AirBNB, and between taxi companies and carpooling apps. Oh, and academic publishers vs open access publishers. \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe great tension in media has always been that freedom and quality are conflicting goals. There have always been people willing to argue that an increase in freedom to publish isn\u0026#39;t worth the decrease in average quality.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e He goes on to quote Martin Luther and Edgar Allen Poe saying exactly that. \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e[W]hen publication - the act of making something public - goes from being hard to being virtually effortless, people used to the old system often regard publishing by amateurs as frivolous, as if publishing was an inherently serious activity. In never was , though. Publishing had to be taken seriously when its cost and effort made people take it seriously - if you made too many mistakes, you were out of business. But if these factors collapse, then the risk collapses, too. An activity that once seemed inherently valuable turned out to be only accidentally valuable, as a change in the economics revealed.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e Here\u0026#39;s the message for us: the decrease in overall quality of the scientific literature IS happening. It\u0026#39;s here to stay. Whatever model of peer review we choose, there will always be a place to publish bad papers, because publication itself is cheap as dirt. But this is also an opportunity. Since publication is cheap, we have the chance to simply determine quality post-publication. Publishing itself is no longer the bottleneck it once was, and so the chance to put everything out there and let the record correct itself is now here.\u003c/p\u003e\n","md":"\r\nI recently finished Clay Shirkey's \"Cognitive Surplus\" and there are a number of great points in here relevant to the open science movement. This might seem a little surprising given the central thesis of the book: for academics, contributing to knowledge creation and dissemination is not really \"surplus\", it's their job. Nevertheless, the values at the heart of the open source software movement, Wikipedia, and so on, are really the inspiration for open science, with the added kick that if somuch has been doneby people working for free, a class of professionals paid to contribute to human knowledge should be able to do even more.\r\n\r\nHere are some key quotes from the book relevant to open access and open science:\r\n\r\n\u003e Curiously, an organization that commits to helping society manage a problem also commits itself to the preservation of that same problem, as its institutional existence hinges on society's continued need for its management.\r\n\r\n The examples of this we are currently seeing includethe tension between the hospitality industry and AirBNB, and between taxi companies and carpooling apps. Oh, and academic publishers vs open access publishers. \r\n \r\n \u003e The great tension in media has always been that freedom and quality are conflicting goals. There have always been people willing to argue that an increase in freedom to publish isn't worth the decrease in average quality.\r\n\r\n He goes on to quote Martin Luther and Edgar Allen Poe saying exactly that. \r\n \r\n \u003e [W]hen publication - the act of making something public - goes from being hard to being virtually effortless, people used to the old system often regard publishing by amateurs as frivolous, as if publishing was an inherently serious activity. In never was , though. Publishing had to be taken seriously when its cost and effort made people take it seriously - if you made too many mistakes, you were out of business. But if these factors collapse, then the risk collapses, too. An activity that once seemed inherently valuable turned out to be only accidentally valuable, as a change in the economics revealed.\r\n\r\n Here's the message for us: the decrease in overall quality of the scientific literature IS happening. It's here to stay. Whatever model of peer review we choose, there will always be a place to publish bad papers, because publication itself is cheap as dirt. But this is also an opportunity. Since publication is cheap, we have the chance to simply determine quality post-publication. Publishing itself is no longer the bottleneck it once was, and so the chance to put everything out there and let the record correct itself is now here."}},"publishedDate":{"$date":"2014-06-14T06:00:00.000Z"}}
{"_id":{"$oid":"5802f56631c9af6010bb4fd6"},"slug":"rivers-vs-lakes-of-information-are-scientific-papers-the-news-or-the-encyclopedia","title":"Rivers vs lakes of information: are scientific papers \"the news\" or \"the encyclopedia\"?","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eIn \u003ca href=\"http://www.caseyy.org/blog/what-im-reading-present-shock-when-everything-happens-now-by-douglas-rushkoff/\" title=\"What Im reading: Present Shock: When Everything Happens Now, by Douglas Rushkoff\"\u003ePresent Shock\u003c/a\u003e by Douglas Rushkoff, the author makes a distinction between communications that have value as a result of being current versus communications that have value as a result of being curated, accurate and complete. You can think of one like a river - information that is constant flowing, and the other like a lake - information that is discarded when it becomes obsolete but comparatively stays quite stable over time. \u003c/p\u003e\n","md":"\r\nIn [Present Shock](http://www.caseyy.org/blog/what-im-reading-present-shock-when-everything-happens-now-by-douglas-rushkoff/ \"What Im reading: Present Shock: When Everything Happens Now, by Douglas Rushkoff\")by Douglas Rushkoff, the author makes a distinction between communications that have value as a result of being current versus communications that have value as a result of being curated, accurate and complete. You can think of one like a river - information that is constant flowing, and the other like a lake - information that is discarded when it becomes obsolete but comparatively stays quite stable over time. "},"extended":{"html":"\u003cp\u003eIn \u003ca href=\"http://www.caseyy.org/blog/what-im-reading-present-shock-when-everything-happens-now-by-douglas-rushkoff/\" title=\"What Im reading: Present Shock: When Everything Happens Now, by Douglas Rushkoff\"\u003ePresent Shock\u003c/a\u003e by Douglas Rushkoff, the author makes a distinction between communications that have value as a result of being current versus communications that have value as a result of being curated, accurate and complete. You can think of one like a river - information that is constant flowing, and the other like a lake - information that is discarded when it becomes obsolete but comparatively stays quite stable over time. \u003c/p\u003e\n\u003cp\u003eThink of the newspaper vs the encyclopedia: one is useless almost the next day and the other only needs to be updated every few years, but in general contains a higher quality of reporting. Both types of information are needed, but for different reasons. \u003c/p\u003e\n\u003cp\u003eI think that a lot of the confusion and debate over the role and inadequacy of the scientific literature stems from the fact that we expect it to be both of these things at once. People object to the end of peer review because it will because it then be ridiculously easy to add to the scientific cannon. We expect papers to contain a high quality of information: edited, peer-reviewed, and generally speaking, \u003cem\u003eright\u003c/em\u003e. But the actual scientific process is almost incomprehensibly messy, and way that ideas are discarded or adopted more closely resembles a river than a lake. Nevertheless, the whole body of the scientific literature is out there: readable, citable, and - except in the rare case of retraction - immutable. \u003c/p\u003e\n\u003cp\u003eTo take an example from my field, a debate erupted in 2011 over whether filaments in a part of the cell called the lamellipodium are branched or linear. Advances in electron microscopy techniques had prompted a reevaluation of the \u003ca href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2133125/\"\u003eexistence of branched filaments in living cells\u003c/a\u003e. Using more advanced \u0026quot;tomography\u0026quot; techniques, Vic Small\u0026#39;s group \u003ca href=\"http://www.ncbi.nlm.nih.gov/pubmed/20418872\"\u003econcluded that the branch junctions which had been previously observed did not exist\u003c/a\u003e (paywalled), and the earlier, more crude analysis performed by Tatyana Svitkina\u0026#39;s lab had produced the branches artificially during the preparation of the cells for the microscope. For a brief period, Small reveled in his role as a challenger to the scientific status-quo, publishing a \u003ca href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2984616/\"\u003ecommentary piece\u003c/a\u003e titled \u0026quot;Dicing with dogma: Debranching the lamellipodium\u0026quot;. This lasted until the Svitkina group got Small\u0026#39;s data: they looked for the \u003ca href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3407679/\"\u003ebranches and found them\u003c/a\u003e. Positive data trumped negative data, and Small had to concede that his group had simply missed the branchpoints in his earlier analysis. \u003c/p\u003e\n\u003cp\u003eWhile this was ongoing, the literature resembled a river even more strongly: the original paper was not retracted; instead numerous commentary pieces simply cited it, adding to the conversation but not rewriting it (and adding to the impact factor of the original, wrong, study). I don\u0026#39;t think the whole story is fairly represented anywhere in a single publication. In short, there is no encyclopedia entry for this in the scientific literature; one has to piece it together from reading the newspaper articles. \u003c/p\u003e\n\u003cp\u003eAlso in 2011, \u003ca href=\"http://www.ncbi.nlm.nih.gov/pubmed/21127214\"\u003ea paper strongly implying that a particular bacterium can incorporate arsenic into DNA instead of phosphorous\u003c/a\u003e (paywalled) was published in \u003cem\u003eScience\u003c/em\u003e, and was \u003ca href=\"http://rrresearch.fieldofscience.com/2010/12/arsenic-associated-bacteria-nasas.html\"\u003ealmost instantly identified as containing numerous errors in methodology and analysis\u003c/a\u003e. A subsequent study \u003ca href=\"http://arxiv.org/abs/1201.6643\"\u003econcluded that the was no arsenic in the DNA of that bacterium\u003c/a\u003e. As of today, the paper has not been retracted. Perhaps it should not be, because the data in the paper were not wrong, only the implications. The most unfortunate thing is that the findings are actually important, but they are less grandiose than was imagined than the authors, and so once again the whole story is not told anywhere, but in a series of commentaries and letters to the editor. \u003c/p\u003e\n\u003cp\u003eIf we expect papers to be lakes, shouldn\u0026#39;t authors\u0026#39; be able to update them after publication? And if we expect them to be rivers, why hide them until they\u0026#39;ve vetted by peer-review? Isn\u0026#39;t this system the worst of both worlds? \u003c/p\u003e\n\u003cp\u003eThe biggest place this seems to be an issue is when direct replication studies are being performed. I find it strange that even when we know that concepts like statistical significance are just calculations about the probability of whether a hypothesis is true, we still want to be able to \u0026quot;accept\u0026quot; or \u0026quot;reject\u0026quot; hypotheses and \u0026quot;invalidate\u0026quot; conclusions. With a few exceptions, most things we know in science are not true or untrue, they simply have a probability of being true given the data at hand. I\u0026#39;m not qualified to judge \u003ca href=\"http://www.spspblog.org/simone-schnall-on-her-experience-with-a-registered-replication-project/\"\u003ethe back-and-forth that\u0026#39;s going on the psychology literature at the moment\u003c/a\u003e, but here\u0026#39;s my read as an experimentalist in a different field: experiments do not really analyze general phenomena. They analyze phenomena which occur in very specific, controlled conditions, which \u003cstrong\u003eby implication\u003c/strong\u003e point to general phenemena when that becomes the most likely explanation for the results. Failure to replicate, especially in a field like psychology, does not point to sloppiness, error, or fraud. But it does make it less likely that the outcome of the experiment illustrates a general phenomenon. Getting to the truth has to involve a conversation, an open mind, and open debate. As I wrote in my \u003ca href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3218376/\"\u003epiece about the Small-Svitkina controversy\u003c/a\u003e,\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eT\u003cspan style=\"color: #000000;\"\u003ehis recent debate serves as an important reminder that seemingly irreconcilable views can in fact reveal deeper truth, when both sides relentlessly pursue that end.\u003c/span\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e In any case, the practice of publishing papers and expecting that the results will simply be \u0026quot;accepted\u0026quot; and folded into the scientific cannon surely has to stop.\u003c/p\u003e\n","md":"\r\nIn [Present Shock](http://www.caseyy.org/blog/what-im-reading-present-shock-when-everything-happens-now-by-douglas-rushkoff/ \"What Im reading: Present Shock: When Everything Happens Now, by Douglas Rushkoff\")by Douglas Rushkoff, the author makes a distinction between communications that have value as a result of being current versus communications that have value as a result of being curated, accurate and complete. You can think of one like a river - information that is constant flowing, and the other like a lake - information that is discarded when it becomes obsolete but comparatively stays quite stable over time. \r\n\r\nThink of the newspaper vs the encyclopedia: one is useless almost the next day and the other only needs to be updated every few years, but in general contains a higher quality of reporting. Both types of information are needed, but for different reasons. \r\n\r\nI think that a lot of the confusion and debate over the role and inadequacy of the scientific literature stems from the fact that we expect it to be both of these things at once. People object to the end of peer review because it will because it then be ridiculously easy to add to the scientific cannon. We expect papers to contain a high quality of information: edited, peer-reviewed, and generally speaking,*right*. But the actual scientific process is almost incomprehensibly messy, and way that ideas are discarded or adopted more closely resembles a river than a lake. Nevertheless, the whole body of the scientific literature is out there: readable, citable, and - except in the rare case of retraction - immutable. \r\n\r\nTo take an example frommy field, a debate erupted in 2011 over whether filaments in a part of the cell called the lamellipodium are branched or linear. Advances in electron microscopy techniques had prompted a reevaluation of the [existence of branched filaments in living cells](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2133125/). Using more advanced \"tomography\"techniques, Vic Small's group [concluded that the branch junctions which had been previously observed did not exist](http://www.ncbi.nlm.nih.gov/pubmed/20418872)(paywalled), and the earlier, more crudeanalysis performed by TatyanaSvitkina's lab had produced the branches artificially during the preparation of the cells for the microscope. For a brief period, Small reveled in his role as a challenger to the scientific status-quo, publishing a [commentary piece](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2984616/) titled \"Dicing with dogma: Debranching the lamellipodium\". This lasted until the Svitkina group got Small's data: they looked for the [branches and found them](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3407679/). Positive data trumped negative data, and Small had to concede that his group had simply missed the branchpoints in his earlier analysis. \r\n\r\nWhile this was ongoing, the literature resembled a river even more strongly: the original paper was not retracted; instead numerous commentary pieces simply cited it, adding to the conversation but not rewriting it (and adding to the impact factor of the original, wrong, study). I don't think the whole story is fairlyrepresented anywhere in a single publication. In short, there is no encyclopedia entry for this in the scientific literature; one has to piece it together from reading the newspaper articles. \r\n\r\nAlso in 2011, [a paper strongly implying that a particular bacterium can incorporate arsenic into DNA instead of phosphorous](http://www.ncbi.nlm.nih.gov/pubmed/21127214)(paywalled) was published in *Science*, and was [almost instantly identified ascontaining numerous errors in methodology and analysis](http://rrresearch.fieldofscience.com/2010/12/arsenic-associated-bacteria-nasas.html). A subsequent study [concluded that the was no arsenic in the DNA of that bacterium](http://arxiv.org/abs/1201.6643). As of today, the paper has not been retracted. Perhaps it should not be, because thedata in the paper were not wrong, only the implications. The most unfortunate thing is that the findings are actually important, but they are less grandiose than was imagined than the authors, and so once again the whole story is not told anywhere, but in a series of commentaries and letters to the editor. \r\n\r\nIf we expect papers to be lakes, shouldn't authors' be able to update them after publication? And if we expect them to be rivers, why hide them until they've vetted by peer-review? Isn't this system the worst of both worlds? \r\n\r\nThe biggest place this seems to be an issue is when direct replication studies are being performed. I find it strange that even whenwe know that concepts like statistical significance are just calculations about the probability of whether ahypothesis is true, we still want to be able to \"accept\" or \"reject\" hypotheses and \"invalidate\" conclusions. With a few exceptions, most things we know in science are not true or untrue, they simply have a probability of being true given the data at hand. I'm not qualified to judge [the back-and-forth that's going on the psychology literature at the moment](http://www.spspblog.org/simone-schnall-on-her-experience-with-a-registered-replication-project/), but here's my read as an experimentalist in a different field: experiments do not really analyze general phenomena. They analyze phenomena which occur in very specific, controlled conditions, which**by implication** point to general phenemena when that becomes the most likely explanation for the results. Failure to replicate, especially in a field like psychology, does not point to sloppiness, error, or fraud. But it does make it less likely that the outcome of the experiment illustrates a general phenomenon. Getting to the truth has to involve a conversation, an open mind, and open debate. As I wrote in my [piece about the Small-Svitkina controversy](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3218376/),\r\n\r\n\u003e T\u003cspan style=\"color: #000000;\"\u003ehis recent debate serves as an important reminder that seemingly irreconcilable views can in fact reveal deeper truth, when both sides relentlessly pursue that end.\u003c/span\u003e\r\n\r\n In any case, the practice of publishing papers and expecting that the results will simply be \"accepted\" and folded into the scientific cannon surely has to stop."}},"publishedDate":{"$date":"2014-06-01T06:00:00.000Z"}}
{"_id":{"$oid":"5802f59e31c9af6010bb4fd7"},"slug":"open-science-how-do-we-track-contributions-across-the-whole-internet","title":"Open Science: How do we track contributions across the whole internet?","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI\u0026#39;ve had two discussions recently with organizations trying to implement open science-type platforms, and the conversation keeps coming back to the same thing: \u0026quot;How do we get people to contribute?\u0026quot;\u003c/p\u003e\n","md":"\r\nI've had two discussionsrecently with organizations trying to implement open science-type platforms, and the conversationkeeps coming back to the same thing: \"How do weget people to contribute?\""},"extended":{"html":"\u003cp\u003eI\u0026#39;ve had two discussions recently with organizations trying to implement open science-type platforms, and the conversation keeps coming back to the same thing: \u0026quot;How do we get people to contribute?\u0026quot; \u003c/p\u003e\n\u003cp\u003eMaybe this is a silly question. Clay Shirky argues that \u003ca href=\"http://www.ted.com/talks/clay_shirky_how_cognitive_surplus_will_change_the_world\"\u003etrying to understand why people contribute to Wikipedia\u003c/a\u003e (or other crowdsourced projects) in raw economic terms makes no sense. There is literally no reason for it, except that people have free time and would rather spend some of it creating as well as consuming media (ie, watching TV or surfing the web). \u003c/p\u003e\n\u003cp\u003eStill, I think when it comes to post-publication peer review, crowdsourced knowledge repositories, and the other ventures in open science, getting some amount of recognition for contributions can only help. This doesn\u0026#39;t only apply only to open science, and sites as diverse as Wikipedia and Stack Overflow have their own ways of assessing reputation, but I think it becomes more critical in the academic realm. The key thing to keep in mind is that - for academics - recognition is currency. Recognition is everything. It affects hiring, tenure, promotion, pay, and reputation, which is key to getting more opportunities to get recognized. Right now, recognition comes mostly in the form of authorship on papers, and one\u0026#39;s academic worth can be measured in the number and \u0026quot;quality\u0026quot; of those publications (though quality is by nature subjective and difficult to measure, so a poor stand-in is often the perceived quality of the journal in which the paper appears). \u003c/p\u003e\n\u003cp\u003eA very slow process of change is underway, whereby \u003ca href=\"https://impactstory.org/\"\u003equality can be more directly measured\u003c/a\u003e, and \u0026quot;contributions\u0026quot; can be considered viable units of research output instead of just papers. Contributions could include data, code, reagents, post-publication reviews, and edits to knowledge repositories. There are many ways one can contribute to knowledge creation and dissemination, and the scientific community is right to begin to reward those of them which go beyond publishing in high-profile journals. Whether or not we actually get to the point where contributing data or post-pub reviews is taken into account in hiring and tenure decisions is dubious, but I think it\u0026#39;s somewhat beside the point. Academics already review papers, sit on study section, edit journals, organize conferences, and sometimes even put a little effort into their teaching responsibilities, all of which might not necessarily impact their future pay or prospects. \u003c/p\u003e\n\u003cp\u003eThese things (usually) go on a CV. Where should we track them in the digital age? One place might be on academics own websites, with links to all the relevant places, but (for now) this would require a large amount of maintenance (it should be noted that maintaining a CV is no small task, in and of itself). Another place would be ORCID, which could be considered a digital CV. A recent \u003ca href=\"http://pigsonthewing.org.uk/orcid-plugin-for-wordpress/\"\u003eORCID plugin for Wordpress\u003c/a\u003e provides a step forward here - now blogposts and even comments can be associated with an ORCID profile. Theoretically, they could therefore be tracked. I\u0026#39;m interested to see where this goes. \u003c/p\u003e\n\u003cp\u003eAt another level, we\u0026#39;ll need a way to count whether these contributions are meaningful. A poor-quality dataset is both easy to create and of little value to anyone. A blog that no one reads is of little immediate value, although everyone has to start somewhere (please tell your friends about my blog). Do we need altmetrics for these other contributions, too? \u003ca href=\"https://www.addgene.org/search/advanced/?q=GFP\"\u003eAddGene\u003c/a\u003e provides an interesting case study here, I believe. A search for \u0026quot;GFP\u0026quot; revealed 2357 plasmids. Beyond assuring that the sequence of each of these is exactly right, which of these is the best one for me to use? Similarly, if I deposit a plasmid that gets highly used, should I be recognized for that in some way? Since AddGene sends out the plasmids themselves, they must have this information available. \u003c/p\u003e\n\u003cp\u003eThe consensus largely exists that assessing value only through the glam-publication game is hurting science. We understand very well why people keep publishing there: because it helps their careers. Change the metrics that matter, change what people get recognized for, and you change science.\u003c/p\u003e\n","md":"\r\nI've had two discussionsrecently with organizations trying to implement open science-type platforms, and the conversationkeeps coming back to the same thing: \"How do weget people to contribute?\" \r\n\r\nMaybe this is a silly question. Clay Shirky argues that [trying to understand why people contribute to Wikipedia](http://www.ted.com/talks/clay_shirky_how_cognitive_surplus_will_change_the_world)(or other crowdsourced projects) in raw economic terms makes no sense. There is literally no reason for it, except that people have free time and would rather spend some of it creating as well as consuming media (ie, watching TV or surfing the web). \r\n\r\nStill, I think when it comes to post-publication peer review, crowdsourced knowledge repositories, and the other ventures in open science, getting some amount of recognition for contributions can only help. This doesn't onlyapply only to open science,andsites as diverse as Wikipedia and Stack Overflow havetheir own ways of assessing reputation, but I think it becomes more critical in the academic realm. Thekey thing to keep in mind is that - for academics -recognition is currency. Recognition is everything. It affects hiring, tenure, promotion, pay, and reputation, which is key to getting more opportunities to get recognized. Right now, recognition comes mostly in the form of authorship on papers, and one's academic worth can be measured in the number and \"quality\" of those publications (though quality is by nature subjective and difficult to measure, so apoor stand-in is often the perceived quality of the journal in which the paper appears). \r\n\r\nA very slow process of change is underway, whereby [quality can be more directly measured](https://impactstory.org/), and \"contributions\" can be considered viable units of research output instead of just papers. Contributions could include data, code, reagents, post-publication reviews, and editsto knowledge repositories. There are many ways one can contribute to knowledge creation and dissemination, and the scientific community is right to begin to reward those of them which go beyond publishing in high-profile journals. Whether or not we actuallyget to the point where contributing data or post-pub reviews is taken into account in hiring and tenure decisions is dubious, but I think it'ssomewhat beside the point. Academics already review papers, sit on study section, edit journals, organize conferences, and sometimes even put a little effort into their teaching responsibilities, allof which might not necessarily impact their future pay or prospects. \r\n\r\nThese things (usually) go on a CV. Where should we track them in the digital age? One place might be on academics own websites, with links to all the relevant places, but (for now) this would require a large amount of maintenance (it should be noted that maintaining a CV is no small task, in and of itself). Another place would be ORCID, which could be considereda digital CV. A recent [ORCID plugin for Wordpress](http://pigsonthewing.org.uk/orcid-plugin-for-wordpress/) provides a step forward here- now blogposts and even comments can be associated with an ORCID profile. Theoretically, they could therefore be tracked. I'm interested to see where this goes. \r\n\r\nAt another level, we'll need a way to count whether these contributions are meaningful. A poor-quality dataset is both easy to create and of little value to anyone. A blog that no one reads is of little immediate value, although everyone has to start somewhere (please tell your friends about my blog). Do we need altmetrics for these other contributions, too? [AddGene](https://www.addgene.org/search/advanced/?q=GFP) provides an interesting case study here, I believe.A search for \"GFP\" revealed 2357 plasmids. Beyond assuring that the sequence of each of these is exactly right, which of these is the best one for me to use? Similarly, if I deposit a plasmid that gets highly used, should I be recognized for that in some way? Since AddGene sends out the plasmids themselves, they must have this information available. \r\n\r\nThe consensus largely exists that assessing value only through the glam-publication game is hurting science. We understand very wellwhy people keep publishing there: because it helps their careers. Change the metrics that matter, change what people get recognized for, and you change science."}},"publishedDate":{"$date":"2014-05-24T06:00:00.000Z"}}
{"_id":{"$oid":"5802f6d731c9af6010bb4fd8"},"slug":"consciously-uncoupling-from-academia","title":"Consciously uncoupling from academia","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI have reached a point in my academic career where there is nothing to be gained from staying any longer. \u003ca href=\"/meta-analysis-of-im-leaving-research-blog-posts/\"\u003eI\u0026#39;m luckier than most\u003c/a\u003e: my spouse has received a teaching position in our home country and the salary is enough to support our family for a while. I\u0026#39;ve had time to plan this and I\u0026#39;ve been investing in skills beyond the lab bench. We\u0026#39;re moving to a place with a bustling economy and low unemployment. \u003c/p\u003e\n","md":"\r\nI have reached a point in my academic career where there is nothing to be gained from staying any longer. [I'm luckier than most](/meta-analysis-of-im-leaving-research-blog-posts/): my spouse has received a teaching position in our home country and the salary is enough to support our family for a while. I've had time to plan this and I've been investing in skills beyond the lab bench. We're moving to a place with a bustling economy and low unemployment. "},"extended":{"html":"\u003cp\u003eI have reached a point in my academic career where there is nothing to be gained from staying any longer. \u003ca href=\"/meta-analysis-of-im-leaving-research-blog-posts/\"\u003eI\u0026#39;m luckier than most\u003c/a\u003e: my spouse has received a teaching position in our home country and the salary is enough to support our family for a while. I\u0026#39;ve had time to plan this and I\u0026#39;ve been investing in skills beyond the lab bench. We\u0026#39;re moving to a place with a bustling economy and low unemployment. \u003c/p\u003e\n\u003cp\u003eOn the flip side, it goes without saying that this isn\u0026#39;t really what I had in mind when I started grad school. It is very likely that the role I end up in will be one that doesn\u0026#39;t require a Ph.D., and certainly not a postdoc, and so however you slice it, much of the past eleven years has been a waste of time. The biggest thing that the \u003ca href=\"http://www.caseyy.org/blog/what-fraction-of-phd-training-is-wasted-the-hidden-variable/\" title=\"What fraction of PhD training is wasted? A hidden variable in the debate\"\u003eprofessoriate opposed to reducing graduate enrollment\u003c/a\u003e does not seem to understand is the that there is an opportunity cost associated with keeping so many people in a profession when it\u0026#39;s clear there is no sustainable role for them. Leaving-academia blog posts have become a \u003ca href=\"http://www.caseyy.org/blog/meta-analysis-of-im-leaving-research-blog-posts/\" title=\"Meta-analysis of Im leaving research blog posts\"\u003ebit of a thing\u003c/a\u003e, lately, and some people have questioned why you never see people writing about how they left academia because they just \u003ca href=\"https://twitter.com/edyong209/statuses/454958990460747776\"\u003eweren\u0026#39;t very good\u003c/a\u003e. \u003c/p\u003e\n\u003cp\u003eSo, fine, in the interests of full disclosure, I am not very good. While I excel at finding the bottom line of an experiment - while simultaneously grasping its complexity - there\u0026#39;s a huge difference between explaining research and doing it. For me, doing experiments and having them work has always been a struggle, and unlike most other human endeavors, it doesn\u0026#39;t seem to get easier with time. Worse yet, I can\u0026#39;t teach experimentation effectively. Every student I\u0026#39;ve ever supervised has struggled under me, too, and I\u0026#39;ve never been able to strike a balance between helicoptering and abandonment that made the student comfortable and allowed work to get done. In many ways I\u0026#39;ve been fortunate enough to discover this short-coming early on. \u003c/p\u003e\n\u003cp\u003eHowever, the part of science where I really and truly suck is the grant-writing process. I applied for many fellowships at the beginning of both of my postdocs, and had to swallow rejection after rejection after rejection without ever getting any feedback. This is probably the single most frustrating thing about my academic experience. For a profession that is ostensibly about teaching and research, there is very little teaching outside of the lecture halls. We teach experimentation by placing a graduate student at the bench and seeing what they can do. We teach writing by telling them to write it up. We have an army of professors that don\u0026#39;t know how to teach because they haven\u0026#39;t been taught how to teach, just like they haven\u0026#39;t been taught how to manage their labs or grant money. Every single grad student or postdoc is expected to be the captain of their own ship, and each generation just rediscovers for themselves their own \u0026quot;best practices\u0026quot;. We don\u0026#39;t watch each other, we don\u0026#39;t learn from each other, and as a result there are no standards for the research process, and so the the outcomes of \u003ca href=\"http://www.nature.com/nature/journal/v483/n7391/full/483531a.html\"\u003eresearch cannot be trusted\u003c/a\u003e. The pleasing stories are still there, but the majority of them are castles in the sky. \u003c/p\u003e\n\u003cp\u003eA friend of mine wrote that if he won the lottery, he would perform basic research for free. I\u0026#39;m envious of his passion. It\u0026#39;s hard for me to feel enthusiasm anymore for something that I feel is so deliberately wasteful of taxpayer\u0026#39;s money, and of young people\u0026#39;s ambition. I read the \u0026quot;\u003ca href=\"http://www.pnas.org/content/early/2014/04/09/1404402111\"\u003eRescuing US biomedical research\u003c/a\u003e\u0026quot; paper with a mix of bemusement and sadness. Bemusement because so many of the problems are articulations of why I\u0026#39;m leaving, and sadness because it\u0026#39;s too late for me, and - given the rate at which things seem to really change in academia - probably everyone I know who is currently a graduate student or postdoc. Maybe the undergrads I work with might be able to find staff scientist positions someday, but anyone currently hanging on is deluding themselves. In all likelihood things are going to get worse before they get better. \u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eFor every flaw I see in the academic system, there is something I love about the discipline of science itself. For nearly four billion years life on this planet has been the very unreasonable byproduct of microscopic strings of information trying to make copies of themselves. Even more unlikely, in the last century we became \u003cstrong\u003eaware of it.\u003c/strong\u003e The ability to understand and interrogate the world is without doubt the greatest human endeavor we have engaged in, and I feel incredibly fortunate to have been part of it while I could. So long, and thanks for all the fish.\u003c/p\u003e\n","md":"\r\nI have reached a point in my academic career where there is nothing to be gained from staying any longer. [I'm luckier than most](/meta-analysis-of-im-leaving-research-blog-posts/): my spouse has received a teaching position in our home country and the salary is enough to support our family for a while. I've had time to plan this and I've been investing in skills beyond the lab bench. We're moving to a place with a bustling economy and low unemployment. \r\n\r\nOn the flip side, it goes without saying that this isn't really what I had in mind when I started grad school. It is very likely that the role I end up in will be one that doesn't require a Ph.D., and certainly not a postdoc, and so however you slice it, much of the past eleven years has been a waste of time. The biggest thing that the [professoriate opposed to reducing graduate enrollment](http://www.caseyy.org/blog/what-fraction-of-phd-training-is-wasted-the-hidden-variable/ \"What fraction of PhD training is wasted? A hidden variable in the debate\") does not seem to understand is the that there is an opportunity cost associated with keeping so many people in a profession when it's clear there is no sustainablerole for them. Leaving-academia blog posts have become a [bit of a thing](http://www.caseyy.org/blog/meta-analysis-of-im-leaving-research-blog-posts/ \"Meta-analysis of Im leaving research blog posts\"), lately, and some people have questioned why you never see people writing about how they left academia because they just [weren't very good](https://twitter.com/edyong209/statuses/454958990460747776). \r\n\r\nSo, fine, in the interests of full disclosure, I am not very good. WhileI excel at finding the bottom line of an experiment - while simultaneously grasping its complexity - there's a huge difference between explaining research and doing it. For me, doing experiments and having them work has always been a struggle, and unlike most other human endeavors, it doesn't seem to get easier with time. Worse yet, I can't teach experimentation effectively. Every student I've ever supervised has struggled under me, too, and I've never been able to strike a balance between helicoptering and abandonment that made the student comfortable and allowed work to get done. In many ways I've been fortunate enough to discover this short-coming early on. \r\n\r\nHowever, the part of science where I really and truly suck is the grant-writing process. I applied for many fellowships at the beginning of both of my postdocs, and had to swallow rejection after rejection after rejection without ever getting any feedback. This is probably the single most frustrating thing about my academic experience. For a profession that is ostensibly about teaching and research, there is very little teaching outside of the lecture halls. We teach experimentation by placing a graduate student at the bench and seeing what they can do. We teach writing by telling them to write it up. We have an army of professors that don't know how to teach because they haven't been taught how to teach, just like they haven't been taught how to manage their labs or grant money. Every single grad student or postdoc is expected to be the captain of their own ship, and each generation just rediscovers for themselves their own \"best practices\". We don't watch each other, we don't learn from each other, and as a resultthere are no standards for the research process, and so the the outcomes of [research cannot be trusted](http://www.nature.com/nature/journal/v483/n7391/full/483531a.html). The pleasing stories are still there, but the majority of them are castles in the sky. \r\n\r\nA friend of mine wrote that if he won the lottery, he would perform basic research for free. I'm envious of his passion. It's hard for me to feel enthusiasm anymore for something that I feel is so deliberately wasteful of taxpayer's money, and of young people's ambition. I read the \"[Rescuing US biomedical research](http://www.pnas.org/content/early/2014/04/09/1404402111)\" paper with a mix of bemusement and sadness. Bemusement because so many of the problems are articulations of why I'm leaving, and sadness because it's too late for me, and - given the rate at which things seem to really change in academia - probably everyone I know who is currently a graduate student or postdoc. Maybe the undergrads I work with might be able to find staff scientist positions someday, but anyone currently hanging on is deluding themselves. In all likelihood things are going to get worse before they get better. \r\n\r\n***\r\n\r\nFor every flaw I see in the academic system, there is something I love about the discipline of science itself. For nearly four billion years life on this planet has been the very unreasonable byproduct of microscopic strings of information trying to make copies of themselves. Even more unlikely, in the last century we became**aware of it.** The ability to understand and interrogate the world is without doubt the greatest human endeavor we have engaged in, and I feel incredibly fortunate to have been part of it while I could. So long, and thanks for all the fish."}},"publishedDate":{"$date":"2014-05-03T06:00:00.000Z"}}
{"_id":{"$oid":"5803a79f74664abd2fad00d5"},"sortOrder":1,"slug":"t8n-magazine","title":"T8N Magazine","__t":"Project","tech":[{"$oid":"57edd1aeecd6d32a6890f974"},{"$oid":"57edd1c8ecd6d32a6890f976"},{"$oid":"57edd1bcecd6d32a6890f975"}],"state":"archived","__v":1,"author":{"$oid":"5803a93774664abd2fad00d6"},"brief":"Online version of St. Albert's monthly magazine","links":{"code":"","site":"http://www.t8nmagazine.com/"},"myRole":{"html":"\u003cp\u003ePart of my role during early phases of the project was in advising the client about the advantages and limitations of designing content for the web versus for a print publication. Graphos was able to produce a unique design for several templates that worked across the many different types of articles that T8N produces.\u003c/p\u003e\n\u003cp\u003eI coded the website in accordance with Graphos\u0026#39; designs and specifications from the client. The project was a natural fit for WordPress and made use of many of its \u0026quot;natural\u0026quot; CMS capabilities (including categories and tags). The website also uses custom solutions for displaying the current weather (drawn from \u003ca href=\"https://darksky.net/dev/docs\"\u003eDarkSky\u003c/a\u003e) and for querying the most-viewed articles.\u003c/p\u003e\n","md":"Part of my role during early phases of the project was in advising the client about the advantages and limitations of designing content for the web versus for a print publication. Graphos was able to produce a unique design for several templates that worked across the many different types of articles that T8N produces.\r\n\r\nI coded the website in accordance with Graphos' designs and specifications from the client. The project was a natural fit for WordPress and made use of many of its \u0026quot;natural\u0026quot; CMS capabilities (including categories and tags). The website also uses custom solutions for displaying the current weather (drawn from [DarkSky](https://darksky.net/dev/docs)) and for querying the most-viewed articles."},"problem":{"html":"\u003cp\u003eT8N Magazine is a relatively new publication serving the St. Albert, Alberta community. They came to Graphos to upgrade their \u0026quot;brochure\u0026quot; website (with a PDF-embedded version of the print publication) to a full content-driven online magazine.\u003c/p\u003e\n","md":"T8N Magazine is a relatively new publication serving the St. Albert, Alberta community. They came to Graphos to upgrade their \u0026quot;brochure\u0026quot; website (with a PDF-embedded version of the print publication) to a full content-driven online magazine."},"status":{"html":"\u003cp\u003eT8N\u0026#39;s writers currently use the CMS to enter about 30 new articles each month. The website gets approximately 3000 page views per month, and I maintain the code base by applying updates and responding to new feature requests.\u003c/p\u003e\n","md":"T8N's writers currently use the CMS to enter about 30 new articles each month. The website gets approximately 3000 page views per month, and I maintain the code base by applying updates and responding to new feature requests.\r\n"},"publishedDate":{"$date":"2015-12-01T05:00:00.000Z"},"image":{"secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1534365119/qo4tlgdtbjlzc65lnmjo.png","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1534365119/qo4tlgdtbjlzc65lnmjo.png","resource_type":"image","format":"png","height":557,"width":800,"signature":"db6dc6dfd56647c2ba0e3be7127765d59d7204e6","version":1534365119,"public_id":"qo4tlgdtbjlzc65lnmjo"}}
{"_id":{"$oid":"5803bab674664abd2fad00da"},"sortOrder":4,"slug":"wp-impactpubs","title":"wp-impactpubs","__t":"Project","tech":[{"$oid":"57edd1aeecd6d32a6890f974"},{"$oid":"57edd1c8ecd6d32a6890f976"}],"state":"published","__v":1,"author":{"$oid":"57cddf32d75ea10a19c42073"},"brief":"WordPress plugin to output a publication list pulled from a third-party source","links":{"code":"","site":"http://www.can.ubc.ca/the-science-of-applied-neurogenetics/publications/"},"myRole":{"html":"\u003cp\u003eI began by creating a WordPress plugin which simply imported a list of publications from a third-party source, saved it to the database, and displayed it in response to shortcode. This allowed the user to create a publications list and display it wherever she wanted it on her website. It was designed such that a separate list could be created for each WordPress user, and a cron was included to make sure it stayed up-to-date with whatever source was being used. I called this plugin wp-impactpubs (or just ImpactPubs) because the major third-party source that I targeted is ImpactStory.\u003c/p\u003e\n","md":"I began by creating a WordPress plugin which simply imported a list of publications from a third-party source, saved it to the database, and displayed it in response to shortcode. This allowed the user to create a publications list and display it wherever she wanted it on her website. It was designed such that a separate list could be created for each WordPress user, and a cron was included to make sure it stayed up-to-date with whatever source was being used. I called this plugin wp-impactpubs (or just ImpactPubs) because the major third-party source that I targeted is ImpactStory."},"problem":{"html":"\u003cp\u003eVirtually all academic scientists have a relatively simple website containing information about their labs. These sites typically include a list of lab members, ongoing projects, cool images or protocols that people might be looking for, a list of the labs publications. Labs are not commercial entities, and very few of these sites are professionally developed, and most are not updated frequently. The publications list is the most arduous part of the website to maintain by hand, because it changes frequently and because it requires reformatting complex bibliographic text into HTML. Nevertheless, any given scientist\u0026#39;s publication info might be available at any number of publicly available, automatically updated locations.\u003c/p\u003e\n","md":"Virtually all academic scientists have a relatively simple website containing information about their labs. These sites typically include a list of lab members, ongoing projects, cool images or protocols that people might be looking for, a list of the labs publications. Labs are not commercial entities, and very few of these sites are professionally developed, and most are not updated frequently. The publications list is the most arduous part of the website to maintain by hand, because it changes frequently and because it requires reformatting complex bibliographic text into HTML. Nevertheless, any given scientist's publication info might be available at any number of publicly available, automatically updated locations."},"publishedDate":{"$date":"2016-10-15T04:00:00.000Z"},"status":{"html":"\u003cp\u003eA beautifully-designed implementation can be seen at \u003ca href=\"http://www.can.ubc.ca/the-science-of-applied-neurogenetics/publications/\"\u003eUBC\u0026#39;s Centre for Applied Neurogenetics\u003c/a\u003e and the code can be found on \u003ca href=\"https://github.com/CAYdenberg/wp-impactpubs\"\u003eGitHub\u003c/a\u003e. The plugin is also available at the \u003ca href=\"https://wordpress.org/plugins/impactpubs/\"\u003eWordPress plugins repository\u003c/a\u003e.\u003c/p\u003e\n","md":"A beautifully-designed implementation can be seen at [UBC's Centre for Applied Neurogenetics](http://www.can.ubc.ca/the-science-of-applied-neurogenetics/publications/) and the code can be found on [GitHub](https://github.com/CAYdenberg/wp-impactpubs). The plugin is also available at the [WordPress plugins repository](https://wordpress.org/plugins/impactpubs/)."},"image":{"secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1534365235/g6lckmnwemgreosg8jfq.png","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1534365235/g6lckmnwemgreosg8jfq.png","resource_type":"image","format":"png","height":693,"width":720,"signature":"5fd54cce64dd0ff4be7bcae99bd440568e74bbc6","version":1534365235,"public_id":"g6lckmnwemgreosg8jfq"}}
{"_id":{"$oid":"5803bb5974664abd2fad00db"},"sortOrder":0,"slug":"chartjs","title":"Chart.js","__t":"Project","tech":[{"$oid":"57edd06c8a31cb06684b45a2"}],"state":"archived","__v":1,"author":{"$oid":"57cddf32d75ea10a19c42073"},"brief":"Extension to a popular JavaScript graphing solution","links":{"code":"https://github.com/CAYdenberg/Chart.js-ErrorBars","site":""},"myRole":{"html":"\u003cp\u003eI added support for error bars on bar and line Charts, by adding a new error bar chart element and two new chart types. The fork can be used either as a standalone library or an extension.\u003c/p\u003e\n","md":"I added support for error bars on bar and line Charts, by adding a new error bar chart element and two new chart types. The fork can be used either as a standalone library or an extension."},"problem":{"html":"\u003cp\u003eChart.js by Nick Downie (@nnnick) was created to make animated plots using the HTML5 canvas element. He originally wrote it to support bar, line, and three types of pie chart. I needed it for scientific purposes which required adding features.\u003c/p\u003e\n","md":"Chart.js by Nick Downie (@nnnick) was created to make animated plots using the HTML5 canvas element. He originally wrote it to support bar, line, and three types of pie chart. I needed it for scientific purposes which required adding features."},"publishedDate":{"$date":"2016-10-16T04:00:00.000Z"},"status":{"html":"\u003cp\u003e\u003ca href=\"https://github.com/CAYdenberg/Chart.js\"\u003eMy fork of this repository\u003c/a\u003e has been starred 32 times and was additionally forked twice. There are have been two almost-complete re-writes of the library, and I have branches that work with both Chart.js 1.0 and Chart.js 2.0. A formal API for plugins has now been established, so the next step will be to refactor the extension as a plugin.\u003c/p\u003e\n","md":"[My fork of this repository](https://github.com/CAYdenberg/Chart.js) has been starred 32 times and was additionally forked twice. There are have been two almost-complete re-writes of the library, and I have branches that work with both Chart.js 1.0 and Chart.js 2.0. A formal API for plugins has now been established, so the next step will be to refactor the extension as a plugin."}}
{"_id":{"$oid":"5805830374664abd2fad00dc"},"sortOrder":6,"slug":"monocle","title":"Monocle","__t":"Project","tech":[{"$oid":"57edd234ecd6d32a6890f979"},{"$oid":"57edd06c8a31cb06684b45a2"},{"$oid":"57edd229ecd6d32a6890f978"}],"state":"archived","__v":1,"author":{"$oid":"57cddf32d75ea10a19c42073"},"brief":"Browsing interface to view scientific papers in Lens","links":{"code":"https://github.com/CAYdenberg/monocle/","site":"http://ncbi.site/"},"myRole":{"html":"\u003cp\u003eIvan\u0026#39;s project made heavy use of jQuery to retrieve, parse, and render search results, which made refactoring difficult. I used parts of the codebase to begin \u003ca href=\"https://github.com/CAYdenberg/monocle\"\u003emy own version of the app\u003c/a\u003e based on Node.js and React, which I call Monocle. This streamlined the UI and made iterating on development much quicker. It also allowed cleaner separation of the logic: I have released standalone modules handling the \u003ca href=\"https://github.com/CAYdenberg/node-ncbi\"\u003ePMC API\u003c/a\u003e and a \u003ca href=\"https://github.com/CAYdenberg/lens-starter\"\u003ededicated Lens parser\u003c/a\u003e that may be useful in their own right. Further development will proceed from here.\u003c/p\u003e\n","md":"Ivan's project made heavy use of jQuery to retrieve, parse, and render search results, which made refactoring difficult. I used parts of the codebase to begin [my own version of the app](https://github.com/CAYdenberg/monocle) based on Node.js and React, which I call Monocle. This streamlined the UI and made iterating on development much quicker. It also allowed cleaner separation of the logic: I have released standalone modules handling the [PMC API](https://github.com/CAYdenberg/node-ncbi) and a [dedicated Lens parser](https://github.com/CAYdenberg/lens-starter) that may be useful in their own right. Further development will proceed from here."},"problem":{"html":"\u003cp\u003e\u003ca href=\"http://lens.elifesciences.org/\"\u003eeLife Lens provides a novel way of reading scientific papers\u003c/a\u003e that is web-centric: it separates text from figures and allows easy navigation throughout the article. Lens was originally developed by Ivan Grubisic in collaboration with the open-access publisher eLife, and is now used on their website. Lens was released as open-source code, and is being used by several other journals. Because it works by parsing NLM XML (an XML format used by most publishers to produce the PDF and HTML versions of their articles already) it could theoretically be used to read content from any journal, as long as the XML is available and can be legally scraped.\u003c/p\u003e\n\u003cp\u003ePubMed Central (PMC) is a free, online repository of biomedical papers from thousands of journals (even subscription journals deposit papers there after an embargo period). Of these, a subset are truly open-access, and the NLM XML is publically available. Ivan Grubisic built a JavaScript app which uses the PMC API to search the open-access literature and return results that can be viewed with Lens. It thus represents the broadest implementation of Lens on the web, in the sense that it can access the greatest fraction of the literature.\u003c/p\u003e\n","md":"[eLife Lens provides a novel way of reading scientific papers](http://lens.elifesciences.org/) that is web-centric: it separates text from figures and allows easy navigation throughout the article. Lens was originally developed by Ivan Grubisic in collaboration with the open-access publisher eLife, and is now used on their website. Lens was released as open-source code, and is being used by several other journals. Because it works by parsing NLM XML (an XML format used by most publishers to produce the PDF and HTML versions of their articles already) it could theoretically be used to read content from any journal, as long as the XML is available and can be legally scraped.\r\n\r\nPubMed Central (PMC) is a free, online repository of biomedical papers from thousands of journals (even subscription journals deposit papers there after an embargo period). Of these, a subset are truly open-access, and the NLM XML is publically available. Ivan Grubisic built a JavaScript app which uses the PMC API to search the open-access literature and return results that can be viewed with Lens. It thus represents the broadest implementation of Lens on the web, in the sense that it can access the greatest fraction of the literature."},"publishedDate":{"$date":"2016-10-16T04:00:00.000Z"},"status":{"html":"","md":""},"image":{"secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1534365332/tfossgp7fwcdhnj3yr9x.png","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1534365332/tfossgp7fwcdhnj3yr9x.png","resource_type":"image","format":"png","height":608,"width":1138,"signature":"fb4a521ce0508cfe0d5c61689db2ef43fe5772ba","version":1534365332,"public_id":"tfossgp7fwcdhnj3yr9x"}}
{"_id":{"$oid":"580696a8a85812cc21ce45a5"},"slug":"meta-analysis-of-im-leaving-research-blog-posts","title":"Meta-analysis of \"I'm leaving research\" blog posts","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eEven though I have known for some time now that a career in academia is not for me, blog posts about people being forced out of academia still tug at my heart strings in a way I can\u0026#39;t quite explain.\u003c/p\u003e\n","md":"Even though I have known for some time now that a career in academia is not for me, blog posts about people being forced out of academia still tug at my heart strings in a way I can't quite explain."},"extended":{"html":"\u003cp\u003eEven though I have known for some time now that a career in academia is not for me, blog posts about people being forced out of academia still tug at my heart strings in a way I can\u0026#39;t quite explain. Dreams are dreams, and whether you simply grow apart from them, as I have, or whether you have no choice in the matter, as many of my contemporaries do, there will always be a lament for what might have been. And maybe it\u0026#39;s the bad economy (but didn\u0026#39;t this crisis hit almost \u003cstrong\u003efive years ago now\u003c/strong\u003e - that\u0026#39;s the length of grad school or a postdoc - an entire lab\u0026#39;s turnover of wasted careers), or maybe it\u0026#39;s the increasing connectedness of the world, or maybe it\u0026#39;s that as I continue to scan the horizon to find out what\u0026#39;s ahead, I seek out people in a similar situation, but there \u003ca href=\"http://beangirls.blogspot.com/2013/03/on-leaving-scientific-research-again.html\"\u003ehave been\u003c/a\u003e  \u003ca href=\"http://biochembelle.wordpress.com/2013/04/07/when-the-odds-beat-you/\"\u003ea lot\u003c/a\u003e  \u003ca href=\"http://blog.devicerandom.org/2011/02/18/getting-a-life/\"\u003eof these\u003c/a\u003e  lately. \u003c/p\u003e\n\u003cp\u003eOne I find myself reading over and over again, is by Kevin Zelnio, formerly writing for Deep Sea News. In his farewell post titled \u003ca href=\"http://deepseanews.com/2013/02/19294/\"\u003e\u0026quot;I must go down to the seas again, to the lonely sea and the sky\u0026quot;\u003c/a\u003e he writes a long lament for a why he found a life in science incompatible with  being good husband and father, and eventually had to choose between them. Maybe it\u0026#39;s the honesty and the humility of it, but as far as the messy world of blogging goes, I consider this a masterpiece. Kevin does not pretend to have done everything right, he readily admits his to own mistakes, both professional and personal. His admissions come across as plainly as his passion for the life he\u0026#39;s leaving behind.  The horrible tragedy of all of this, of course, is that while perhaps none of these people had \u0026quot;what it takes\u0026quot; to succeed in science today, each of them possess the raw passion and \u003cem\u003esome\u003c/em\u003e of the skills needed to make research work. No one person has\u003cem\u003e all \u003c/em\u003e of the talents needed to develop a product, bring it market, and sell it, but that is exactly what we\u0026#39;re trying to in the research enterprise today. The current system selects for exactly one type of personality: the brilliant grantsmith. Everything else is done by trainees aspiring to be that grantsmith. Fail to become that, and there\u0026#39;s no room for you. Peter Medawar wrote, in a very different time:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eScientists are people of very dissimilar temperaments doing different things in very different ways. Among scientists are collectors, classifiers and compulsive tidiers-up; many are detectives by temperament and many are explorers; some are artists and others artisans. There are poet-scientists and philosopher-scientists and even a few mystics.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThat world, obviously, is gone. This is exactly what\u0026#39;s been so painful about the \u0026quot;public journeyman science exploits of Ethan Perlstein.\u0026quot; Dr. Perlstein is currently attempted to crowdfund his research (using yeast as a pharmacological model) after losing his funding as a research fellow at Princeton and failing to land a tenure-track position (full disclosure: Dr. Perlstein and I overlapped briefly at Princeton but had little direct contact). Three anonymous science bloggers who go by the names of DrugMonkey, Proflikesubtsance and Comrade Physioprof, all of whom are - allegedly - professors \u003cem\u003esomewhere\u003c/em\u003e, reacted somewhat violently to certain comments he made about whether or not landing that job contained an element of luck, as well as the limitations of scientists depending entirely on government grants. \u0026gt; Your anger at having washed out despite every possible leg up is understandable but dude, a little introspection. @\u003ca href=\"https://twitter.com/eperlste\"\u003eeperlste\u003c/a\u003e @\u003ca href=\"https://twitter.com/rxnm_\"\u003erxnm_\u003c/a\u003e  Drug Monkey (@drugmonkeyblog) \u003ca href=\"https://twitter.com/drugmonkeyblog/status/316971845565960192\"\u003eMarch 27, 2013\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eWhether the breakup was the fault of Dr. Perlstein\u0026#39;s or The System\u0026#39;s is not a question I\u0026#39;m very qualified to judge, and it doesn\u0026#39;t really interest me. What has struck me is that all three of the critics admit to varying degrees that Dr. Perlstein is a solid scientist in most respects: what he lacks is salesmanship. \u0026gt; .@\u003ca href=\"https://twitter.com/eperlste\"\u003eeperlste\u003c/a\u003e not really. You had some big advantages working for you. Crafting a sell perhaps the only lack  Drug Monkey (@drugmonkeyblog) \u003ca href=\"https://twitter.com/drugmonkeyblog/status/332222053216313345\"\u003eMay 8, 2013\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eIn one post that I had a pretty viscerally negative reaction to, Proflikesubtance extolled the virtues of \u003ca href=\"http://scientopia.org/blogs/proflikesubstance/2013/05/09/like-it-or-not-youre-in-sales/\"\u003esalesmanship in grantsmithing\u003c/a\u003e. \u0026quot;Without being able to pitch your research plan to an audience (whoever has the money) and convince them that you have a worthy investment, you aren\u0026#39;t going to be able to continue to do science.\u0026quot; Some of the commentors took issue with the borrowing of business terms, or with the creation of an ends-justify-the-means mindset. He took aim at Dr. Perlstein in particular in his post, and I thought: \u0026quot;Really? \u003cem\u003eThat\u0026#39;s\u003c/em\u003e what keeping him from having a career in science?\u0026quot; Isn\u0026#39;t there a way we could envision this where someone does the science and \u003cem\u003esomeone else\u003c/em\u003e sells it? This is, according to one commentor \u003cem\u003edefending\u003c/em\u003e PLS\u0026#39;s point of view, how Darwin and Huxley did it (though I think - hope - they wouldn\u0026#39;t have called it \u0026quot;selling\u0026quot;). It\u0026#39;s also how Microsoft, Apple, and pretty much every company in world with more than two employeers conducts business. No one expects software developers to go out and pitch their products to customers. And therein lies the critical difference: companies are teams that work together for a time for mutual benefit. Academia is about \u003cem\u003eme\u003c/em\u003e, \u003cem\u003emy\u003c/em\u003e first author paper, \u003cem\u003emy\u003c/em\u003e grant, \u003cem\u003emy\u003c/em\u003e science. Figuring out a way to make someone else\u0026#39;s research interesting is as beneficial to your long-term survival in research as helping a fellow student in a bell curve-graded course.\u003c/p\u003e\n","md":"\r\nEven though I have known for some time now that a career in academia is not for me, blog posts about people being forced out of academia still tug at my heart strings in a way I can't quite explain. Dreams are dreams, and whether you simply grow apart from them, as I have, or whether you have no choice in the matter, as many of my contemporaries do, there will always be a lament for what might have been. And maybe it's the bad economy (but didn't this crisis hit almost **five years ago now** - that's the length of grad school or a postdoc - an entire lab's turnover of wasted careers), or maybe it's the increasing connectedness of the world, or maybe it's that as I continue to scan the horizon to find out what's ahead, I seek out people in a similar situation, but there [have been](http://beangirls.blogspot.com/2013/03/on-leaving-scientific-research-again.html)  [a lot](http://biochembelle.wordpress.com/2013/04/07/when-the-odds-beat-you/)  [of these](http://blog.devicerandom.org/2011/02/18/getting-a-life/)  lately. \r\n\r\nOne I find myself reading over and over again, is by Kevin Zelnio, formerly writing for Deep Sea News. In his farewell post titled [\"I must go down to the seas again, to the lonely sea and the sky\"](http://deepseanews.com/2013/02/19294/) he writes a long lament for a why he found a life in science incompatible with  being good husband and father, and eventually had to choose between them. Maybe it's the honesty and the humility of it, but as far as the messy world of blogging goes, I consider this a masterpiece. Kevin does not pretend to have done everything right, he readily admits his to own mistakes, both professional and personal. His admissions come across as plainly as his passion for the life he's leaving behind.  The horrible tragedy of all of this, of course, is that while perhaps none of these people had \"what it takes\" to succeed in science today, each of them possess the raw passion and *some* of the skills needed to make research work. No one person has* all * of the talents needed to develop a product, bring it market, and sell it, but that is exactly what we're trying to in the research enterprise today. The current system selects for exactly one type of personality: the brilliant grantsmith. Everything else is done by trainees aspiring to be that grantsmith. Fail to become that, and there's no room for you. Peter Medawar wrote, in a very different time:\r\n\r\n\u003e Scientists are people of very dissimilar temperaments doing different things in very different ways. Among scientists are collectors, classifiers and compulsive tidiers-up; many are detectives by temperament and many are explorers; some are artists and others artisans. There are poet-scientists and philosopher-scientists and even a few mystics.\r\n\r\nThat world, obviously, is gone. This is exactly what's been so painful about the \"public journeyman science exploits of Ethan Perlstein.\" Dr. Perlstein is currently attempted to crowdfund his research (using yeast as a pharmacological model) after losing his funding as a research fellow at Princeton and failing to land a tenure-track position (full disclosure: Dr. Perlstein and I overlapped briefly at Princeton but had little direct contact). Three anonymous science bloggers who go by the names of DrugMonkey, Proflikesubtsance and Comrade Physioprof, all of whom are - allegedly - professors *somewhere*, reacted somewhat violently to certain comments he made about whether or not landing that job contained an element of luck, as well as the limitations of scientists depending entirely on government grants. \u003e Your anger at having washed out despite every possible leg up is understandable but dude, a little introspection. @[eperlste](https://twitter.com/eperlste) @[rxnm_](https://twitter.com/rxnm_)  Drug Monkey (@drugmonkeyblog) [March 27, 2013](https://twitter.com/drugmonkeyblog/status/316971845565960192)\r\n\r\nWhether the breakup was the fault of Dr. Perlstein's or The System's is not a question I'm very qualified to judge, and it doesn't really interest me. What has struck me is that all three of the critics admit to varying degrees that Dr. Perlstein is a solid scientist in most respects: what he lacks is salesmanship. \u003e .@[eperlste](https://twitter.com/eperlste) not really. You had some big advantages working for you. Crafting a sell perhaps the only lack  Drug Monkey (@drugmonkeyblog) [May 8, 2013](https://twitter.com/drugmonkeyblog/status/332222053216313345)\r\n\r\nIn one post that I had a pretty viscerally negative reaction to, Proflikesubtance extolled the virtues of [salesmanship in grantsmithing](http://scientopia.org/blogs/proflikesubstance/2013/05/09/like-it-or-not-youre-in-sales/). \"Without being able to pitch your research plan to an audience (whoever has the money) and convince them that you have a worthy investment, you aren't going to be able to continue to do science.\" Some of the commentors took issue with the borrowing of business terms, or with the creation of an ends-justify-the-means mindset. He took aim at Dr. Perlstein in particular in his post, and I thought: \"Really? *That's* what keeping him from having a career in science?\" Isn't there a way we could envision this where someone does the science and *someone else* sells it? This is, according to one commentor *defending* PLS's point of view, how Darwin and Huxley did it (though I think - hope - they wouldn't have called it \"selling\"). It's also how Microsoft, Apple, and pretty much every company in world with more than two employeers conducts business. No one expects software developers to go out and pitch their products to customers. And therein lies the critical difference: companies are teams that work together for a time for mutual benefit. Academia is about *me*, *my* first author paper, *my* grant, *my* science. Figuring out a way to make someone else's research interesting is as beneficial to your long-term survival in research as helping a fellow student in a bell curve-graded course."}},"publishedDate":{"$date":"2013-06-01T06:00:00.000Z"}}
{"_id":{"$oid":"580697c8a85812cc21ce45a6"},"slug":"what-im-reading-present-shock-when-everything-happens-now-by-douglas-rushkoff","title":"What I'm reading: \"Present Shock: When Everything Happens Now\" by Douglas Rushkoff","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eThis is a very difficult book to summarize, so I\u0026#39;ll begin with a very specific argument the author makes, delivered completely out of context, but probably familiar to most people of my generation:\u003c/p\u003e\n","md":"This is a very difficult book to summarize, so I'll begin with a very specific argument the author makes, delivered completely out of context, but probably familiar to most people of my generation:"},"extended":{"html":"\u003cp\u003eThis is a very difficult book to summarize, so I\u0026#39;ll begin with a very specific argument the author makes, delivered completely out of context, but probably familiar to most people of my generation:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe show\u0026#39;s gags don\u0026#39;t even relate to the story or throughline (such as they are), but serve as detours that thwart or halt forward motion altogether. Rather than simply scripting pulp culture references into the scenes, \u003cem\u003eFamily Guy\u003c/em\u003e uses these references more as wormholes through which to escape from the temporal reality of the show altogether, often for minutes at a time, which is an eternity on prime-time television. In one episode the mom asks her son to grab a carton of milk \u0026quot;and be sure to take it from the back.\u0026quot; Apropos of nothing, a black-and-white sketch of a man\u0026#39;s hand pulls the child into an alternative universe of a-ha\u0026#39;s iconic 1984 \u0026quot;Take On Me\u0026quot; music video. The child runs through a paper labyrinth with the band\u0026#39;s front man for the better part of a minute before suddenly breaking through a wall and back into the \u003cem\u003eFamily Guy \u003c/em\u003euniverse.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e All of which makes me wish he\u0026#39;d tried to describe the fight with Chicken in such delightful academic language. If there\u0026#39;s a unifying theme to \u0026quot;Present Shock\u0026quot;, it\u0026#39;s probably this: the invention of computing and digital communication is at least as transformative for our species as the Industrial Revolution, and possibly as transformative as the invention of writing. Therefore the way we think about time, money, democracy, relationships, and work is changing in much the same way as it changed during the Industrial Revolution.\u003c/p\u003e\n\u003cp\u003eRushkoff is particularly (and I would say peculiarly) interested in how we think about time. Before the invention of writing, there was, in a sense, no time. Things obviously did change, but they changed gradually and as there was no way to create permanent records it was likely undetectable to the inhabitants of that era. There were also no days of the week or months of the year. Writing allowed records to be kept, but the Industrial Revolution and in particular the invention of railroads necessitated the invention of \u003cem\u003eprecise\u003c/em\u003e time: clocks and watches and the need to know time accurately to the minute (my current town of Waltham, MA became famous - and wealthy - by manufacturing the \u003ca href=\"http://en.wikipedia.org/wiki/Waltham_Watch_Company\"\u003efirst pocket watches\u003c/a\u003e just when there was suddenly a need for them). The digital era is changing it all again, when, as the title suggests, everything happens \u003cem\u003enow\u003c/em\u003e. The quote about \u003cem\u003eFamily Guy\u003c/em\u003e, above, is meant to illustrate how our changing relationship with time has in turn altered our relationship with the traditional story has changed, especially in the 21st century, as a result of this new relationship with time. \u003cem\u003eThe Simpsons, Mystery Science Theatre 3000, The Office, Family Guy, \u003c/em\u003eand\u003cem\u003e Community\u003c/em\u003e are all examples of the TV shows that give their characters awareness of the fact that they are in a TV show, and so satirize narrative itself. Contrast this with the classic situation comedy: \u0026quot;The \u0026#39;situation\u0026#39; usually consisted of a history so important to the show that it was retold during the opening theme song\u0026quot; (yeah, I never made that connection either).** This is of course a bit of a leap, but it\u0026#39;s a microcosm of the issues touched on by Rushkoff, many of which are not meant to be convincing arguments at all but rather thought provoking starting points. \u003c/p\u003e\n\u003cp\u003eIf we take as a given that the Industrial Age is firmly over, and we have now entered what we might call the Digital Age, then we need to re-think how we approach the economy, government, and work-life balance. If stock trades need to be made instantaneously by a computer, and need to be immediately profitable, then the very meaning of value - so far as stocks are concerned - is destroyed. Viewed through this lens, the financial crisis is just the beginning of the end of an era when those sorts of commercial exchanges made sense. Now that they don\u0026#39;t, the market will have to reinvent itself. Similarly, Occupy can be viewed not as a grassroots political movement with a particular goal in mind (like the civil rights movement) but as a first attempt to diversify - or even re-invent - the way people self-govern. Self-governance through representative democracy is after all a relatively recent invention. If the current dearth of voting options, lack of effective information through traditional media channels, and poisoning of the system through private interests is creating a climate in which government ceases to function, then what will replace it? \u003c/p\u003e\n\u003cp\u003eRushkoff is primarily descriptive, not prescriptive, and the point of the book is not to say whether the coming of the Digital Age is good or bad. It simply \u003cstrong\u003eis\u003c/strong\u003e. Personally I find the basic idea exciting. The basic conceit means that much of the current anxiety we have over the 21st century so far is not so much a symptom of technology being bad for our souls, but a disconnect that arises from trying to ram Industrial Age mentalities into a place where they don\u0026#39;t belong. With technology current technology we are able to work anytime, anywhere. That doesn\u0026#39;t mean it\u0026#39;s a good idea. After all, in the end the whole point of everything from telecommuting to Netflix is to \u003cem\u003esave\u003c/em\u003e time, which in turn means to create time for other things. The question is: why haven\u0026#39;t they?\u003c/p\u003e\n","md":"This is a very difficult book to summarize, so I'll begin with a very specific argument the author makes, delivered completely out of context, but probably familiar to most people of my generation:\r\n\r\n\u003e The show's gags don't even relate to the story or throughline (such as they are), but serve as detours that thwart or halt forward motion altogether. Rather than simply scripting pulp culture references into the scenes, *Family Guy* uses these references more as wormholes through which to escape from the temporal reality of the show altogether, often for minutes at a time, which is an eternity on prime-time television. In one episode the mom asks her son to grab a carton of milk \"and be sure to take it from the back.\" Apropos of nothing, a black-and-white sketch of a man's hand pulls the child into an alternative universe of a-ha's iconic 1984 \"Take On Me\" music video. The child runs through a paper labyrinth with the band's front man for the better part of a minute before suddenly breaking through a wall and back into the *Family Guy *universe.\r\n\r\n All of which makes me wish he'd tried to describe the fight with Chicken in such delightful academic language. If there's a unifying theme to \"Present Shock\", it's probably this: the invention of computing and digital communication is at least as transformative for our species as the Industrial Revolution, and possibly as transformative as the invention of writing. Therefore the way we think about time, money, democracy, relationships, and work is changing in much the same way as it changed during the Industrial Revolution.\r\n\r\nRushkoff is particularly (and I would say peculiarly) interested in how we think about time. Before the invention of writing, there was, in a sense, no time. Things obviously did change, but they changed gradually and as there was no way to create permanent records it was likely undetectable to the inhabitants of that era. There were also no days of the week or months of the year. Writing allowed records to be kept, but the Industrial Revolution and in particular the invention of railroads necessitated the invention of *precise* time: clocks and watches and the need to know time accurately to the minute (my current town of Waltham, MA became famous - and wealthy - by manufacturing the [first pocket watches](http://en.wikipedia.org/wiki/Waltham_Watch_Company) just when there was suddenly a need for them). The digital era is changing it all again, when, as the title suggests, everything happens *now*. The quote about *Family Guy*, above, is meant to illustrate how our changing relationship with time has in turn altered our relationship with the traditional story has changed, especially in the 21st century, as a result of this new relationship with time. *The Simpsons, Mystery Science Theatre 3000, The Office, Family Guy, *and* Community* are all examples of the TV shows that give their characters awareness of the fact that they are in a TV show, and so satirize narrative itself. Contrast this with the classic situation comedy: \"The 'situation' usually consisted of a history so important to the show that it was retold during the opening theme song\" (yeah, I never made that connection either).** This is of course a bit of a leap, but it's a microcosm of the issues touched on by Rushkoff, many of which are not meant to be convincing arguments at all but rather thought provoking starting points. \r\n\r\nIf we take as a given that the Industrial Age is firmly over, and we have now entered what we might call the Digital Age, then we need to re-think how we approach the economy, government, and work-life balance. If stock trades need to be made instantaneously by a computer, and need to be immediately profitable, then the very meaning of value - so far as stocks are concerned - is destroyed. Viewed through this lens, the financial crisis is just the beginning of the end of an era when those sorts of commercial exchanges made sense. Now that they don't, the market will have to reinvent itself. Similarly, Occupy can be viewed not as a grassroots political movement with a particular goal in mind (like the civil rights movement) but as a first attempt to diversify - or even re-invent - the way people self-govern. Self-governance through representative democracy is after all a relatively recent invention. If the current dearth of voting options, lack of effective information through traditional media channels, and poisoning of the system through private interests is creating a climate in which government ceases to function, then what will replace it? \r\n\r\nRushkoff is primarily descriptive, not prescriptive, and the point of the book is not to say whether the coming of the Digital Age is good or bad. It simply **is**. Personally I find the basic idea exciting. The basic conceit means that much of the current anxiety we have over the 21st century so far is not so much a symptom of technology being bad for our souls, but a disconnect that arises from trying to ram Industrial Age mentalities into a place where they don't belong. With technology current technology we are able to work anytime, anywhere. That doesn't mean it's a good idea. After all, in the end the whole point of everything from telecommuting to Netflix is to *save* time, which in turn means to create time for other things. The question is: why haven't they?"}},"publishedDate":{"$date":"2013-04-13T06:00:00.000Z"}}
{"_id":{"$oid":"582b54f632c844b34c6ef873"},"slug":"javascript-basics-promises","title":"JavaScript Basics: Promises","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"","md":""},"extended":{"html":"\u003cp\u003eI gave a talk about Promises at Exchange.js here in Edmonton earlier this month. \u003ca href=\"https://caydenberg.github.io/exjs-promises/#/\"\u003eHere are the slides\u003c/a\u003e, \u003ca href=\"https://www.youtube.com/watch?v=KF6HzYK3ty0\u0026amp;feature=youtu.be\"\u003eand the video\u003c/a\u003e (begins at about 18 minutes).\u003c/p\u003e\n","md":"I gave a talk about Promises at Exchange.js here in Edmonton earlier this month. [Here are the slides](https://caydenberg.github.io/exjs-promises/#/), [and the video](https://www.youtube.com/watch?v=KF6HzYK3ty0\u0026feature=youtu.be) (begins at about 18 minutes)."}},"publishedDate":{"$date":"2016-11-15T05:00:00.000Z"}}
{"_id":{"$oid":"584cbbed19f48cf71b3dcdb7"},"slug":"war-is-peace-ignorance-is-strength-freedom-is-slavery-citation-needed","title":"War is peace, ignorance is strength, freedom is slavery [citation needed].","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eKnowledge does not come from nothing. It can only come from reason, from experimentation, or from preexisting knowledge. Yet throughout the history of our civilisation, those in positions have power have claimed access to greater versions of knowledge, whether through divine revelation, or through being \u0026quot;like, really smart.\u0026quot;\u003c/p\u003e\n","md":"Knowledge does not come from nothing. It can only come from reason, from experimentation, or from preexisting knowledge. Yet throughout the history of our civilisation, those in positions have power have claimed access to greater versions of knowledge, whether through divine revelation, or through being \"like, really smart.\""},"extended":{"html":"\u003cp\u003eKnowledge does not come from nothing. It can only come from reason, from experimentation, or from preexisting knowledge. Yet throughout the history of our civilisation, those in positions have power have claimed access to greater versions of knowledge, whether through divine revelation, or through being \u0026quot;like, really smart.\u0026quot;\u003c/p\u003e\n\u003cp\u003eThere is a battle as old as time: between an objective reality which can be queried, and an infinitely malleable one which can be invented. And it is one and the same as the battle between freedom and authoritarianism. Free and fair elections, freedom of the press, checks and balances on executive power ... all of these are wonderful things, things we may take for granted in the 21st century, and things that are essential for healthy democracy. \u003cstrong\u003eBut all of them are secondary to freedom of thought.\u003c/strong\u003e If a tyrant can convince his subjects to believe what he wants them to, none of those other things matter. We need only think about the subjects of Oceania in George Orwell\u0026#39;s \u0026quot;1984\u0026quot;, who could be convinced to believe any truth, no matter how absurd, no matter how it contradicted whatever else they believed or had been told to believe previously.\u003c/p\u003e\n\u003cp\u003eOn the flip side, when a population rejects it\u0026#39;s ruler\u0026#39;s version of the truth, that ruler\u0026#39;s days are numbered. In the latter days of communism in Poland, citizens turned their television sets to the windows of their home during the daily Soviet-sponsored newscasts. The message was: we reject you and your propaganda, and we are letting the world know.\u003c/p\u003e\n\u003cp\u003eThis is nothing new. It predates the inclusion of \u0026quot;post-truth\u0026quot; in the Oxford English Dictionary, Brexit and Donald Trump, Brietbart and fake news, by thousands of years. It is the conflict between Galileo and Pope Urban VIII, between Thomas Huxley and Samuel Wilberforce, the conflict with authoritarians in the 20th century, and with religious extremists in the 21st. But now I and all those who value freedom of thought above all else, need to watch very, very carefully: perhaps for history repeating itself, perhaps for something new.\u003c/p\u003e\n\u003cp\u003eI have watched the US election closely, first with amusement, then disdain, then alarm and finally acceptance, as a bona fide conspiracy theorist was elected as President of the United States. He has falsely claimed that Barack Obama is secretly a Kenyan Muslim, that climate change is hoax created by the Chinese, that his political opponents were involved with the Kennedy assassination or are actively working with international cabals of bankers to undermine American sovereignty, that an election that looked like it was about to defeat him was rigged. After he won that election, he lashed at those calling for recounts or audits while at the same time claiming that he would have won by more if \u0026quot;millions\u0026quot; hadn\u0026#39;t voted illegally. He has flirted with the anti-vaccine movement. Just today, his press secretary made easily falsifiable statements about the crowd sizes at the inauguration and the counter-protests in Washington. He has never attempted nor seemed to think it was important that he provide any evidence whatsoever for these apparently extraordinary claims. The ability to believe seemingly contradictory truths fits Orwell\u0026#39;s \u0026quot;doublethink\u0026quot; to a T.\u003c/p\u003e\n\u003cp\u003eAmericans - supposedly - vote on character, Canadians on issues. As a Canadian, I have trouble caring about whether he was a successful businessman or inherited his empire from his father, that he\u0026#39;s had three wives or even that many of his business ventures were little more than elaborate scams leveraging his personal brand. I could even forgive his apparent admission of sexual assault if he really appeared to be a qualified candidate, as Canadians appeared to forgive Rob Ford\u0026#39;s drug use if they otherwise believed in his politics. But there is no clearer indication to me that American voters are flirting with disaster than Donald Trump\u0026#39;s flagrant disregard for objective reality. His \u0026quot;policies\u0026quot; are nothing more than a thinly veiled attempt to acknowledge a fictitious reality (already believed-in wholesale by millions): where trade deals screw American workers, where \u0026quot;hard working\u0026quot; means \u0026quot;white\u0026quot;, where immigrants run rampant committing violent crime, where middle America is becoming poorer because of a gravy-train delivering their tax dollars to coastal elites and minorities, where their country is weakened by weak-kneed politicians cuckholded by foreign leaders. This alternative reality is undeniably racist, but racism is not even its biggest problem. Its biggest problem is that it is fake: disguising complex problems as ones that can be pinned on scapegoats, and thus easily solved. \u003c/p\u003e\n\u003cp\u003eOne thing is for sure: Trump is something different. I lived in America through the 2004, 2008 and 2012 elections and now, living 600 km from the border, I have never been so afraid. I remember well the disheartening re-election of George W. Bush in 2004: how he could lie impunity about Iraq and get away with it. But this is way, way beyond that. No one could really check Bush\u0026#39;s claims, but Trump\u0026#39;s lies are easily falsifiable and yet, \u003cem\u003e61 million Americans don\u0026#39;t seem to care.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eTo my mind, this is the line that cannot be crossed. Acknowledge the legitimacy of the election. Respect the office, if not the man. Celebrate the peaceful transition of power. But never, ever recant on reason, on deduction, on the need for verification and falsification. The rallying cry for Liberalism in 2017 should be from the pages of Wikipedia: \u0026quot;citation needed\u0026quot;.\u003c/p\u003e\n","md":"Knowledge does not come from nothing. It can only come from reason, from experimentation, or from preexisting knowledge. Yet throughout the history of our civilisation, those in positions have power have claimed access to greater versions of knowledge, whether through divine revelation, or through being \"like, really smart.\"\r\n\r\nThere is a battle as old as time: between an objective reality which can be queried, and an infinitely malleable one which can be invented. And it is one and the same as the battle between freedom and authoritarianism. Free and fair elections, freedom of the press, checks and balances on executive power ... all of these are wonderful things, things we may take for granted in the 21st century, and things that are essential for healthy democracy. **But all of them are secondary to freedom of thought.** If a tyrant can convince his subjects to believe what he wants them to, none of those other things matter. We need only think about the subjects of Oceania in George Orwell's \"1984\", who could be convinced to believe any truth, no matter how absurd, no matter how it contradicted whatever else they believed or had been told to believe previously.\r\n\r\nOn the flip side, when a population rejects it's ruler's version of the truth, that ruler's days are numbered. In the latter days of communism in Poland, citizens turned their television sets to the windows of their home during the daily Soviet-sponsored newscasts. The message was: we reject you and your propaganda, and we are letting the world know.\r\n\r\nThis is nothing new. It predates the inclusion of \"post-truth\" in the Oxford English Dictionary, Brexit and Donald Trump, Brietbart and fake news, by thousands of years. It is the conflict between Galileo and Pope Urban VIII, between Thomas Huxley and Samuel Wilberforce, the conflict with authoritarians in the 20th century, and with religious extremists in the 21st. But now I and all those who value freedom of thought above all else, need to watch very, very carefully: perhaps for history repeating itself, perhaps for something new.\r\n\r\nI have watched the US election closely, first with amusement, then disdain, then alarm and finally acceptance, as a bona fide conspiracy theorist was elected as President of the United States. He has falsely claimed that Barack Obama is secretly a Kenyan Muslim, that climate change is hoax created by the Chinese, that his political opponents were involved with the Kennedy assassination or are actively working with international cabals of bankers to undermine American sovereignty, that an election that looked like it was about to defeat him was rigged. After he won that election, he lashed at those calling for recounts or audits while at the same time claiming that he would have won by more if \"millions\" hadn't voted illegally. He has flirted with the anti-vaccine movement. Just today, his press secretary made easily falsifiable statements about the crowd sizes at the inauguration and the counter-protests in Washington. He has never attempted nor seemed to think it was important that he provide any evidence whatsoever for these apparently extraordinary claims. The ability to believe seemingly contradictory truths fits Orwell's \"doublethink\" to a T.\r\n\r\nAmericans - supposedly - vote on character, Canadians on issues. As a Canadian, I have trouble caring about whether he was a successful businessman or inherited his empire from his father, that he's had three wives or even that many of his business ventures were little more than elaborate scams leveraging his personal brand. I could even forgive his apparent admission of sexual assault if he really appeared to be a qualified candidate, as Canadians appeared to forgive Rob Ford's drug use if they otherwise believed in his politics. But there is no clearer indication to me that American voters are flirting with disaster than Donald Trump's flagrant disregard for objective reality. His \"policies\" are nothing more than a thinly veiled attempt to acknowledge a fictitious reality (already believed-in wholesale by millions): where trade deals screw American workers, where \"hard working\" means \"white\", where immigrants run rampant committing violent crime, where middle America is becoming poorer because of a gravy-train delivering their tax dollars to coastal elites and minorities, where their country is weakened by weak-kneed politicians cuckholded by foreign leaders. This alternative reality is undeniably racist, but racism is not even its biggest problem. Its biggest problem is that it is fake: disguising complex problems as ones that can be pinned on scapegoats, and thus easily solved. \r\n\r\nOne thing is for sure: Trump is something different. I lived in America through the 2004, 2008 and 2012 elections and now, living 600 km from the border, I have never been so afraid. I remember well the disheartening re-election of George W. Bush in 2004: how he could lie impunity about Iraq and get away with it. But this is way, way beyond that. No one could really check Bush's claims, but Trump's lies are easily falsifiable and yet, _61 million Americans don't seem to care._\r\n\r\nTo my mind, this is the line that cannot be crossed. Acknowledge the legitimacy of the election. Respect the office, if not the man. Celebrate the peaceful transition of power. But never, ever recant on reason, on deduction, on the need for verification and falsification. The rallying cry for Liberalism in 2017 should be from the pages of Wikipedia: \"citation needed\"."}},"publishedDate":{"$date":"2017-01-22T05:00:00.000Z"}}
{"_id":{"$oid":"585c63f9969721ab4bfbfc75"},"slug":"adding-an-rss-feed-in-keystonejs","title":"Adding an RSS feed in Keystone.js","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI recently rebuilt my personal website on KeystoneJS and immediately fell in love with it. I think it\u0026#39;s for the following reason: Keystone has successfully married NoSQL with the basic concept of the CMS. \u003c/p\u003e\n","md":"I recently rebuilt my personal website on KeystoneJS and immediately fell in love with it. I think it's for the following reason: Keystone has successfully married NoSQL with the basic concept of the CMS. "},"extended":{"html":"\u003cp\u003eI recently rebuilt my personal website on KeystoneJS and immediately fell in love with it. I think it\u0026#39;s for the following reason: Keystone has successfully married NoSQL with the basic concept of the CMS. This means that any document type which can be envisioned (blog post, recipe, event, product) can just be defined as a schema from the very beginning, without the need to \u0026quot;override\u0026quot; any pre-existing assumptions about what that data might be. \u003c/p\u003e\n\u003cp\u003eAt the same time, data models go way beyond defining field keys and their data-type. You can get a full-functioning CMS in minutes by setting field properties that control their appearance on the \u0026quot;back end\u0026quot; (by which I mean the administration panel).\u003c/p\u003e\n\u003cp\u003eBeyond that, the framework is just a slightly souped-up version of Express. You define your own routes, rendering engine, and \u003cstrong\u003eall the front-end code\u003c/strong\u003e. Nothing appears in the markup sent to the user unless you want it to be there.\u003c/p\u003e\n\u003cp\u003eFrankly, all things considered, it\u0026#39;s a huge relief to go from WordPress to a lightweight, unopinionated system. I have control of the HTML my site emits, and we can \u003cstrong\u003eMake the Web Great Again\u003c/strong\u003e. Of course is a double-edged sword, and you might start missing things like RSS feeds, sitemaps, and the SEO features that come with a plugin like Yoast.\u003c/p\u003e\n\u003cp\u003eThese things are not hard add, though. For RSS feeds, I found \u003ca href=\"https://www.npmjs.com/package/rss\"\u003ean npm module\u003c/a\u003e that worked with almost no setup. I simply set it up as one of my routes:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003emodule.exports = function(req, res) {\n  // define global features of the feed\n  var feed = new RSS({\n    title: \u0026#39;Casey A. Ydenberg\\\u0026#39;s blog feed\u0026#39;,\n    description: \u0026#39;Web development and JavaScript\u0026#39;,\n    author: \u0026#39;@CAYdenberg\u0026#39;\n  });\n\n  // similar to the blog index page, we pull the most\n  // recent 10 blog posts\n  keystone.list(\u0026#39;Post\u0026#39;).model\n    .where(\u0026#39;state\u0026#39;, \u0026#39;published\u0026#39;)\n    .sort(\u0026#39;-publishedDate\u0026#39;)\n    .limit(10)\n    .exec()\n\n    // define features for each blog post\n    .then(posts =\u0026gt; {\n      posts.forEach(post =\u0026gt; {\n        feed.item({\n          title: post.title,\n          description: post.content.brief.html,\n          url: post.canonicalUrl(),\n          date: post.publishedDate\n        });\n      });\n\n      // alter the HTTP header and send XML\n      res.set(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/xml\u0026#39;);\n      res.send(feed.xml());\n    });\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou\u0026#39;ll notice the function \u003ccode\u003epost.canonicalUrl()\u003c/code\u003e to get the URL of a post. Keystone does not have an obvious way to do this. In WordPress, this is easier because data models (\u0026quot;posts\u0026quot;) automatically have a canonical URL (permalink) that they are associated with. MVC frameworks don\u0026#39;t usually work this way: URLs (or routes) map to a controller or action, but that action could call up all kinds of different data to render the display. \u003c/p\u003e\n\u003cp\u003e(Of course, this is also a weakness of WordPress - when you try rendering \u0026quot;related posts\u0026quot; in the sidebar and end up writing batshit code like \u003ccode\u003ewp_rewind_posts\u003c/code\u003e ... ugh).\u003c/p\u003e\n\u003cp\u003eI decided to give my blog post model an extra function to generate the link. \u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-javascript\"\u003ePost.schema.methods.canonicalUrl = () =\u0026gt; keystone.get(\u0026#39;url\u0026#39;) + \u0026#39;/blog/\u0026#39; + this.slug;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is sort-of duplicating logic found in the router, but only sort-of. In fact, Keystone\u0026#39;s standard set of templating \u0026quot;helpers\u0026quot; comes with just this sort of function for use in the HTML; I\u0026#39;ve just replaced it with a function associated with the data model (which makes more sense).\u003c/p\u003e\n\u003cp\u003eAs a bonus, I used this function on the blog index page (instead of the helper):\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-html\"\u003e\u0026lt;article class=\u0026quot;blog-post\u0026quot;\u0026gt;\n  \u0026lt;h2 class=\u0026quot;blog-post__title\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;{{canonicalUrl}}\u0026quot;\u0026gt;{{{title}}}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt;\n  \u0026lt;div class=\u0026quot;blog-post__content\u0026quot;\u0026gt;{{{content.brief.html}}}\u0026lt;/div\u0026gt;\n  \u0026lt;p class=\u0026quot;blog-post__read-more\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;{{canonicalUrl}}\u0026quot;\u0026gt;Read more \u0026amp;gt;\u0026amp;gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n  \u0026lt;hr /\u0026gt;\n\u0026lt;/article\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n","md":"I recently rebuilt my personal website on KeystoneJS and immediately fell in love with it. I think it's for the following reason: Keystone has successfully married NoSQL with the basic concept of the CMS. This means that any document type which can be envisioned (blog post, recipe, event, product) can just be defined as a schema from the very beginning, without the need to \"override\" any pre-existing assumptions about what that data might be. \r\n\r\nAt the same time, data models go way beyond defining field keys and their data-type. You can get a full-functioning CMS in minutes by setting field properties that control their appearance on the \"back end\" (by which I mean the administration panel).\r\n\r\nBeyond that, the framework is just a slightly souped-up version of Express. You define your own routes, rendering engine, and **all the front-end code**. Nothing appears in the markup sent to the user unless you want it to be there.\r\n\r\nFrankly, all things considered, it's a huge relief to go from WordPress to a lightweight, unopinionated system. I have control of the HTML my site emits, and we can **Make the Web Great Again**. Of course is a double-edged sword, and you might start missing things like RSS feeds, sitemaps, and the SEO features that come with a plugin like Yoast.\r\n\r\nThese things are not hard add, though. For RSS feeds, I found [an npm module](https://www.npmjs.com/package/rss) that worked with almost no setup. I simply set it up as one of my routes:\r\n\r\n```javascript\r\nmodule.exports = function(req, res) {\r\n  // define global features of the feed\r\n  var feed = new RSS({\r\n    title: 'Casey A. Ydenberg\\'s blog feed',\r\n    description: 'Web development and JavaScript',\r\n    author: '@CAYdenberg'\r\n  });\r\n\r\n  // similar to the blog index page, we pull the most\r\n  // recent 10 blog posts\r\n  keystone.list('Post').model\r\n    .where('state', 'published')\r\n    .sort('-publishedDate')\r\n    .limit(10)\r\n    .exec()\r\n\r\n    // define features for each blog post\r\n    .then(posts =\u003e {\r\n      posts.forEach(post =\u003e {\r\n        feed.item({\r\n          title: post.title,\r\n          description: post.content.brief.html,\r\n          url: post.canonicalUrl(),\r\n          date: post.publishedDate\r\n        });\r\n      });\r\n\r\n      // alter the HTTP header and send XML\r\n      res.set('Content-Type', 'text/xml');\r\n      res.send(feed.xml());\r\n    });\r\n}\r\n```\r\n\r\nYou'll notice the function `post.canonicalUrl()` to get the URL of a post. Keystone does not have an obvious way to do this. In WordPress, this is easier because data models (\"posts\") automatically have a canonical URL (permalink) that they are associated with. MVC frameworks don't usually work this way: URLs (or routes) map to a controller or action, but that action could call up all kinds of different data to render the display. \r\n\r\n(Of course, this is also a weakness of WordPress - when you try rendering \"related posts\" in the sidebar and end up writing batshit code like `wp_rewind_posts` ... ugh).\r\n\r\nI decided to give my blog post model an extra function to generate the link. \r\n\r\n```javascript\r\nPost.schema.methods.canonicalUrl = () =\u003e keystone.get('url') + '/blog/' + this.slug;\r\n```\r\n\r\nThis is sort-of duplicating logic found in the router, but only sort-of. In fact, Keystone's standard set of templating \"helpers\" comes with just this sort of function for use in the HTML; I've just replaced it with a function associated with the data model (which makes more sense).\r\n\r\nAs a bonus, I used this function on the blog index page (instead of the helper):\r\n\r\n```html\r\n\u003carticle class=\"blog-post\"\u003e\r\n  \u003ch2 class=\"blog-post__title\"\u003e\u003ca href=\"{{canonicalUrl}}\"\u003e{{{title}}}\u003c/a\u003e\u003c/h2\u003e\r\n  \u003cdiv class=\"blog-post__content\"\u003e{{{content.brief.html}}}\u003c/div\u003e\r\n  \u003cp class=\"blog-post__read-more\"\u003e\u003ca href=\"{{canonicalUrl}}\"\u003eRead more \u0026gt;\u0026gt;\u003c/a\u003e\u003c/p\u003e\r\n  \u003chr /\u003e\r\n\u003c/article\u003e\r\n```"}},"publishedDate":{"$date":"2017-01-07T05:00:00.000Z"}}
{"_id":{"$oid":"588abaf3ddeb2871178808b8"},"sortOrder":7,"slug":"mymetcredit","title":"my.MetCredit","__t":"Project","tech":[{"$oid":"57edd1aeecd6d32a6890f974"},{"$oid":"588abbaaddeb2871178808b9"}],"state":"archived","__v":2,"author":{"$oid":"5803a93774664abd2fad00d6"},"brief":"CRUD application allowing creating of listing forms detailing information on collectable debt","links":{"code":"","site":"https://my.metcredit.com"},"myRole":{"html":"\u003cp\u003eAfter Graphos built the MetCredit website, MetCredit approached us wanting a \u0026quot;web form\u0026quot; to replace their existing PDF solution. I argued that given the complexity of the information (more than one hundred fields and about a dozen possible attachments) that a simple \u0026quot;contact form\u0026quot; on a CMS-based website would be insufficient for their needs, and they should consider a standalone application built on an MVC framework. The application collects data over a series of form submissions, and - when the user is ready - transmits all the data plus attachments to MetCredit\u0026#39;s internal infrastructure by SFTP.\u003c/p\u003e\n\u003cp\u003eI proposed building the app in a series of \u0026quot;sprints\u0026quot; that allowed testing and feedback at each stage. I eventually chose the Laravel framework as a suitable foundation, and built the initial 1.0 release according to that plan.\u003c/p\u003e\n","md":"After Graphos built the MetCredit website, MetCredit approached us wanting a \u0026quot;web form\u0026quot; to replace their existing PDF solution. I argued that given the complexity of the information (more than one hundred fields and about a dozen possible attachments) that a simple \u0026quot;contact form\u0026quot; on a CMS-based website would be insufficient for their needs, and they should consider a standalone application built on an MVC framework. The application collects data over a series of form submissions, and - when the user is ready - transmits all the data plus attachments to MetCredit's internal infrastructure by SFTP.\r\n\r\nI proposed building the app in a series of \u0026quot;sprints\u0026quot; that allowed testing and feedback at each stage. I eventually chose the Laravel framework as a suitable foundation, and built the initial 1.0 release according to that plan."},"problem":{"html":"\u003cp\u003eMetCredit\u0026#39;s clients fill out \u0026quot;listing forms\u0026quot; which detail many kinds of information on debt owed to them. Historically, these were downloaded as PDFs, filled out by hand or in Adobe Acrobat, and then submitted by email or snailmail along with many attachments (signed contracts, liens, etc.). After this, agents at MetCredit would enter the information into spreadsheets. This process was inefficient for both the clients and for MetCredit.\u003c/p\u003e\n","md":"MetCredit's clients fill out \u0026quot;listing forms\u0026quot; which detail many kinds of information on debt owed to them. Historically, these were downloaded as PDFs, filled out by hand or in Adobe Acrobat, and then submitted by email or snailmail along with many attachments (signed contracts, liens, etc.). After this, agents at MetCredit would enter the information into spreadsheets. This process was inefficient for both the clients and for MetCredit."},"status":{"html":"\u003cp\u003eSince leaving my position at Graphos I have continued to maintain the application as a freelancer. Enhancements have included the improvement of the admin panel side of the application, and tooltips for users.\u003c/p\u003e\n\u003cp\u003eThe next round of improvements include a chat system based on websockets, and an improved download interface. \u003c/p\u003e\n","md":"Since leaving my position at Graphos I have continued to maintain the application as a freelancer. Enhancements have included the improvement of the admin panel side of the application, and tooltips for users.\r\n\r\nThe next round of improvements include a chat system based on websockets, and an improved download interface. "},"publishedDate":{"$date":"2018-05-10T04:00:00.000Z"},"image":{"public_id":"pvvllyq2mybjcpygxcyh","version":1533695796,"signature":"251d7824d878f1e8ae1d73222c39bf94de1f9b2a","width":841,"height":527,"format":"png","resource_type":"image","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1533695796/pvvllyq2mybjcpygxcyh.png","secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1533695796/pvvllyq2mybjcpygxcyh.png"}}
{"_id":{"$oid":"58f10fc0b777ce067fa0d79f"},"slug":"what-i-want-from-a-react-ui-framework-intentions-and-skins-in-the-presentation-layer","title":"What I want from a React UI framework: Intentions and skins in the presentation layer","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eI do not share the outlook that CSS is over. I want a React UI library that shares this philosophy.\u003c/p\u003e\n","md":"I do not share the outlook that CSS is over. I want a React UI library that shares this philosophy."},"extended":{"html":"\u003cp\u003eFront-end frameworks like Bootstrap and Foundation are reviled among some front-end developers for creating bloated CSS and for making every site look the same. However, much of this hatred focuses on the use of the use of the framework as a \u0026quot;drop-in\u0026quot; CSS (and JavaScript) file. \u003ca href=\"https://github.com/twbs/bootstrap-sass/blob/master/assets/stylesheets/bootstrap/_variables.scss\"\u003eCustomization of SCSS variables\u003c/a\u003e can \u003ca href=\"http://foundation.zurb.com/sites/docs/sass.html#the-settings-file\"\u003eproduce amazingly distinctive designs\u003c/a\u003e, and it\u0026#39;s possible to include only those parts of the framework which are needed, drastically reducing the size of both the CSS and JS assets. To my mind, these frameworks provide two advantages: standardized responsive grid layout systems which work across browsers, and a variety of components (tooltips, dropdown menus, modals etc.) which can be included in a project without being coded from scratch.\u003c/p\u003e\n\u003cp\u003eAt first glance, this \u0026quot;component-based\u0026quot; system would seem to be a good fit for React.js, but that leaves you heavily reliant on jQuery. A new set of projects has sprung up that each provide a library of components that replace the common Bootstrap and Foundation UX patterns that both users and developers are used to. These include \u003ca href=\"https://www.material-ui.com/\"\u003eMaterial UI\u003c/a\u003e, \u003ca href=\"https://react.semantic-ui.com/introduction\"\u003eSemantic UI React\u003c/a\u003e and \u003ca href=\"http://elemental-ui.com/\"\u003eElemental UI\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOne major consideration in choosing between these libraries in the degree to which you will be dependent on \u003cstrong\u003einline styles\u003c/strong\u003e. The argument in favour goes like this: React pushes a component-based architecture, and just as separating form and function between HTML and JavaScript no longer makes sense, it also no longer makes sense to separate content and style by using CSS. Instead, JavaScript manages function, presentation and style. The concerns that need separation are no longer between different layers of a component, but between the components themselves.\u003c/p\u003e\n\u003cp\u003ePersonally, I don\u0026#39;t share this outlook. It makes perfect sense for JavaScript to be tightly coupled to HTML in a user-interface library, because the \u003cstrong\u003eintent\u003c/strong\u003e of the component depends on the state of that component and its function. But how this intent translates in the styles (\u0026quot;skin\u0026quot;) of the component is a different consideration. That is why a \u003ccode\u003e\u0026amp;lt;strong\u0026amp;gt;\u003c/code\u003e HTML tag and a \u003ccode\u003efont-weight\u003c/code\u003e CSS property are different things: strong text is the intention, but bold text is the skin that communicates that intention. \u003c/p\u003e\n\u003cp\u003eYou might want to change the skin of a component without changing its function (such as the share of orange or yellow meant to communicate a warning) but you will rarely change the meaning red or orange without changing the function itself. Moreover, if you change the shade of red or orange, you\u0026#39;ll likely want to change it across the entire the site or app. The stylesheet is therefore a reference that components make use of, not an embedded part of the components themselves.\u003c/p\u003e\n\u003cp\u003eFor libraries that make heavy use of inline styles, the bottom line is that components are not really reusable, at least not in the way that I would like. I can override the custom styles by providing a custom style object or \u003ccode\u003eclassName\u003c/code\u003e to the component (and then write CSS with heavy use of \u003ccode\u003e!important\u003c/code\u003e declarations), but then I have to do this every time I use that component. The only way to do that in a DRY way to wrap the library component in another component which provides the customizations for a particular project, adding to the depth of nesting and complexity.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.material-ui.com/#/customization/styles\"\u003eMaterial UI has noted other downsides to inline styles\u003c/a\u003e, including performance, and the lack of media queries and pseudo-elements. To be sure, it does provide a method of \u0026quot;customization\u0026quot; through theming, but the number of possible variables is pretty limited compared to Foundation or Bootstrap.\u003c/p\u003e\n\u003cp\u003eIdeally, here is how I think a framework in this space should work:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCSS is produced by compiling SCSS (or similar) with a set of user-provided variables, just like Bootstrap or Foundation\u003c/li\u003e\n\u003cli\u003eComponents refer to CSS by class. The user can therefore \u0026quot;override\u0026quot; styles with their own CSS/SCSS.\u003c/li\u003e\n\u003cli\u003eComponents with programmatic behaviour are controlled with internal state, and change their own classes or other attributes depending on state. For example, a modal adds a class when it \u0026quot;appears\u0026quot;, or better yet, just change its \u003ccode\u003earia-hidden\u003c/code\u003e attribute.\u003c/li\u003e\n\u003cli\u003eComponents accept props from their parents to notify them of state changes. For example, a modal would accept an \u003ccode\u003eonClose\u003c/code\u003e prop which is a function that fires when the modal closes. Even better, these functions could override the custom behaviour by returning false.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are a plethora of these libraries available, but from my research none of them work this way. Feel free to chime in in the comments if anything deserves a second look, if my philosophy is just too wrong and I should get with the inline styles!\u003c/p\u003e\n","md":"Front-end frameworks like Bootstrap and Foundation are reviled among some front-end developers for creating bloated CSS and for making every site look the same. However, much of this hatred focuses on the use of the use of the framework as a \"drop-in\" CSS (and JavaScript) file. [Customization of SCSS variables](https://github.com/twbs/bootstrap-sass/blob/master/assets/stylesheets/bootstrap/_variables.scss) can [produce amazingly distinctive designs](http://foundation.zurb.com/sites/docs/sass.html#the-settings-file), and it's possible to include only those parts of the framework which are needed, drastically reducing the size of both the CSS and JS assets. To my mind, these frameworks provide two advantages: standardized responsive grid layout systems which work across browsers, and a variety of components (tooltips, dropdown menus, modals etc.) which can be included in a project without being coded from scratch.\r\n\r\nAt first glance, this \"component-based\" system would seem to be a good fit for React.js, but that leaves you heavily reliant on jQuery. A new set of projects has sprung up that each provide a library of components that replace the common Bootstrap and Foundation UX patterns that both users and developers are used to. These include [Material UI](https://www.material-ui.com/), [Semantic UI React](https://react.semantic-ui.com/introduction) and [Elemental UI](http://elemental-ui.com/).\r\n\r\nOne major consideration in choosing between these libraries in the degree to which you will be dependent on **inline styles**. The argument in favour goes like this: React pushes a component-based architecture, and just as separating form and function between HTML and JavaScript no longer makes sense, it also no longer makes sense to separate content and style by using CSS. Instead, JavaScript manages function, presentation and style. The concerns that need separation are no longer between different layers of a component, but between the components themselves.\r\n\r\nPersonally, I don't share this outlook. It makes perfect sense for JavaScript to be tightly coupled to HTML in a user-interface library, because the **intent** of the component depends on the state of that component and its function. But how this intent translates in the styles (\"skin\") of the component is a different consideration. That is why a `\u0026lt;strong\u0026gt;` HTML tag and a `font-weight` CSS property are different things: strong text is the intention, but bold text is the skin that communicates that intention. \r\n\r\nYou might want to change the skin of a component without changing its function (such as the share of orange or yellow meant to communicate a warning) but you will rarely change the meaning red or orange without changing the function itself. Moreover, if you change the shade of red or orange, you'll likely want to change it across the entire the site or app. The stylesheet is therefore a reference that components make use of, not an embedded part of the components themselves.\r\n\r\nFor libraries that make heavy use of inline styles, the bottom line is that components are not really reusable, at least not in the way that I would like. I can override the custom styles by providing a custom style object or `className` to the component (and then write CSS with heavy use of `!important` declarations), but then I have to do this every time I use that component. The only way to do that in a DRY way to wrap the library component in another component which provides the customizations for a particular project, adding to the depth of nesting and complexity.\r\n\r\n[Material UI has noted other downsides to inline styles](https://www.material-ui.com/#/customization/styles), including performance, and the lack of media queries and pseudo-elements. To be sure, it does provide a method of \"customization\" through theming, but the number of possible variables is pretty limited compared to Foundation or Bootstrap.\r\n\r\nIdeally, here is how I think a framework in this space should work:\r\n\r\n- CSS is produced by compiling SCSS (or similar) with a set of user-provided variables, just like Bootstrap or Foundation\r\n- Components refer to CSS by class. The user can therefore \"override\" styles with their own CSS/SCSS.\r\n- Components with programmatic behaviour are controlled with internal state, and change their own classes or other attributes depending on state. For example, a modal adds a class when it \"appears\", or better yet, just change its `aria-hidden` attribute.\r\n- Components accept props from their parents to notify them of state changes. For example, a modal would accept an `onClose` prop which is a function that fires when the modal closes. Even better, these functions could override the custom behaviour by returning false.\r\n\r\nThere are a plethora of these libraries available, but from my research none of them work this way. Feel free to chime in in the comments if anything deserves a second look, if my philosophy is just too wrong and I should get with the inline styles!"}},"publishedDate":{"$date":"2017-04-18T04:00:00.000Z"}}
{"_id":{"$oid":"58f127d3b777ce067fa0d7a0"},"slug":"using-immutability-helpers-for-redux-reducers","title":"Using Immutability Helpers for Redux reducers","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eImmutability is a core concept of libraries like Redux, and has many advantages - not the least of which is that is easier to decide when a React component should update. The downside of immutability is that it\u0026#39;s hard to do: familiar methods like \u003ccode\u003e.push\u003c/code\u003e modify arrays in place instead of producing and new ones, and even when trying to \u0026quot;think immutable\u0026quot; it\u0026#39;s easy to mess up and modify and existing data structure.\u003c/p\u003e\n","md":"Immutability is a core concept of libraries like Redux, and has many advantages - not the least of which is that is easier to decide when a React component should update. The downside of immutability is that it's hard to do: familiar methods like `.push` modify arrays in place instead of producing and new ones, and even when trying to \"think immutable\" it's easy to mess up and modify and existing data structure.\r\n"},"extended":{"html":"\u003cp\u003eImmutability is a core concept of libraries like Redux, and has many advantages - not the least of which is that is easier to decide when a React component should update. The downside of immutability is that it\u0026#39;s hard to do: familiar methods like \u003ccode\u003e.push\u003c/code\u003e modify arrays in place instead of producing and new ones, and even when trying to \u0026quot;think immutable\u0026quot; it\u0026#39;s easy to mess up and modify and existing data structure.\u003c/p\u003e\n\u003cp\u003eThere are several great solutions to this, the most well-known of which is Immutable.js. One which has been largely overlooked in the \u003ca href=\"https://github.com/kolodny/immutability-helper\"\u003eImmutability helper\u003c/a\u003e, formerly part of React but now seems to be maintained separately.\u003c/p\u003e\n\u003cp\u003eSee the Github repo for a full explanation. Basically, you can \u0026quot;drill into\u0026quot; a deep data structure, modify the part you want using a special \u0026quot;command\u0026quot; object, and then get a brand, shiny new object at the end of it all.\u003c/p\u003e\n\u003cp\u003eTo illustrate how it can work with Redux, I\u0026#39;ve modified the \u003ca href=\"http://redux.js.org/docs/basics/Reducers.html#splitting-reducers\"\u003ecode example here\u003c/a\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003efunction todoApp(state = initialState, action) {\n  switch (action.type) {\n    case SET_VISIBILITY_FILTER:\n      return update(state, {\n        visibilityFilter: {$set: action.filter}\n      })      \n    case ADD_TODO:\n      return update(state, {\n         todos: {$push: [{text: action.text, completed: false}]}\n      })\n    case TOGGLE_TODO:\n      const todo = state.todos[action.index]\n      const newTodo = update(todo, {\n        completed: {$set: !todo.completed}\n      })\n      return update(state, {\n        todos: {$splice: [[index, 1, newTodo]]}\n      })\n    default:\n      return state\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eWhat about Deep Freeze?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePersonally, I like using Deep Freeze in test code, on the state which are about to pass through reducers. If we\u0026#39;re ensuring the state isn\u0026#39;t modified in tests, there\u0026#39;s no need to include in the application code itself.\u003c/p\u003e\n","md":"Immutability is a core concept of libraries like Redux, and has many advantages - not the least of which is that is easier to decide when a React component should update. The downside of immutability is that it's hard to do: familiar methods like `.push` modify arrays in place instead of producing and new ones, and even when trying to \"think immutable\" it's easy to mess up and modify and existing data structure.\r\n\r\nThere are several great solutions to this, the most well-known of which is Immutable.js. One which has been largely overlooked in the [Immutability helper](https://github.com/kolodny/immutability-helper), formerly part of React but now seems to be maintained separately.\r\n\r\nSee the Github repo for a full explanation. Basically, you can \"drill into\" a deep data structure, modify the part you want using a special \"command\" object, and then get a brand, shiny new object at the end of it all.\r\n\r\nTo illustrate how it can work with Redux, I've modified the [code example here](http://redux.js.org/docs/basics/Reducers.html#splitting-reducers):\r\n\r\n```js\r\nfunction todoApp(state = initialState, action) {\r\n  switch (action.type) {\r\n    case SET_VISIBILITY_FILTER:\r\n      return update(state, {\r\n        visibilityFilter: {$set: action.filter}\r\n      })      \r\n    case ADD_TODO:\r\n      return update(state, {\r\n         todos: {$push: [{text: action.text, completed: false}]}\r\n      })\r\n    case TOGGLE_TODO:\r\n      const todo = state.todos[action.index]\r\n      const newTodo = update(todo, {\r\n        completed: {$set: !todo.completed}\r\n      })\r\n      return update(state, {\r\n        todos: {$splice: [[index, 1, newTodo]]}\r\n      })\r\n    default:\r\n      return state\r\n  }\r\n}\r\n```\r\n\r\n**What about Deep Freeze?**\r\n\r\nPersonally, I like using Deep Freeze in test code, on the state which are about to pass through reducers. If we're ensuring the state isn't modified in tests, there's no need to include in the application code itself."}},"author":{"$oid":"57cddf32d75ea10a19c42073"},"publishedDate":{"$date":"2017-04-27T04:00:00.000Z"}}
{"_id":{"$oid":"592104d7b777ce067fa0d7a2"},"slug":"bookshelf-weapons-of-math-destruction-by-cathy-oneal","title":"Bookshelf: Weapons of Math Destruction by Cathy O'Neal","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eCathy O\u0026#39;Neal, in \u003ca href=\"https://weaponsofmathdestructionbook.com/\"\u003eWeapons of Math Destruction\u003c/a\u003e, describes how algorithms increasingly control our lives: the news we see, the jobs we might be hired or fired from, how prisoners are sentenced and granted parole, whether or not we qualify for a loan. Moreover, she makes the case convincingly that the bizarre results of algorithms gone awry disproportionately affect the lives of the poor and disadvantaged.\u003c/p\u003e\n","md":"Cathy O'Neal, in [Weapons of Math Destruction](https://weaponsofmathdestructionbook.com/), describes how algorithms increasingly control our lives: the news we see, the jobs we might be hired or fired from, how prisoners are sentenced and granted parole, whether or not we qualify for a loan. Moreover, she makes the case convincingly that the bizarre results of algorithms gone awry disproportionately affect the lives of the poor and disadvantaged."},"extended":{"html":"\u003cp\u003eIn 2006, Douglas Coupland wrote a book called \u003ca href=\"https://en.wikipedia.org/wiki/JPod\"\u003eJPod\u003c/a\u003e about a group of employees at a video game company who are assigned to work together due to a computer glitch in a human resources algorithm. The algorithm is thus the hand of God that sets the events in the book in motion, and it is typical of Coupland\u0026#39;s brand of fiction that it appears to be a witty observation of what modern life is increasingly like.\u003c/p\u003e\n\u003cp\u003eCathy O\u0026#39;Neal, in \u003ca href=\"https://weaponsofmathdestructionbook.com/\"\u003eWeapons of Math Destruction\u003c/a\u003e, describes how algorithms increasingly control our lives: the news we see, the jobs we might be hired or fired from, how prisoners are sentenced and granted parole, whether or not we qualify for a loan. Moreover, she makes the case convincingly that the sometimes bizarre results of algorithms gone awry disproportionately affect the lives of the poor and disadvantaged. After all, those with wealth and influence are better able to connect with actual people when applying for a job or a loan; those without it are mere data points, and some data points have to be at the bottom. O\u0026#39;Neal calls algorithms that lead to increased inequality \u0026quot;weapons of math destruction\u0026quot;, or WMDs.\u003c/p\u003e\n\u003cp\u003eThe strangest part of all of this from a scientific perspective is how often algorithms are used as a modern replacement for phrenology. Their complexity, which in scientific terms makes them less useful, is instead used to argue for their infallibility. A teacher who is fired because of their low score according to a \u0026quot;value-added\u0026quot; model can\u0026#39;t very well argue that the algorithm is mistaken if neither they nor their superiors understand how it works. The algorithm itself has no way to be evaluated, to see if its results predict the real world.\u003c/p\u003e\n\u003cp\u003eOf course, the real world is complex and so sometimes a model must be, too. But in science, every model is known to be false; the idea is to improve it by continuously incorporating new data. Without this feedback loop, it\u0026#39;s impossible to tell good algorithms from bad. As O\u0026#39;Neal argues, the incentive behind a Weapon of Math Destruction is not to produce better models but to give the appearance of creating greater value by using cutting-edge techniques. Complexity, or simple opaqueness, is a weakness for creating a scientifically better model, but it\u0026#39;s a strength in marketing it. \u003c/p\u003e\n\u003cp\u003eO\u0026#39;Neal provides a compelling narrative that illustrates the real human consequences of blind trust in big data. It\u0026#39;s an argument for comprehension, for responsibility, and for compassion. \u003c/p\u003e\n","md":"In 2006, Douglas Coupland wrote a book called [JPod](https://en.wikipedia.org/wiki/JPod) about a group of employees at a video game company who are assigned to work together due to a computer glitch in a human resources algorithm. The algorithm is thus the hand of God that sets the events in the book in motion, and it is typical of Coupland's brand of fiction that it appears to be a witty observation of what modern life is increasingly like.\r\n\r\nCathy O'Neal, in [Weapons of Math Destruction](https://weaponsofmathdestructionbook.com/), describes how algorithms increasingly control our lives: the news we see, the jobs we might be hired or fired from, how prisoners are sentenced and granted parole, whether or not we qualify for a loan. Moreover, she makes the case convincingly that the sometimes bizarre results of algorithms gone awry disproportionately affect the lives of the poor and disadvantaged. After all, those with wealth and influence are better able to connect with actual people when applying for a job or a loan; those without it are mere data points, and some data points have to be at the bottom. O'Neal calls algorithms that lead to increased inequality \"weapons of math destruction\", or WMDs.\r\n\r\nThe strangest part of all of this from a scientific perspective is how often algorithms are used as a modern replacement for phrenology. Their complexity, which in scientific terms makes them less useful, is instead used to argue for their infallibility. A teacher who is fired because of their low score according to a \"value-added\" model can't very well argue that the algorithm is mistaken if neither they nor their superiors understand how it works. The algorithm itself has no way to be evaluated, to see if its results predict the real world.\r\n\r\nOf course, the real world is complex and so sometimes a model must be, too. But in science, every model is known to be false; the idea is to improve it by continuously incorporating new data. Without this feedback loop, it's impossible to tell good algorithms from bad. As O'Neal argues, the incentive behind a Weapon of Math Destruction is not to produce better models but to give the appearance of creating greater value by using cutting-edge techniques. Complexity, or simple opaqueness, is a weakness for creating a scientifically better model, but it's a strength in marketing it. \r\n\r\nO'Neal provides a compelling narrative that illustrates the real human consequences of blind trust in big data. It's an argument for comprehension, for responsibility, and for compassion. "}},"publishedDate":{"$date":"2017-06-15T04:00:00.000Z"}}
{"_id":{"$oid":"5971514071d0352c44a81869"},"slug":"opinionated-opinions-on-code-organization-of-a-react-redux-project","title":"Opinionated opinions on code organization of a React-Redux project","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eI\u0026#39;ve been working on a large-scale React-Redux project for several months now. React is not a framework and so it doesn\u0026#39;t enforce a particular way of grouping related code or related files, code style or organization. I\u0026#39;ve been thinking about what it means to provide forward-maintainability in this type of codebase and how we can make our code understandable to other human beings.\u003c/p\u003e\n","md":"I've been working on a large-scale React-Redux project for several months now. React is not a framework and so it doesn't enforce a particular way of grouping related code or related files, code style or organization. I've been thinking about what it means to provide forward-maintainability in this type of codebase and how we can make our code understandable to other human beings."},"extended":{"html":"\u003cp\u003eI\u0026#39;ve been working on a large-scale React-Redux project for several months now. React is not a framework and so it doesn\u0026#39;t enforce a particular way of grouping related code or related files. I\u0026#39;ve been thinking about what it means to provide forward-maintainability in this type of codebase and how we can make our code understandable to other human beings (ok, all human beings, including the original programmer). I thought I would share some of what I\u0026#39;ve learned (often the hard way) and see what other people who\u0026#39;ve faced this think.\u003c/p\u003e\n\u003ch2 id=\"1-keep-store-related-concerns-together\"\u003e1. Keep store-related concerns together\u003c/h2\u003e\n\u003cp\u003eIt seems pretty normal to have one top-level folder for actions and another for reducers, but I\u0026#39;ve decided that this isn\u0026#39;t great. For one thing, both actions and reducers need access to the same set of constants. For another, large stores have a need for a type of \u0026quot;store-query\u0026quot; function that doesn\u0026#39;t really belong in either place. I\u0026#39;ve ultimately decided that a better organization is to have a single \u0026quot;store\u0026quot; folder containing a set of files which export separately their constants, actions, reducer, and queries. Each part of the store is then grouped together in one file making it easier to understand what its purpose it and cutting down on \u003ccode\u003eimport\u003c/code\u003e boilerplate.\u003c/p\u003e\n\u003ch2 id=\"2-test-your-store\"\u003e2. Test your store\u003c/h2\u003e\n\u003cp\u003eAction creators (at least synchronous ones) and reducers are extremely easy to test and the benefits of testing therefore greatly outweigh the costs. Redux\u0026#39;s \u003ccode\u003ecombineReducers\u003c/code\u003e method makes it easy to write reducers that only need to know about a single section of the store, limiting the amount of state we have to mock in our tests. For example, to test an ADD_TODO action we could write:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003eimport todosReducers, {constants as c} from \u0026#39;../todos\u0026#39;\n\nit(\u0026#39;should add a TODO\u0026#39;, () =\u0026gt; {\n    const initialState = []\n    const finalState = todoReducer(initialState, {type: c.ADD_TODO, todo: \u0026#39;Write unit tests\u0026#39;})\n    expect(finalState).toHaveLength(1)\n})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile our application state will surely be more complex than a single array, the todosReducer doesn\u0026#39;t care. These types of tests are trivially easy to write, and the process of writing them will solidify the design of the reducers as well and guard against regressions.\u003c/p\u003e\n\u003ch2 id=\"3-redux-middleware-is-powerful\"\u003e3. Redux middleware is powerful\u003c/h2\u003e\n\u003cp\u003eRedux is not about fetching data, it is about predictable data management. Yet the two are so closely intertwined that you basically cannot have one without the other. The \u0026quot;de facto\u0026quot; solution for binding asynchonous calls to redux is redux-thunk, which allows you to dispatch a function which is passed dispatch as an argument.\u003c/p\u003e\n\u003cp\u003eDid you know that the source code for \u003ca href=\"https://github.com/gaearon/redux-thunk/blob/master/src/index.js\"\u003eredux-thunk\u003c/a\u003e is only 14 lines? It does its\u0026#39; job because the middleware interface for Redux is so well designed: if the middleware sees a \u003cem\u003ething\u003c/em\u003e which matches some criteria (in this case: it\u0026#39;s a function), it is able to dispatch other actions (in this case when the function says so).\u003c/p\u003e\n\u003cp\u003eBut there isn\u0026#39;t any reason to stop there: \u003ca href=\"https://github.com/acdlite/redux-promise\"\u003emiddleware that sees a promise\u003c/a\u003e can dispatch when the promise resolves (or errors); middleware that requests geolocation could dispatch when the user gives permission. There are a myriad of middleware libraries to choose from or you can write your own, and the advantage over thunk is that they make it easy to test your action creators. If your app uses a particular type of data and you know how you will be requesting it, you can use ONE hard-to-test middleware that interfaces with your now easy-to-test action creators, of which you will have many. Going with thunk alone is simple to begin, but testing it \u003cem\u003esucks\u003c/em\u003e (\u003ca href=\"http://redux.js.org/docs/recipes/WritingTests.html#async-action-creators\"\u003ethe recommended approach is to mock the entire store/state\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eFor example, suppose all your app\u0026#39;s data is fetched over REST. You could write (or pick) a middleware that monitors for objects that look like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003e{\n    type: \u0026#39;REQUEST\u0026#39;,\n    method: \u0026#39;GET\u0026#39;,\n    url: \u0026#39;http://example.com/api/send\u0026#39;\n    query: // ...\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYour action creators now spit out simple objects which makes them a piece of cake to test. Your middleware looks for these \u0026quot;actions\u0026quot; and then dispatches when they are made, when they resolve, and when they error. The middleware is harder to test but once it works, it works (and chances are a library already exists).\u003c/p\u003e\n\u003ch2 id=\"4-immutability-helpers-the-best-kept-secret-in-state-management\"\u003e4. Immutability helpers: the best kept secret in state management\u003c/h2\u003e\n\u003cp\u003eI\u0026#39;ve extolled the virtues of the immutability helpers in a (\u003ca href=\"http://caseyy.org/blog/using-immutability-helpers-for-redux-reducers)[previous\"\u003ehttp://caseyy.org/blog/using-immutability-helpers-for-redux-reducers)[previous\u003c/a\u003e post] - I really like this solution for immutable state management and haven\u0026#39;t felt the need to go all-in and use Immutable.js. Yet.\u003c/p\u003e\n\u003ch2 id=\"5-nest-as-deeply-as-you-need-to\"\u003e5. Nest as deeply as you need to\u003c/h2\u003e\n\u003cp\u003eWhen I took over this current project, all of the components were kept in one folder one level deep. This does not ... scale. When you have hundreds or even dozens of components, it becomes hard to find what you\u0026#39;re looking for. I\u0026#39;ve found a better approach is to make any \u0026quot;parent\u0026quot; component the index file in its own folder, with all of its subcomponents as separate files. If/when those subcomponents become components, they are moved to directories (of the same name) and become index files. This can create some very deeply nested folders, but it\u0026#39;s much better than the alternative. I also have a top-level \u0026quot;partials\u0026quot; folder with shared/reusable components. \u003c/p\u003e\n\u003cp\u003eAs far as the annoying \u003ccode\u003erequire(\u0026#39;../../../../...\u0026#39;)\u003c/code\u003e-like statements you tend to get, \u003ca href=\"https://gist.github.com/branneman/8048520\"\u003ethere are some possible solutions to that, too\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eShortly before I published this, \u003ca href=\"https://hackernoon.com/the-100-correct-way-to-structure-a-react-app-or-why-theres-no-such-thing-3ede534ef1ed\"\u003ethis article came out from Hacker Noon\u003c/a\u003e, which dives into this whole topic a lot more deeply.\u003c/p\u003e\n\u003ch2 id=\"6-test-components-judiciously\"\u003e6. Test components judiciously\u003c/h2\u003e\n\u003cp\u003eGenerally speaking, it\u0026#39;s easiest to test code that is free of side-effects, and React components fail this litmus test (by their nature, they \u0026quot;mutate\u0026quot; the DOM). There\u0026#39;s also a litany of ways that a UI can look \u0026quot;broken\u0026quot; while producing perfectly valid markup and error-free processes, so it\u0026#39;s arguable whether any amount of automated testing can eliminate regressions entirely. Still, there can be advantages to testing components, especially when a component is used in a wide variety of contexts throughout the application. \u003ca href=\"http://caseyy.org/blog/dry-react\"\u003eReusage of components\u003c/a\u003e provides more opportunity for something to go wrong in one context, and a greater need to clearly define the \u003ca href=\"https://medium.freecodecamp.org/the-right-way-to-test-react-components-548a4736ab22\"\u003econtract of the component\u003c/a\u003e, increasing the value of both unit testing and TDD.\u003c/p\u003e\n\u003ch2 id=\"7-proptypes-help-to-self-document-a-component-s-responsibilities\"\u003e7. PropTypes help to self-document a component\u0026#39;s responsibilities\u003c/h2\u003e\n\u003cp\u003eSpeaking of defining the responsibilities of a component, PropTypes are just a godsend here. Not because they provide any safeguard against bugs, or are a replacement for static typing (they aren\u0026#39;t and shouldn\u0026#39;t be), but for the sheer value of writing out the PropTypes any component will accept. They are more documentation that anything else, with the added benefit that React will warn you when your expectations fail.\u003c/p\u003e\n\u003cp\u003eAn additional nugget that took me way too long to learn about was using \u003ccode\u003ePropTypes.shape\u003c/code\u003e to define objects with particular properties. It can a little tempting to go nuts here, so I settled on defining objects down as far as any particular prop that will be accessed within that component itself, and then further deconstructing it inside of any child components as necessary.\u003c/p\u003e\n\u003ch2 id=\"8-any-component-which-can-be-functional-should-be-functional\"\u003e8. Any component which can be functional, should be functional\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://medium.com/dailyjs/we-jumped-the-gun-moving-react-components-to-es2015-class-syntax-2b2bb6f35cb3\"\u003eJacques Favreau made a compelling argument recently\u003c/a\u003e that React jumped the gun in deprecating \u003ccode\u003ecreateClass\u003c/code\u003e in favour of ES6 classes, and I\u0026#39;m tempted to agree. But that is a secondary consideration to the fact that functional stateless components are just easier to understand and reason about. Unless you have a compelling reason for storing state in a React component instead of in Redux, do so. Unless you have a compelling reason to use a lifecycle method, do not use a lifecycle method. For me, the overuse of \u003ccode\u003eshouldComponentUpdate\u003c/code\u003e, \u003ccode\u003ecomponentDidMount\u003c/code\u003e, and \u003ccode\u003ecomponentWillReceiveProps\u003c/code\u003e is a code-smell: it maybe means there is something more deeply wrong about this part of the component tree and it should be rethought.\u003c/p\u003e\n\u003ch2 id=\"9-jsx-is-more-like-html-than-it-is-like-javascript\"\u003e9. JSX is more like HTML than it is like JavaScript\u003c/h2\u003e\n\u003cp\u003eAnother use I have seen for class methods in React is calling out additional \u0026quot;render\u0026quot; methods from the main render function. So, instead of placing all JSX in one render, the render calls \u003ccode\u003erenderSomePartOfTheDOM\u003c/code\u003e. I believe the idea behind this pattern was that it keeps code compartmentalized and the various render functions \u0026quot;doing one thing\u0026quot;, but I personally find it impenetrable spaghetti. JSX should be \u0026quot;templating\u0026quot;, it should look like HTML and HTML is easier to understand when it\u0026#39;s obvious where a given set of tags fits into its environment.\u003c/p\u003e\n\u003cp\u003eIf you think about templating languages like Handlebars, they have \u0026quot;reduced\u0026quot; features compared to Turing-complete languages because you only need a few things: loops are handy, so are conditionals, and the ability to \u0026quot;include\u0026quot; other templates is essential. JSX allows you to \u0026quot;jump\u0026quot; back into JavaScript at any point using curly braces and call other functions if you want to, but any expression must be complete before the closing brace. So \u003ccode\u003emap\u003c/code\u003e works for looping, while ternary expressions are my go-to for conditional statements. Any more complex logic should probably be handled outside of the JSX entirely.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eI have endevoured in this post to be opinionated but not preachy: I\u0026#39;m genuinely curious to know how others handle these problems and if anyone disagrees with me. The flexability of React is both a blessing a curse, and I greatly enjoy working in a space where there are so many ways to skin a cat.\u003c/p\u003e\n","md":"I've been working on a large-scale React-Redux project for several months now. React is not a framework and so it doesn't enforce a particular way of grouping related code or related files. I've been thinking about what it means to provide forward-maintainability in this type of codebase and how we can make our code understandable to other human beings (ok, all human beings, including the original programmer). I thought I would share some of what I've learned (often the hard way) and see what other people who've faced this think.\r\n\r\n## 1. Keep store-related concerns together\r\n\r\nIt seems pretty normal to have one top-level folder for actions and another for reducers, but I've decided that this isn't great. For one thing, both actions and reducers need access to the same set of constants. For another, large stores have a need for a type of \"store-query\" function that doesn't really belong in either place. I've ultimately decided that a better organization is to have a single \"store\" folder containing a set of files which export separately their constants, actions, reducer, and queries. Each part of the store is then grouped together in one file making it easier to understand what its purpose it and cutting down on `import` boilerplate.\r\n\r\n## 2. Test your store\r\n\r\nAction creators (at least synchronous ones) and reducers are extremely easy to test and the benefits of testing therefore greatly outweigh the costs. Redux's `combineReducers` method makes it easy to write reducers that only need to know about a single section of the store, limiting the amount of state we have to mock in our tests. For example, to test an ADD_TODO action we could write:\r\n\r\n```js\r\nimport todosReducers, {constants as c} from '../todos'\r\n\r\nit('should add a TODO', () =\u003e {\r\n    const initialState = []\r\n    const finalState = todoReducer(initialState, {type: c.ADD_TODO, todo: 'Write unit tests'})\r\n    expect(finalState).toHaveLength(1)\r\n})\r\n```\r\n\r\nWhile our application state will surely be more complex than a single array, the todosReducer doesn't care. These types of tests are trivially easy to write, and the process of writing them will solidify the design of the reducers as well and guard against regressions.\r\n\r\n## 3. Redux middleware is powerful\r\n\r\nRedux is not about fetching data, it is about predictable data management. Yet the two are so closely intertwined that you basically cannot have one without the other. The \"de facto\" solution for binding asynchonous calls to redux is redux-thunk, which allows you to dispatch a function which is passed dispatch as an argument.\r\n\r\nDid you know that the source code for [redux-thunk](https://github.com/gaearon/redux-thunk/blob/master/src/index.js) is only 14 lines? It does its' job because the middleware interface for Redux is so well designed: if the middleware sees a _thing_ which matches some criteria (in this case: it's a function), it is able to dispatch other actions (in this case when the function says so).\r\n\r\nBut there isn't any reason to stop there: [middleware that sees a promise](https://github.com/acdlite/redux-promise) can dispatch when the promise resolves (or errors); middleware that requests geolocation could dispatch when the user gives permission. There are a myriad of middleware libraries to choose from or you can write your own, and the advantage over thunk is that they make it easy to test your action creators. If your app uses a particular type of data and you know how you will be requesting it, you can use ONE hard-to-test middleware that interfaces with your now easy-to-test action creators, of which you will have many. Going with thunk alone is simple to begin, but testing it _sucks_ ([the recommended approach is to mock the entire store/state](http://redux.js.org/docs/recipes/WritingTests.html#async-action-creators)).\r\n\r\nFor example, suppose all your app's data is fetched over REST. You could write (or pick) a middleware that monitors for objects that look like this:\r\n\r\n```js\r\n{\r\n    type: 'REQUEST',\r\n    method: 'GET',\r\n    url: 'http://example.com/api/send'\r\n    query: // ...\r\n}\r\n```\r\n\r\nYour action creators now spit out simple objects which makes them a piece of cake to test. Your middleware looks for these \"actions\" and then dispatches when they are made, when they resolve, and when they error. The middleware is harder to test but once it works, it works (and chances are a library already exists).\r\n\r\n## 4. Immutability helpers: the best kept secret in state management\r\n\r\nI've extolled the virtues of the immutability helpers in a (http://caseyy.org/blog/using-immutability-helpers-for-redux-reducers)[previous post] - I really like this solution for immutable state management and haven't felt the need to go all-in and use Immutable.js. Yet.\r\n\r\n## 5. Nest as deeply as you need to\r\n\r\nWhen I took over this current project, all of the components were kept in one folder one level deep. This does not ... scale. When you have hundreds or even dozens of components, it becomes hard to find what you're looking for. I've found a better approach is to make any \"parent\" component the index file in its own folder, with all of its subcomponents as separate files. If/when those subcomponents become components, they are moved to directories (of the same name) and become index files. This can create some very deeply nested folders, but it's much better than the alternative. I also have a top-level \"partials\" folder with shared/reusable components. \r\n\r\nAs far as the annoying `require('../../../../...')`-like statements you tend to get, [there are some possible solutions to that, too](https://gist.github.com/branneman/8048520).\r\n\r\nShortly before I published this, [this article came out from Hacker Noon](https://hackernoon.com/the-100-correct-way-to-structure-a-react-app-or-why-theres-no-such-thing-3ede534ef1ed), which dives into this whole topic a lot more deeply.\r\n\r\n## 6. Test components judiciously\r\n\r\nGenerally speaking, it's easiest to test code that is free of side-effects, and React components fail this litmus test (by their nature, they \"mutate\" the DOM). There's also a litany of ways that a UI can look \"broken\" while producing perfectly valid markup and error-free processes, so it's arguable whether any amount of automated testing can eliminate regressions entirely. Still, there can be advantages to testing components, especially when a component is used in a wide variety of contexts throughout the application. [Reusage of components](http://caseyy.org/blog/dry-react) provides more opportunity for something to go wrong in one context, and a greater need to clearly define the [contract of the component](https://medium.freecodecamp.org/the-right-way-to-test-react-components-548a4736ab22), increasing the value of both unit testing and TDD.\r\n\r\n## 7. PropTypes help to self-document a component's responsibilities\r\n\r\nSpeaking of defining the responsibilities of a component, PropTypes are just a godsend here. Not because they provide any safeguard against bugs, or are a replacement for static typing (they aren't and shouldn't be), but for the sheer value of writing out the PropTypes any component will accept. They are more documentation that anything else, with the added benefit that React will warn you when your expectations fail.\r\n\r\nAn additional nugget that took me way too long to learn about was using `PropTypes.shape` to define objects with particular properties. It can a little tempting to go nuts here, so I settled on defining objects down as far as any particular prop that will be accessed within that component itself, and then further deconstructing it inside of any child components as necessary.\r\n\r\n## 8. Any component which can be functional, should be functional\r\n\r\n[Jacques Favreau made a compelling argument recently](https://medium.com/dailyjs/we-jumped-the-gun-moving-react-components-to-es2015-class-syntax-2b2bb6f35cb3) that React jumped the gun in deprecating `createClass` in favour of ES6 classes, and I'm tempted to agree. But that is a secondary consideration to the fact that functional stateless components are just easier to understand and reason about. Unless you have a compelling reason for storing state in a React component instead of in Redux, do so. Unless you have a compelling reason to use a lifecycle method, do not use a lifecycle method. For me, the overuse of `shouldComponentUpdate`, `componentDidMount`, and `componentWillReceiveProps` is a code-smell: it maybe means there is something more deeply wrong about this part of the component tree and it should be rethought.\r\n\r\n## 9. JSX is more like HTML than it is like JavaScript\r\n\r\nAnother use I have seen for class methods in React is calling out additional \"render\" methods from the main render function. So, instead of placing all JSX in one render, the render calls `renderSomePartOfTheDOM`. I believe the idea behind this pattern was that it keeps code compartmentalized and the various render functions \"doing one thing\", but I personally find it impenetrable spaghetti. JSX should be \"templating\", it should look like HTML and HTML is easier to understand when it's obvious where a given set of tags fits into its environment.\r\n\r\nIf you think about templating languages like Handlebars, they have \"reduced\" features compared to Turing-complete languages because you only need a few things: loops are handy, so are conditionals, and the ability to \"include\" other templates is essential. JSX allows you to \"jump\" back into JavaScript at any point using curly braces and call other functions if you want to, but any expression must be complete before the closing brace. So `map` works for looping, while ternary expressions are my go-to for conditional statements. Any more complex logic should probably be handled outside of the JSX entirely.\r\n\r\n## Conclusion\r\n\r\nI have endevoured in this post to be opinionated but not preachy: I'm genuinely curious to know how others handle these problems and if anyone disagrees with me. The flexability of React is both a blessing a curse, and I greatly enjoy working in a space where there are so many ways to skin a cat."}},"author":{"$oid":"57cddf32d75ea10a19c42073"},"publishedDate":{"$date":"2017-11-07T05:00:00.000Z"}}
{"_id":{"$oid":"59a07d376172c28e3d1603ed"},"slug":"dry-react","title":"DRY React","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eReact is much more than a templating language, and the breadth of ways in which components can be reused greatly exceeds languages like Handlebars. Some of these patterns are more useful than others, however.\u003c/p\u003e\n","md":"React is much more than a templating language, and the breadth of ways in which components can be reused greatly exceeds languages like Handlebars. Some of these patterns are more useful than others, however."},"extended":{"html":"\u003cp\u003eHTML is a declarative language that offers no opportunity for code reuse. When a page contains several elements that are identical or almost identical, the HTML needed to create those elements is simply repeated. Programming languages - whether they be Turing-complete languages like PHP or \u0026quot;templating\u0026quot; languages like Handlebars - provide a way to write a component once and reuse it: but the challenge is knowing how to abstract it. The ways in which a \u0026quot;partial\u0026quot; can be reused are generally limited to whatever arguments are defined by the partial.\u003c/p\u003e\n\u003cp\u003eReact is much more than a templating language, and the breadth of ways in which components can be reused greatly exceeds languages like Handlebars. Some of these patterns are more useful than others, however. In this post I\u0026#39;ll provide a quick summary of the ways in which React components can be reused and the situations in which the pattern should be employed (if any).\u003c/p\u003e\n\u003ch2 id=\"mixins\"\u003eMixins\u003c/h2\u003e\n\u003cp\u003eMixins were originally a way of reusing the same function between React components. The pattern is simple: the component importing mixins at definition that can subscribe to a data store, provide inline styles or really do anything that a React component method can do. This pattern has been deprecated since React 0.13 and \u003ca href=\"https://facebook.github.io/react/blog/2016/07/13/mixins-considered-harmful.html#why-mixins-are-broken\"\u003eyou can read about the reason\u0026#39;s on Facebook\u0026#39;s blog\u003c/a\u003e. The tl;dr is that changes in the mixin always have consequences for the components that use it, including name clashes and side-effects. For the reasons given there, I don\u0026#39;t recommend it.\u003c/p\u003e\n\u003ch2 id=\"inheritance\"\u003eInheritance\u003c/h2\u003e\n\u003cp\u003eInheritance is a classical object-oriented pattern of code reuse, and because React components are \u0026quot;classes\u0026quot; (\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes\"\u003ekind of\u003c/a\u003e) you are free to use this. Suppose you are creating a set of form elements:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003eimport React, {Component} from \u0026#39;react\u0026#39;\n\nclass TextInput extends Component {\n    constructor(props) {\n        super(props)\n        this.state = {\n           value: \u0026#39;\u0026#39;\n        }\n    }\n\n    _updateValue(e) {\n        this.setState({value: e.target.value})\n    }\n\n    render() {\n        return \u0026lt;input type=\u0026quot;text\u0026quot; value={this.state.value} /\u0026gt;\n    }\n}\n\nclass EmailInput extends TextInput {\n    render() {\n        return \u0026lt;input type=\u0026quot;email\u0026quot; value={{this.state.email}} /\u0026gt;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe EmailInput component gains some benefits: it doesn\u0026#39;t have to repeat the annoying code to update the state on when text is entered in the form. The downsides of this approach are even worse than they are for mixins, however. You might say that inheritance has all the same problems that mixins do, but on steroids, since several methods can be inherited at once. Worse yet, the parent component may be directly used to create elements, increasing its responsibility and the number of things that can go wrong in a refactor. In short, inheritance and class introduce a host of problems in general, and like mixins, are \u003ca href=\"https://facebook.github.io/react/docs/composition-vs-inheritance.html\"\u003enot recommended by the creators of React\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"subcomponents\"\u003eSubcomponents\u003c/h2\u003e\n\u003cp\u003eReact components pass props from parents to children, and this can be exploited to do simple remixing. Taking the example above, we could make the Input component agnostic as to it\u0026#39;s type:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003eimport React, {Component} from \u0026#39;react\u0026#39;\n\nclass Input extends Component {\n    constructor(props) {\n        super(props)\n        this.state = {\n           value: \u0026#39;\u0026#39;\n        }\n        this._updateValue = this._updateValue.bind(this)\n    }\n\n    _updateValue(e) {\n        this.setState({value: e.target.value})\n    }\n\n    render() {\n        return \u0026lt;input type={this.props.type || \u0026#39;text\u0026#39;} value={this.state.value} /\u0026gt;\n    }\n}\n\nconst EmailInput = props =\u0026gt; {\n    return \u0026lt;Input type=\u0026quot;email\u0026quot; {...props} /\u0026gt;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEven with this simple example, we can see the advantages of subcomponents. EmailInput can change from being class-based to functional, making it easier to understand. Everything EmailInput provides to Input is clearly laid out in its prop declarations. Since EmailInput doesn\u0026#39;t have any methods, there isn\u0026#39;t any confusion about responsibility: EmailInput is just a special case of Input.\u003c/p\u003e\n\u003cp\u003eIt can become tempting to overuse this and create special cases of special cases. There are two downsides to this approach. One is that it has the potential to create an awful lot of nesting. This nesting increases the complexity of the DOM, the component hierarchy in the debug tools, and in the prop chains. Name conflicts will eventually occur in the prop chains. All of these create headaches when debugging. Another disadvantage is that every single special case is indeed a new component - even if it contains much less code. In this simplified example, you\u0026#39;d need a new component (probably a new file) for EmailInput, PasswordInput, NumberInput, etc.. \u003c/p\u003e\n\u003ch2 id=\"subcomponents-with-children\"\u003eSubcomponents with children\u003c/h2\u003e\n\u003cp\u003eOne thing I love about React components over \u0026quot;partials\u0026quot; in templating languages is the special \u003ccode\u003echildren\u003c/code\u003e property. In a recent PHP project, I wanted to create a reusable modal and ended up having to split to necessary code between two files: one to open the modal\u0026#39;s DOM elements and another to close them. This is ugly and I didn\u0026#39;t like doing it (but I did it anyway). In React you can actually make this beautiful:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003econst Modal = props =\u0026gt; {\n    const display: props.isOpen ? \u0026#39;block\u0026#39; : \u0026#39;none\u0026#39;\n    return (\n        \u0026lt;div className=\u0026quot;modal-wrapper\u0026quot; onClick={props.onRequestClose} style={{display}}\u0026gt;\n            \u0026lt;div className=\u0026quot;modal\u0026quot;\u0026gt;\n                {props.children}\n            \u0026lt;/div\u0026gt;\n        \u0026lt;/div\u0026gt;\n    )\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(I\u0026#39;ll leave out all of the CSS you need to make the modal behave properly).\u003c/p\u003e\n\u003cp\u003eWe can put literally anything inside it as long we remember to pass the \u003ccode\u003eisOpen\u003c/code\u003e and \u003ccode\u003eonRequestClose\u003c/code\u003e methods (which we would always carefully document with PropTypes, right?). \u003c/p\u003e\n\u003ch2 id=\"subcomponents-with-functions-as-children\"\u003eSubcomponents with functions as children\u003c/h2\u003e\n\u003cp\u003eWe have to remember to pass those props because React is like a boy band: One Direction (of information flow). Since a modal can\u0026#39;t open itself, there must be some controller component sitting at a level above both the modal and the thing opening it. That controller (or a redux store) keeps track of whether the modal is open and passes that information down as props. Is there a way that we can abstract state control, instead of markup?\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003eclass ModalController extends Component {\n    constructor(props) {\n        super(props)\n        this.state = {\n            open: false\n        }\n        this._toggleOpen = this._toggleOpen.bind(this)\n    }\n\n    _toggleOpen() {\n        this.setState({open: !this.state.open})\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBut what should the render method be? The child pattern on its own isn\u0026#39;t useful because ModalController has no opporunity to send props to its children.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003e// This won\u0026#39;t work:\n\u0026lt;div\u0026gt;\n    {this.props.children // but no way to give it _toggleOpen}\n    \u0026lt;Modal open={this.state.open} /\u0026gt;\n\u0026lt;/div\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe solution is the \u003cstrong\u003efunction-as-child pattern\u003c/strong\u003e. Somewhat unexpectedly, you can pass a function instead of an component as the child of another component. Our ModalController render method is:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003erender() {\n    return this.props.children(this.state.open, this._toggleOpen)\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand we use it like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003e\u0026lt;ModalController\u0026gt;\n    {(open, toggle) =\u0026gt; {\n        const display: props.isOpen ? \u0026#39;block\u0026#39; : \u0026#39;none\u0026#39;\n        return (\n            \u0026lt;div\u0026gt;    \n                \u0026lt;button type=\u0026quot;button\u0026quot; onClick={toggle}\u0026gt;Open Modal\u0026lt;/button\u0026gt;\n                \u0026lt;Modal open={open}\u0026gt;\n                    {// modal interior}\n                \u0026lt;/Modal\u0026gt;\n             \u0026lt;/div\u0026gt;\n        )\n    }}\n\u0026lt;/ModalController\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOf course, we now need two different components to make our Modal work properly.\u003c/p\u003e\n\u003ch2 id=\"higher-order-components\"\u003eHigher-order components\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ehigher-order function\u003c/strong\u003e is simply a function that returns another function, a powerful abstraction pattern that is the heart of functional programming. In React, a component is a function that returns an element (or a class with a render function that returns an element), but there is no reason the chain has to stop there. We can have functions returning components.\u003c/p\u003e\n\u003cp\u003eHere is what it looks like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003econst HOC = (args) =\u0026gt; props =\u0026gt; {\n    // regular functional component\n}\n\nconst HOC = (args) =\u0026gt; class extends Component {\n    // regular class component\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn each case, the inner components have access to all the normal props and state, as well as the arguments, which are provided at the time the component is created rather than the time the element is created. The React-Redux \u003ccode\u003econnect\u003c/code\u003e function is a higher order component - it produces a React component but the user of connect doesn\u0026#39;t write any JSX at all to do it.\u003c/p\u003e\n\u003cp\u003eAny of the earlier examples in this tutorial could be reworked as HOCs. But let\u0026#39;s take our Modal example again to illustrate the concept. It would be really great to combine ModalController and Modal into a single reusable component, while leaving both the button and the modal content up to the consuming code. Here is one solution using HOCs:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003econst HOC = (Button) =\u0026gt; class extends Component {\n    constructor(props) {\n        super(props)\n        this.state = {\n            open: false\n        }\n        this._toggleOpen = this._toggleOpen.bind(this)\n    }\n\n    _toggleOpen() {\n        this.setState({open: !this.state.open})\n    }\n\n    render() {\n        const display: props.isOpen ? \u0026#39;block\u0026#39; : \u0026#39;none\u0026#39;\n        return (\n            \u0026lt;div\u0026gt;\n                \u0026lt;Button type=\u0026quot;button\u0026quot; onClick={this._toggleOpen} {...this.props} /\u0026gt;\n                \u0026lt;div className=\u0026quot;modal-wrapper\u0026quot; onClick={props.onRequestClose} style={{display}}\u0026gt;\n                    \u0026lt;div className=\u0026quot;modal\u0026quot;\u0026gt;\n                        {props.children}\n                    \u0026lt;/div\u0026gt;\n                \u0026lt;/div\u0026gt;\n            \u0026lt;/div\u0026gt;\n        )\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can use it like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003econst ButtonWithModal = HOC(\u0026lt;AnyButtonComponent\u0026gt;)\n\u0026lt;ButtonWithModal\u0026gt;\n    \u0026lt;ModalContent /\u0026gt;\n\u0026lt;/ButtonWithModal\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewhich gives us the best of both worlds.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eHOCs are probably the most powerful pattern you can employ to reuse code, but they can often be overkill. The function-as-child pattern is quite underutilised in the React community, and the choice of whether to use a function-as-child or a HOC pattern can be a difficult one. And of course, subcomponents are simple to grasp and simple to use, and may often be the best choice for a particular problem.\u003c/p\u003e\n","md":"HTML is a declarative language that offers no opportunity for code reuse. When a page contains several elements that are identical or almost identical, the HTML needed to create those elements is simply repeated. Programming languages - whether they be Turing-complete languages like PHP or \"templating\" languages like Handlebars - provide a way to write a component once and reuse it: but the challenge is knowing how to abstract it. The ways in which a \"partial\" can be reused are generally limited to whatever arguments are defined by the partial.\r\n\r\nReact is much more than a templating language, and the breadth of ways in which components can be reused greatly exceeds languages like Handlebars. Some of these patterns are more useful than others, however. In this post I'll provide a quick summary of the ways in which React components can be reused and the situations in which the pattern should be employed (if any).\r\n\r\n## Mixins\r\n\r\nMixins were originally a way of reusing the same function between React components. The pattern is simple: the component importing mixins at definition that can subscribe to a data store, provide inline styles or really do anything that a React component method can do. This pattern has been deprecated since React 0.13 and [you can read about the reason's on Facebook's blog](https://facebook.github.io/react/blog/2016/07/13/mixins-considered-harmful.html#why-mixins-are-broken). The tl;dr is that changes in the mixin always have consequences for the components that use it, including name clashes and side-effects. For the reasons given there, I don't recommend it.\r\n\r\n## Inheritance\r\n\r\nInheritance is a classical object-oriented pattern of code reuse, and because React components are \"classes\" ([kind of](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes)) you are free to use this. Suppose you are creating a set of form elements:\r\n\r\n```js\r\nimport React, {Component} from 'react'\r\n\r\nclass TextInput extends Component {\r\n    constructor(props) {\r\n        super(props)\r\n        this.state = {\r\n           value: ''\r\n        }\r\n    }\r\n\r\n    _updateValue(e) {\r\n        this.setState({value: e.target.value})\r\n    }\r\n\r\n    render() {\r\n        return \u003cinput type=\"text\" value={this.state.value} /\u003e\r\n    }\r\n}\r\n\r\nclass EmailInput extends TextInput {\r\n    render() {\r\n        return \u003cinput type=\"email\" value={{this.state.email}} /\u003e\r\n    }\r\n}\r\n```\r\n\r\nThe EmailInput component gains some benefits: it doesn't have to repeat the annoying code to update the state on when text is entered in the form. The downsides of this approach are even worse than they are for mixins, however. You might say that inheritance has all the same problems that mixins do, but on steroids, since several methods can be inherited at once. Worse yet, the parent component may be directly used to create elements, increasing its responsibility and the number of things that can go wrong in a refactor. In short, inheritance and class introduce a host of problems in general, and like mixins, are [not recommended by the creators of React](https://facebook.github.io/react/docs/composition-vs-inheritance.html).\r\n\r\n## Subcomponents\r\n\r\nReact components pass props from parents to children, and this can be exploited to do simple remixing. Taking the example above, we could make the Input component agnostic as to it's type:\r\n\r\n```js\r\nimport React, {Component} from 'react'\r\n\r\nclass Input extends Component {\r\n    constructor(props) {\r\n        super(props)\r\n        this.state = {\r\n           value: ''\r\n        }\r\n        this._updateValue = this._updateValue.bind(this)\r\n    }\r\n\r\n    _updateValue(e) {\r\n        this.setState({value: e.target.value})\r\n    }\r\n\r\n    render() {\r\n        return \u003cinput type={this.props.type || 'text'} value={this.state.value} /\u003e\r\n    }\r\n}\r\n\r\nconst EmailInput = props =\u003e {\r\n    return \u003cInput type=\"email\" {...props} /\u003e\r\n}\r\n```\r\n\r\nEven with this simple example, we can see the advantages of subcomponents. EmailInput can change from being class-based to functional, making it easier to understand. Everything EmailInput provides to Input is clearly laid out in its prop declarations. Since EmailInput doesn't have any methods, there isn't any confusion about responsibility: EmailInput is just a special case of Input.\r\n\r\nIt can become tempting to overuse this and create special cases of special cases. There are two downsides to this approach. One is that it has the potential to create an awful lot of nesting. This nesting increases the complexity of the DOM, the component hierarchy in the debug tools, and in the prop chains. Name conflicts will eventually occur in the prop chains. All of these create headaches when debugging. Another disadvantage is that every single special case is indeed a new component - even if it contains much less code. In this simplified example, you'd need a new component (probably a new file) for EmailInput, PasswordInput, NumberInput, etc.. \r\n\r\n## Subcomponents with children\r\n\r\nOne thing I love about React components over \"partials\" in templating languages is the special `children` property. In a recent PHP project, I wanted to create a reusable modal and ended up having to split to necessary code between two files: one to open the modal's DOM elements and another to close them. This is ugly and I didn't like doing it (but I did it anyway). In React you can actually make this beautiful:\r\n\r\n```js\r\nconst Modal = props =\u003e {\r\n    const display: props.isOpen ? 'block' : 'none'\r\n    return (\r\n        \u003cdiv className=\"modal-wrapper\" onClick={props.onRequestClose} style={{display}}\u003e\r\n            \u003cdiv className=\"modal\"\u003e\r\n                {props.children}\r\n            \u003c/div\u003e\r\n        \u003c/div\u003e\r\n    )\r\n}\r\n```\r\n\r\n(I'll leave out all of the CSS you need to make the modal behave properly).\r\n\r\nWe can put literally anything inside it as long we remember to pass the `isOpen` and `onRequestClose` methods (which we would always carefully document with PropTypes, right?). \r\n    \r\n## Subcomponents with functions as children\r\n\r\nWe have to remember to pass those props because React is like a boy band: One Direction (of information flow). Since a modal can't open itself, there must be some controller component sitting at a level above both the modal and the thing opening it. That controller (or a redux store) keeps track of whether the modal is open and passes that information down as props. Is there a way that we can abstract state control, instead of markup?\r\n\r\n```js\r\nclass ModalController extends Component {\r\n    constructor(props) {\r\n        super(props)\r\n        this.state = {\r\n            open: false\r\n        }\r\n        this._toggleOpen = this._toggleOpen.bind(this)\r\n    }\r\n\r\n    _toggleOpen() {\r\n        this.setState({open: !this.state.open})\r\n    }\r\n}\r\n```\r\n\r\nBut what should the render method be? The child pattern on its own isn't useful because ModalController has no opporunity to send props to its children.\r\n\r\n```js\r\n// This won't work:\r\n\u003cdiv\u003e\r\n    {this.props.children // but no way to give it _toggleOpen}\r\n    \u003cModal open={this.state.open} /\u003e\r\n\u003c/div\u003e\r\n```\r\n\r\nThe solution is the **function-as-child pattern**. Somewhat unexpectedly, you can pass a function instead of an component as the child of another component. Our ModalController render method is:\r\n\r\n```js\r\nrender() {\r\n    return this.props.children(this.state.open, this._toggleOpen)\r\n}\r\n```\r\n\r\nand we use it like this:\r\n\r\n```js\r\n\u003cModalController\u003e\r\n    {(open, toggle) =\u003e {\r\n        const display: props.isOpen ? 'block' : 'none'\r\n        return (\r\n            \u003cdiv\u003e    \r\n                \u003cbutton type=\"button\" onClick={toggle}\u003eOpen Modal\u003c/button\u003e\r\n                \u003cModal open={open}\u003e\r\n                    {// modal interior}\r\n                \u003c/Modal\u003e\r\n             \u003c/div\u003e\r\n        )\r\n    }}\r\n\u003c/ModalController\u003e\r\n```\r\n\r\nOf course, we now need two different components to make our Modal work properly.\r\n\r\n## Higher-order components\r\n\r\nA **higher-order function** is simply a function that returns another function, a powerful abstraction pattern that is the heart of functional programming. In React, a component is a function that returns an element (or a class with a render function that returns an element), but there is no reason the chain has to stop there. We can have functions returning components.\r\n\r\nHere is what it looks like:\r\n\r\n```js\r\nconst HOC = (args) =\u003e props =\u003e {\r\n    // regular functional component\r\n}\r\n\r\nconst HOC = (args) =\u003e class extends Component {\r\n    // regular class component\r\n}\r\n```\r\n\r\nIn each case, the inner components have access to all the normal props and state, as well as the arguments, which are provided at the time the component is created rather than the time the element is created. The React-Redux `connect` function is a higher order component - it produces a React component but the user of connect doesn't write any JSX at all to do it.\r\n\r\nAny of the earlier examples in this tutorial could be reworked as HOCs. But let's take our Modal example again to illustrate the concept. It would be really great to combine ModalController and Modal into a single reusable component, while leaving both the button and the modal content up to the consuming code. Here is one solution using HOCs:\r\n\r\n```js\r\nconst HOC = (Button) =\u003e class extends Component {\r\n    constructor(props) {\r\n        super(props)\r\n        this.state = {\r\n            open: false\r\n        }\r\n        this._toggleOpen = this._toggleOpen.bind(this)\r\n    }\r\n\r\n    _toggleOpen() {\r\n        this.setState({open: !this.state.open})\r\n    }\r\n \r\n    render() {\r\n        const display: props.isOpen ? 'block' : 'none'\r\n        return (\r\n            \u003cdiv\u003e\r\n                \u003cButton type=\"button\" onClick={this._toggleOpen} {...this.props} /\u003e\r\n                \u003cdiv className=\"modal-wrapper\" onClick={props.onRequestClose} style={{display}}\u003e\r\n                    \u003cdiv className=\"modal\"\u003e\r\n                        {props.children}\r\n                    \u003c/div\u003e\r\n                \u003c/div\u003e\r\n            \u003c/div\u003e\r\n        )\r\n    }\r\n}\r\n```\r\n\r\nWe can use it like this:\r\n\r\n```js\r\nconst ButtonWithModal = HOC(\u003cAnyButtonComponent\u003e)\r\n\u003cButtonWithModal\u003e\r\n    \u003cModalContent /\u003e\r\n\u003c/ButtonWithModal\u003e\r\n```\r\n\r\nwhich gives us the best of both worlds.\r\n\r\n## Conclusion\r\n\r\nHOCs are probably the most powerful pattern you can employ to reuse code, but they can often be overkill. The function-as-child pattern is quite underutilised in the React community, and the choice of whether to use a function-as-child or a HOC pattern can be a difficult one. And of course, subcomponents are simple to grasp and simple to use, and may often be the best choice for a particular problem."}},"author":{"$oid":"57cddf32d75ea10a19c42073"},"publishedDate":{"$date":"2017-09-26T04:00:00.000Z"}}
{"_id":{"$oid":"59ece3e1d645338e3d22530b"},"slug":"on-react-s-barriers-to-entry","title":"On React's barriers to entry","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eReact requires a barrier to entry to get started with, that dropping a script tag on a page does not. Or so the common wisdom goes.\u003c/p\u003e\n","md":"React requires a barrier to entry to get started with, that dropping a script tag on a page does not. Or so the common wisdom goes."},"extended":{"html":"\u003cp\u003eIn \u003ca href=\"https://medium.com/@mikeal/react-is-the-new-dojo-18bd9059378f\"\u003eReact is the new Dojo\u003c/a\u003e, Alex Russell argues that React\u0026#39;s days as king among front-end frameworks are limited if it doesn\u0026#39;t increase its circle of appeal outside of specialists who have the patience to learn all of the tooling that comes with it.\u003c/p\u003e\n\u003cp\u003eAs he puts it:\u003c/p\u003e\n\u003cblockquote\u003eThe Web didnt win because it was the favorite among enterprises and real developers. It won because it scaled down better than it scaled up. It won because it amateurized software development and unlocked the creativity of an entire generation of programmers that couldnt participate in software until The Web.\u003c/blockquote\u003e\n\n\u003cp\u003eOf all the holy wars in the web community, this has been one of the hardest for me. On the one hand, I was attracted to coding for the web in the first place because of the openness of the platform, and tools like WordPress and jQuery were invaluable to me in getting literally dozens of sites up and running in those early days. In otherwords, I\u0026#39;m exactly the type of developer Alex is talking about.\u003c/p\u003e\n\u003cp\u003eOn the other hand, my mindset has involved as I\u0026#39;ve become a more confident programmer. Once I became familiar with MVC patterns, WordPress felt ... awful to work with. So many of the \u0026quot;tricks\u0026quot; that I\u0026#39;d accepted as a normal part of WordPress development revealed themselves as clear anti-patterns. Similarly, once I learned to program the DOM with declarative rather than procedural code, doing anything in jQuery felt like rolling a stone up a hill. With these transitions came the realization that plugins aren\u0026#39;t always necessary. WordPress plugins are opinionated and tie down your entire stack from database to design with a particular way of doing things. In my experience, clients and stakeholders and never happy with a plugin solution: it gets the job done, but not in quite the way they expect.\u003c/p\u003e\n\u003cp\u003eThe question becomes: how much of the still-widespread use of WordPress and jQuery is due to developers being comfortable in those environments, versus the widespread plugin ecosystem that surrounds each one already. And if the chore of building plugins the old way is arduous enough, the community will simply move on. \u003c/p\u003e\n\u003cp\u003eIn other words, one of the ways that jQuery \u0026quot;amateurized\u0026quot; software development was by standing on the shoulders of giants. How much longer will the giants be around for?\u003c/p\u003e\n\u003cp\u003eNevertheless, Alex is right about one thing: React requires a barrier to entry to get started with, that dropping a script tag on a page does not. Or does it? As Dan Abromov points out, compiling JSX need not be any harder running a CSS preprocessor (a barrier to entry that most frontend developers are already employing). \u003ca href=\"https://twitter.com/dan_abramov/status/1011995700748521477\"\u003eReact itself can be included on a page via a simple script tag, just like jQuery\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eI tried these two steps together and was able to get a React live on a page without using Webpack, Parceljs or anything else. In the example below, the \u0026quot;Today\u0026quot; button is rendered with JavaScript and activates an event when clicked, that fills the date input with the current date. \nHere is the code:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com//CAYdenberg/46a0d23c1afbb3e910f30b6dd0290006.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cp\u003e  \u003cinput type=\"date\" id=\"date-input\" /\u003e\n  \u003cdiv id=\"date-picker\"\u003e\u003c/div\u003e\n  \u003cscript type=\"text/javascript\" src=\"https://unpkg.com/react@16.0.0/umd/react.production.min.js\"\u003e\u003c/script\u003e\n  \u003cscript type=\"text/javascript\" src=\"https://unpkg.com/react-dom@16.0.0/umd/react-dom.production.min.js\"\u003e\u003c/script\u003e\n  \u003cscript type=\"text/javascript\" src=\"https://momentjs.com/downloads/moment.js\"\u003e\u003c/script\u003e\n  \u003cscript type=\"text/javascript\" src=\"/today.js\"\u003e\u003c/script\u003e\u003c/p\u003e\n\u003cp\u003eOne definite plus to using jQuery is that the plugin interface is much more precisely defined. While React\u0026#39;s componentized system would seem to lend itself well to creating \u0026quot;plugins\u0026quot;, the details are surprisingly complicated because there is currently no consensus on how React components should be bundled. For example, which type of JavaScript should they be transpiled to and how should they handle styles?\u003c/p\u003e\n\u003cp\u003eNevertheless, I have to conclude that the difference in activation energy between jQuery and React is not as great an many people seem to believe it is.\u003c/p\u003e\n","md":"In [React is the new Dojo](https://medium.com/@mikeal/react-is-the-new-dojo-18bd9059378f), Alex Russell argues that React's days as king among front-end frameworks are limited if it doesn't increase its circle of appeal outside of specialists who have the patience to learn all of the tooling that comes with it.\r\n\r\nAs he puts it:\r\n\r\n\u003cblockquote\u003eThe Web didnt win because it was the favorite among enterprises and real developers. It won because it scaled down better than it scaled up. It won because it amateurized software development and unlocked the creativity of an entire generation of programmers that couldnt participate in software until The Web.\u003c/blockquote\u003e\r\n\r\nOf all the holy wars in the web community, this has been one of the hardest for me. On the one hand, I was attracted to coding for the web in the first place because of the openness of the platform, and tools like WordPress and jQuery were invaluable to me in getting literally dozens of sites up and running in those early days. In otherwords, I'm exactly the type of developer Alex is talking about.\r\n\r\nOn the other hand, my mindset has involved as I've become a more confident programmer. Once I became familiar with MVC patterns, WordPress felt ... awful to work with. So many of the \u0026quot;tricks\u0026quot; that I'd accepted as a normal part of WordPress development revealed themselves as clear anti-patterns. Similarly, once I learned to program the DOM with declarative rather than procedural code, doing anything in jQuery felt like rolling a stone up a hill. With these transitions came the realization that plugins aren't always necessary. WordPress plugins are opinionated and tie down your entire stack from database to design with a particular way of doing things. In my experience, clients and stakeholders and never happy with a plugin solution: it gets the job done, but not in quite the way they expect.\r\n\r\nThe question becomes: how much of the still-widespread use of WordPress and jQuery is due to developers being comfortable in those environments, versus the widespread plugin ecosystem that surrounds each one already. And if the chore of building plugins the old way is arduous enough, the community will simply move on. \r\n\r\nIn other words, one of the ways that jQuery \u0026quot;amateurized\u0026quot; software development was by standing on the shoulders of giants. How much longer will the giants be around for?\r\n\r\nNevertheless, Alex is right about one thing: React requires a barrier to entry to get started with, that dropping a script tag on a page does not. Or does it? As Dan Abromov points out, compiling JSX need not be any harder running a CSS preprocessor (a barrier to entry that most frontend developers are already employing). [React itself can be included on a page via a simple script tag, just like jQuery](https://twitter.com/dan_abramov/status/1011995700748521477)\r\n\r\nI tried these two steps together and was able to get a React live on a page without using Webpack, Parceljs or anything else. In the example below, the \u0026quot;Today\u0026quot; button is rendered with JavaScript and activates an event when clicked, that fills the date input with the current date. \r\nHere is the code:\r\n\r\n\u003cscript src=\"https://gist.github.com//CAYdenberg/46a0d23c1afbb3e910f30b6dd0290006.js\"\u003e\u003c/script\u003e\r\n\r\n\r\n\r\n  \u003cinput type=\"date\" id=\"date-input\" /\u003e\r\n  \u003cdiv id=\"date-picker\"\u003e\u003c/div\u003e\r\n  \u003cscript type=\"text/javascript\" src=\"https://unpkg.com/react@16.0.0/umd/react.production.min.js\"\u003e\u003c/script\u003e\r\n  \u003cscript type=\"text/javascript\" src=\"https://unpkg.com/react-dom@16.0.0/umd/react-dom.production.min.js\"\u003e\u003c/script\u003e\r\n  \u003cscript type=\"text/javascript\" src=\"https://momentjs.com/downloads/moment.js\"\u003e\u003c/script\u003e\r\n  \u003cscript type=\"text/javascript\" src=\"/today.js\"\u003e\u003c/script\u003e\r\n\r\nOne definite plus to using jQuery is that the plugin interface is much more precisely defined. While React's componentized system would seem to lend itself well to creating \u0026quot;plugins\u0026quot;, the details are surprisingly complicated because there is currently no consensus on how React components should be bundled. For example, which type of JavaScript should they be transpiled to and how should they handle styles?\r\n\r\nNevertheless, I have to conclude that the difference in activation energy between jQuery and React is not as great an many people seem to believe it is."}},"publishedDate":{"$date":"2018-11-01T20:26:42.000Z"},"author":{"$oid":"57cddf32d75ea10a19c42073"}}
{"_id":{"$oid":"5a94cde18b2e8b8c1c5175d6"},"slug":"functions-as-props-describing-a-thing-by-what-it-can-do","title":"Functions as props: Describing a thing by what it can do","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eOne of the best things about React is that it manages to combine almost-real JavaScript with an intuitive way to interact with the DOM.\u003c/p\u003e\n","md":"One of the best things about React is that it manages to combine almost-real JavaScript with an intuitive way to interact with the DOM."},"extended":{"html":"\u003cp\u003eOne of the best things about React is that it manages to combine almost-real JavaScript with an intuitive way to interact with the DOM. Whereas in a templating language you need a new vocabulary to have conditional statements, in JSX you can do things like:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/CAYdenberg/84bbac55cff24c380c720a1361815524.js\"\u003e\u003c/script\u003e\n\n\u003cp\u003ewhich is evaluated like any other JavaScript \u0026quot;and\u0026quot; statement (nothing will render if props.visible is false, otherwise \u003ccode\u003e\u0026lt;component\u0026gt;\u003c/code\u003e will render).\u003c/p\u003e\n\u003cp\u003eSimilarly, the ability to pass functions as props provides a simple way to tie user actions to particular interface elements, without having to use an event emitter-like system. Just as functions can be passed as arguments into a normal JavaScript function, so are functions passed as props into other components.\u003c/p\u003e\n\u003cp\u003eConsider a generic button element, which might be part of a pattern library:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/CAYdenberg/c8233bf54e7ca6779d4f1b7270207b2e.js\"\u003e\u003c/script\u003e\n\n\u003cp\u003eSo what? All we\u0026#39;ve done is abstract over an HTML button element. This component knows nothing about what will happen when it\u0026#39;s clicked - it simply delegates that responsibility up to its parent.\u003c/p\u003e\n\u003cp\u003eAnd therein lies the power. Suppose at certain times the button will not do anything. We could expand it to communicate that:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/CAYdenberg/7aefb9ae78947507845f5ac1f51c43fb.js\"\u003e\u003c/script\u003e\n\n\u003cp\u003eAt this point, the parent can decide what the button does, and even if it does \u003cem\u003eanything at all\u003c/em\u003e. If it doesn\u0026#39;t have a click handler, the button will appear disabled, clearly communicating its function through its form. Rather than tracking separate props for the click handler and \u003ccode\u003edisabled\u003c/code\u003e you can remove the click handler when the button is disabled. This is very hard to get right with an event-based system.\u003c/component\u003e\u003c/p\u003e\n","md":"One of the best things about React is that it manages to combine almost-real JavaScript with an intuitive way to interact with the DOM. Whereas in a templating language you need a new vocabulary to have conditional statements, in JSX you can do things like:\r\n\r\n\u003cscript src=\"https://gist.github.com/CAYdenberg/84bbac55cff24c380c720a1361815524.js\"\u003e\u003c/script\u003e\r\n\r\nwhich is evaluated like any other JavaScript \u0026quot;and\u0026quot; statement (nothing will render if props.visible is false, otherwise `\u003ccomponent\u003e` will render).\r\n\r\nSimilarly, the ability to pass functions as props provides a simple way to tie user actions to particular interface elements, without having to use an event emitter-like system. Just as functions can be passed as arguments into a normal JavaScript function, so are functions passed as props into other components.\r\n\r\nConsider a generic button element, which might be part of a pattern library:\r\n\r\n\u003cscript src=\"https://gist.github.com/CAYdenberg/c8233bf54e7ca6779d4f1b7270207b2e.js\"\u003e\u003c/script\u003e\r\n\r\nSo what? All we've done is abstract over an HTML button element. This component knows nothing about what will happen when it's clicked - it simply delegates that responsibility up to its parent.\r\n\r\nAnd therein lies the power. Suppose at certain times the button will not do anything. We could expand it to communicate that:\r\n\r\n\u003cscript src=\"https://gist.github.com/CAYdenberg/7aefb9ae78947507845f5ac1f51c43fb.js\"\u003e\u003c/script\u003e\r\n\r\nAt this point, the parent can decide what the button does, and even if it does _anything at all_. If it doesn't have a click handler, the button will appear disabled, clearly communicating its function through its form. Rather than tracking separate props for the click handler and `disabled` you can remove the click handler when the button is disabled. This is very hard to get right with an event-based system.\u003c/component\u003e"}},"author":{"$oid":"57cddf32d75ea10a19c42073"},"publishedDate":{"$date":"2018-11-08T22:55:09.000Z"}}
{"_id":{"$oid":"5af712f99926e403eb479b7f"},"sortOrder":8,"slug":"grand-unified-seach-gus","title":"Grand Unified Seach (GUS)","__t":"Project","tech":[{"$oid":"57edd06c8a31cb06684b45a2"},{"$oid":"5af9ac459926e403eb479b81"}],"state":"published","__v":2,"author":{"$oid":"5af712ca9926e403eb479b7e"},"brief":"Customizable real estate search tool","links":{"code":"","site":"https://www.soniatarabay.com/search"},"myRole":{"html":"\u003cp\u003eRedman Technologies built a search tool that satisfies these requirements, by interfacing with a common API and accepting a JSON object customizing the style of the site and certain attributes like geogrpahic location. The tool also includes user accounts for saving particular search configurations and favouriting properties. I was entirely responsible for building the front-end of the application.\u003c/p\u003e\n\u003cp\u003eThe biggest challenge was building a custom integration between Vue and Google Maps as there was no existing package that supported our needs. I ended up creating a small package that accepts map data (like pin and polygon data) in a declarative way and uses simple diffing to draw and update the map using Google\u0026#39;s API.\u003c/p\u003e\n\u003cp\u003eAn example of the tool can be seen at \u003ca href=\"http://www.scottveitch.ca/search\"\u003eScott Veitch\u0026#39;s website\u003c/a\u003e. However, the parameters of the default search, the results that come up in the search bar, the initial region shown by the map and the fonts and colours are all customizable and differ from site-to-site.\u003c/p\u003e\n","md":"Redman Technologies built a search tool that satisfies these requirements, by interfacing with a common API and accepting a JSON object customizing the style of the site and certain attributes like geogrpahic location. The tool also includes user accounts for saving particular search configurations and favouriting properties. I was entirely responsible for building the front-end of the application.\r\n\r\nThe biggest challenge was building a custom integration between Vue and Google Maps as there was no existing package that supported our needs. I ended up creating a small package that accepts map data (like pin and polygon data) in a declarative way and uses simple diffing to draw and update the map using Google's API.\r\n\r\nAn example of the tool can be seen at [Scott Veitch's website](http://www.scottveitch.ca/search). However, the parameters of the default search, the results that come up in the search bar, the initial region shown by the map and the fonts and colours are all customizable and differ from site-to-site."},"problem":{"html":"\u003cp\u003eMost realtors choose to showcase MLS listing data on their personal websites as a way to drive traffic and make an initial contact with their users. A common tool can be used across many different sites, but we need to give each site a unique look and feel, as well as customize the search for the geographical region and types of properties that the realtor or office serves.\u003c/p\u003e\n","md":"Most realtors choose to showcase MLS listing data on their personal websites as a way to drive traffic and make an initial contact with their users. A common tool can be used across many different sites, but we need to give each site a unique look and feel, as well as customize the search for the geographical region and types of properties that the realtor or office serves."},"status":{"html":"\u003cp\u003eThe tool was very popular and is being integrated into a larger website builder/CMS for creating real-estate websites.\u003c/p\u003e\n","md":"The tool was very popular and is being integrated into a larger website builder/CMS for creating real-estate websites."},"publishedDate":{"$date":"2018-06-12T04:00:00.000Z"},"image":{"secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1544482895/qjspy2pyabjvkircjkre.png","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1544482895/qjspy2pyabjvkircjkre.png","resource_type":"image","format":"png","height":810,"width":1854,"signature":"679b89f170503a125b39fab73450bc031b4ad45d","version":1544482895,"public_id":"qjspy2pyabjvkircjkre"}}
{"_id":{"$oid":"5b453399ab37ca5846b9ec99"},"slug":"a-dev-server-proxy-using-parcel-and-express","title":"A dev server proxy using parcel and express","__t":"Post","state":"draft","__v":0,"content":{"brief":{"html":"","md":""},"extended":{"html":"\u003cp\u003eabbey is a good example\u003c/p\u003e\n","md":"abbey is a good example"}}}
{"_id":{"$oid":"5b5a627206b4cb76f813ded1"},"slug":"chartpen-an-easy-solution-for-putting-a-chart-on-a-website-or-blog","title":"Chartpen: An easy solution for putting a chart on a website or blog","__t":"Post","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eSay you have a blog that talks about science or data on a regular basis. What do you do?\u003c/p\u003e\n","md":"Say you have a blog that talks about science or data on a regular basis. What do you do?"},"extended":{"html":"\u003cp\u003eSay you have a blog that talks about science or data on a regular basis. You want to display some data. You could do the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecreate the chart in Excel and export it as an image\u003c/li\u003e\n\u003cli\u003ecreate the chart in Google sheets and display within an iframe\u003c/li\u003e\n\u003cli\u003euse a plugin or another third-party solution\u003c/li\u003e\n\u003cli\u003ehire a developer\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAll of these have their drawbacks. Images of data usually don\u0026#39;t work well across a variety of devices and screen sizes. Iframes aren\u0026#39;t responsive either, and frequently show up with scroll bars, which can be even worse.\u003c/p\u003e\n\u003cp\u003eI\u0026#39;m interested in a third-party solution that was across types of data, content-management platforms, and provides a neat platform to developers to iterate off of to create new chart types.\u003c/p\u003e\n\u003cp\u003eHere\u0026#39;s a simple example:\u003c/p\u003e\n\u003cp\u003e\u003cdiv data-chartpen-id=\"CTw3KYQlFh0A\"\u003e\u003c/div\u003e\u003c/p\u003e\n\u003cscript type=\"text/javascript\" src=\"//chartpen.app/dist/remote.js\"\u003e\u003c/script\u003e\n\n\u003cp\u003eIt\u0026#39;s a standalone app hosted by me, but it also a js file that be embedded on remote sites. It doesn\u0026#39;t require you to log in, but when working with the app it saves your data locally so that you can come back to it. When you\u0026#39;re done, you simply hit \u0026quot;Publish\u0026quot; and it gives you a line of HTML to embed your Chart anywhere on the web.\u003c/p\u003e\n\u003cp\u003eMy goal is to make the chart themselves as versatile as possible by making each chart type responsive out the box, using a \u003ca href=\"https://learnui.design/tools/data-color-picker.html\"\u003ecouple of algorithms\u003c/a\u003e to generate color schemes, and giving the \u003cem\u003eend-user\u003c/em\u003e some limited control over things like axes. \u003c/p\u003e\n","md":"Say you have a blog that talks about science or data on a regular basis. You want to display some data. You could do the following:\r\n\r\n- create the chart in Excel and export it as an image\r\n- create the chart in Google sheets and display within an iframe\r\n- use a plugin or another third-party solution\r\n- hire a developer\r\n\r\nAll of these have their drawbacks. Images of data usually don't work well across a variety of devices and screen sizes. Iframes aren't responsive either, and frequently show up with scroll bars, which can be even worse.\r\n\r\nI'm interested in a third-party solution that was across types of data, content-management platforms, and provides a neat platform to developers to iterate off of to create new chart types.\r\n\r\nHere's a simple example:\r\n\r\n\u003cdiv data-chartpen-id=\"CTw3KYQlFh0A\"\u003e\u003c/div\u003e\r\n\u003cscript type=\"text/javascript\" src=\"//chartpen.app/dist/remote.js\"\u003e\u003c/script\u003e\r\n\r\nIt's a standalone app hosted by me, but it also a js file that be embedded on remote sites. It doesn't require you to log in, but when working with the app it saves your data locally so that you can come back to it. When you're done, you simply hit \u0026quot;Publish\u0026quot; and it gives you a line of HTML to embed your Chart anywhere on the web.\r\n\r\nMy goal is to make the chart themselves as versatile as possible by making each chart type responsive out the box, using a [couple of algorithms](https://learnui.design/tools/data-color-picker.html) to generate color schemes, and giving the _end-user_ some limited control over things like axes. "}},"publishedDate":{"$date":"2018-08-14T22:03:53.000Z"}}
{"_id":{"$oid":"5b60d19006b4cb76f813ded6"},"sortOrder":9,"slug":"abbey","title":"Abbey","__t":"Project","tech":[{"$oid":"57edd06c8a31cb06684b45a2"},{"$oid":"57edd229ecd6d32a6890f978"},{"$oid":"5b60d58c06b4cb76f813ded7"},{"$oid":"5b60d59906b4cb76f813ded8"}],"state":"published","__v":2,"author":{"$oid":"5b61f1f506b4cb76f813dedb"},"brief":"Web-based visualization tool for Sanger DNA sequencing results","links":{"code":"","site":"http://abbey.girihlet.com/"},"myRole":{"html":"\u003cp\u003eAs someone with molecular biology training, I took the lead on both designing the core user experience and writing the code. The resulting product allows  the user to interactively analyze SNP locations by examining the actual proportion of each nucleotide at a particular position. The resulting data can be exported as a CSV file.\u003c/p\u003e\n\u003cp\u003eOne particular challenge I encountered was achieving smooth animation of the data as the user scrolls back and forth across the sequence. The graph itself is drawn using an interplay of both the canvas element (often used for web-based video games) as well as normal HTML elements, to get both smooth scrolling and interactivity.\u003c/p\u003e\n","md":"As someone with molecular biology training, I took the lead on both designing the core user experience and writing the code. The resulting product allows  the user to interactively analyze SNP locations by examining the actual proportion of each nucleotide at a particular position. The resulting data can be exported as a CSV file.\r\n\r\nOne particular challenge I encountered was achieving smooth animation of the data as the user scrolls back and forth across the sequence. The graph itself is drawn using an interplay of both the canvas element (often used for web-based video games) as well as normal HTML elements, to get both smooth scrolling and interactivity."},"problem":{"html":"\u003cp\u003eThe client found themselves in possession of Sanger DNA sequencing data containing numerous single nucleotide polymorphisms (SNPs). Their data therefore was ill-suited to existing Sanger analysis software solutions, which generally focus on editing the resulting sequence, under the assumption that the sample is homogeneous and does not contain SNPs. We needed a dedicated solution to examine the data and specifically analyze the SNPs.\u003c/p\u003e\n","md":"The client found themselves in possession of Sanger DNA sequencing data containing numerous single nucleotide polymorphisms (SNPs). Their data therefore was ill-suited to existing Sanger analysis software solutions, which generally focus on editing the resulting sequence, under the assumption that the sample is homogeneous and does not contain SNPs. We needed a dedicated solution to examine the data and specifically analyze the SNPs."},"status":{"html":"\u003cp\u003eThe client is using it to generate data and the product is occasionally updated in response to their requests.\u003c/p\u003e\n","md":"The client is using it to generate data and the product is occasionally updated in response to their requests."},"publishedDate":{"$date":"2018-07-27T04:00:00.000Z"},"image":{"secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1541005949/isqgg3q1ushpdqjodap0.png","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1541005949/isqgg3q1ushpdqjodap0.png","resource_type":"image","format":"png","height":341,"width":815,"signature":"8fedb00ab0b7b13baeee1c51d4957a46d0a97ef1","version":1541005949,"public_id":"isqgg3q1ushpdqjodap0"}}
{"_id":{"$oid":"5b60d65306b4cb76f813ded9"},"sortOrder":10,"slug":"chartpen","title":"Chartpen","__t":"Project","tech":[{"$oid":"57edd234ecd6d32a6890f979"},{"$oid":"57edd06c8a31cb06684b45a2"},{"$oid":"57edd229ecd6d32a6890f978"},{"$oid":"57edd193ecd6d32a6890f972"}],"state":"archived","__v":1,"author":{"$oid":"57cddf32d75ea10a19c42073"},"brief":"Simple graphing solution for websites and blogs","links":{"code":"https://github.com/CAYdenberg/chartpen","site":"https://chartpen.app/"},"myRole":{"html":"\u003cp\u003eThis project was entirely of my conception and was designed and coded by me.\u003c/p\u003e\n","md":"This project was entirely of my conception and was designed and coded by me."},"problem":{"html":"\u003cp\u003eThe display of graphical data on the web is hard for content authors who do not have any coding experience. Chartpen gives them an easy solution, by both hosting their data, and giving them a set of ready-made chart types for display on any website.\u003c/p\u003e\n\u003cp\u003eIt also gives developers a common format to produce new chart types that interact with this common data format, providing a platform on which new chart types can be built.\u003c/p\u003e\n","md":"The display of graphical data on the web is hard for content authors who do not have any coding experience. Chartpen gives them an easy solution, by both hosting their data, and giving them a set of ready-made chart types for display on any website.\r\n\r\nIt also gives developers a common format to produce new chart types that interact with this common data format, providing a platform on which new chart types can be built."},"status":{"html":"","md":""},"publishedDate":{"$date":"2018-07-30T04:00:00.000Z"},"image":{"secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1534365638/j86m9n7rw5estqgwm4ye.png","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1534365638/j86m9n7rw5estqgwm4ye.png","resource_type":"image","format":"png","height":674,"width":1253,"signature":"ed3960b34a90d7791404158bfeeea6eab405be72","version":1534365638,"public_id":"j86m9n7rw5estqgwm4ye"}}
{"_id":{"$oid":"5b649e0206b4cb76f813dedd"},"slug":"thinking-in-state-the-tao-of-frontend-development","title":"Thinking in state: The tao of frontend development","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eOne of the side effects of working with redux is that it forces you to think about your application in terms of state instead of thinking in terms of user workflow. While state might seem like an implementation detail, with experience it becomes more a part of the design process, allowing us to accurately predict \u0026quot;sad path\u0026quot; situations that may arise when the app is in a particular state.\u003c/p\u003e\n","md":"One of the side effects of working with redux is that it forces you to think about your application in terms of state instead of thinking in terms of user workflow. While state might seem like an implementation detail, with experience it becomes more a part of the design process, allowing us to accurately predict \u0026quot;sad path\u0026quot; situations that may arise when the app is in a particular state."},"extended":{"html":"\u003cp\u003eOne of the side effects of working with redux is that it forces you to think about your application in terms of state instead of thinking in terms of user workflow. While state might seem like an implementation detail, with experience it becomes more a part of the design process, allowing us to accurately predict \u0026quot;sad path\u0026quot; situations that may arise when the app is in a particular state.\u003c/p\u003e\n\u003cp\u003eFor example, I once worked on an app that allowed users to perform real-estate searches and then favourite properties. If the user was not logged in at the time they clicked the favourite button/heart, they would be prompted to log in (and then the property would be favourited).\u003c/p\u003e\n\u003cp\u003eThe description of this feature, phrased as user stories, might look like this:\u003c/p\u003e\n\u003cblockquote\u003eAs a user, I need a favourite button, so that I can keep track of properties that are interesting to me.\u003c/blockquote\u003e\n\n\u003cblockquote\u003eAs a visitor (user without an account or not logged in), I need to be prompted to create an account when trying to perform actions that require one, so that I can gain all the benefits of being a user.\u003c/blockquote\u003e\n\n\u003cp\u003eThis seems simple at first glance. Maybe it would only take a couple of hours to implement, at most. But up until we\u0026#39;ve neglected to account for the state of the app at the time the favourite is clicked. Obviously, if the property has already been favourited, it can\u0026#39;t be favourited again, and (probably) clicking the same button should unfavourite it.\u003c/p\u003e\n\u003cp\u003eGiven-when-thens get us little closer to describing state:\u003c/p\u003e\n\u003cblockquote\u003eGiven a user is logged in and a property is not favourited, when the user clicks the favourite button, the property should be favourited.\u003c/blockquote\u003e\n\n\u003cblockquote\u003eGiven a user is logged in a property is favourited, when the user clicks the favourite button, the property should be unfavourited.\u003c/blockquote\u003e\n\n\u003cblockquote\u003eGiven a user is not logged in, when the user clicks the favourite button, the user should be prompted to log in and the property favourited.\u003c/blockquote\u003e\n\n\u003cp\u003ePut differently, there are two pieces of information we need to take action: whether the user is logged in, and whether the current property is favourited.\u003c/p\u003e\n\u003cp\u003eThere\u0026#39;s also one other cardinal rule of frontend development we should take into account:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTRUST NO ONE.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFor example, a user might click the favourite button, be prompted to log in and then get annoyed and click away from the modal or whatever we\u0026#39;ve used to interrupt them. Worse, they might log in to an existing account, and then we might find that they\u0026#39;ve \u003cem\u003ealready\u003c/em\u003e favourited the property in question. You can\u0026#39;t trust the user.\u003c/p\u003e\n\u003cp\u003eYou also can\u0026#39;t trust the network. Knowing whether the user is logged in, whether they\u0026#39;ve favourited any properties, the act of favouriting/unfavouriting the property, and the act of creating an account/logging in, all require network requests, which take time and can fail. What do we do if the user attempts to favourite a property and completes the registration form only to have the network fail at that point?\u003c/p\u003e\n\u003cp\u003eProcedurally it might be nightmare to describe all the different paths, but in terms of state it actually becomes manageable. For a task like this I would start by designing the state, which should contain the following items:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-js\"\u003euserLoadState: 0,\nuserId: null,\nloginModal: false,\nproperties: [{\n  id: \u0026#39;\u0026#39;,\n  favourite: false,\n  favouriteLoadState: 0,\n  // ... other data ...\n}]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e I use \u003ccode\u003eloadState\u003c/code\u003e fairly ubiquitously with the following convention: 0 - not requested, 1 - loading, 2 - loaded, -1 - error. Representing these values numerically has the advantage that we test things with a simple comparison - ie if we need to know if already have a particular piece of information we test \u003ccode\u003eloadState === 2\u003c/code\u003e if we want to know if we should try to get something we can do \u003ccode\u003eloadState \u0026amp;lt; 1\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFrom the description of the state, our \u0026quot;sad-path\u0026quot; cases and their solutions become apparent:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf \u003ccode\u003euserId === false\u003c/code\u003e, we\u0026#39;ll transition \u003ccode\u003eloginModal\u003c/code\u003e to true \u003cem\u003einstead of\u003c/em\u003e making any change to the \u003ccode\u003efavourite\u003c/code\u003e of a particular property. We can store the property id somewhere else and dispatch a new action to favourite the property once the login is successful. In fact, using redux, we can store the entire action (since actions are plain objects) to make it flexible enough to handle other types of events that might prompt a login.\u003c/li\u003e\n\u003cli\u003eIf either \u003ccode\u003euserLoadState\u003c/code\u003e or \u003ccode\u003efavouriteLoadState\u003c/code\u003e is 1 or -1, we probably want to disable the button entirely (since the user doesn\u0026#39;t know what action they are really taking). We\u0026#39;d want to show a loading icon or an error message somewhere if that\u0026#39;s the case.\u003c/li\u003e\n\u003cli\u003eIf everything is happy and the user can take action on the particular property, we can go ahead and reverse the value of \u003ccode\u003efavourite\u003c/code\u003e for that property. We\u0026#39;ll also set \u003ccode\u003efavouriteLoadState\u003c/code\u003e back to 1, and represent this difference in the UI, say by making the button slightly smaller. This small cue will give reassurance to the user when the button returns to its normal size that the network request was successful.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eBy \u0026quot;thinking in state\u0026quot; we\u0026#39;ve anticipated a number of \u0026quot;sad path\u0026quot; cases and hopefully saved ourselves some headaches down the road. If we sketch out the state needed to handle a particular feature we can do a better job of estimating the time required to implement something - and sometimes even realized that we may need to send things back to design. This insight comes from realizing that all possible states need to be accounted for.\u003c/p\u003e\n","md":"One of the side effects of working with redux is that it forces you to think about your application in terms of state instead of thinking in terms of user workflow. While state might seem like an implementation detail, with experience it becomes more a part of the design process, allowing us to accurately predict \u0026quot;sad path\u0026quot; situations that may arise when the app is in a particular state.\r\n\r\nFor example, I once worked on an app that allowed users to perform real-estate searches and then favourite properties. If the user was not logged in at the time they clicked the favourite button/heart, they would be prompted to log in (and then the property would be favourited).\r\n\r\nThe description of this feature, phrased as user stories, might look like this:\r\n\r\n\u003cblockquote\u003eAs a user, I need a favourite button, so that I can keep track of properties that are interesting to me.\u003c/blockquote\u003e\r\n\r\n\u003cblockquote\u003eAs a visitor (user without an account or not logged in), I need to be prompted to create an account when trying to perform actions that require one, so that I can gain all the benefits of being a user.\u003c/blockquote\u003e\r\n\r\nThis seems simple at first glance. Maybe it would only take a couple of hours to implement, at most. But up until we've neglected to account for the state of the app at the time the favourite is clicked. Obviously, if the property has already been favourited, it can't be favourited again, and (probably) clicking the same button should unfavourite it.\r\n\r\nGiven-when-thens get us little closer to describing state:\r\n\r\n\u003cblockquote\u003eGiven a user is logged in and a property is not favourited, when the user clicks the favourite button, the property should be favourited.\u003c/blockquote\u003e\r\n\r\n\u003cblockquote\u003eGiven a user is logged in a property is favourited, when the user clicks the favourite button, the property should be unfavourited.\u003c/blockquote\u003e\r\n\r\n\u003cblockquote\u003eGiven a user is not logged in, when the user clicks the favourite button, the user should be prompted to log in and the property favourited.\u003c/blockquote\u003e\r\n\r\nPut differently, there are two pieces of information we need to take action: whether the user is logged in, and whether the current property is favourited.\r\n\r\nThere's also one other cardinal rule of frontend development we should take into account:\r\n\r\n**TRUST NO ONE.**\r\n\r\nFor example, a user might click the favourite button, be prompted to log in and then get annoyed and click away from the modal or whatever we've used to interrupt them. Worse, they might log in to an existing account, and then we might find that they've _already_ favourited the property in question. You can't trust the user.\r\n\r\nYou also can't trust the network. Knowing whether the user is logged in, whether they've favourited any properties, the act of favouriting/unfavouriting the property, and the act of creating an account/logging in, all require network requests, which take time and can fail. What do we do if the user attempts to favourite a property and completes the registration form only to have the network fail at that point?\r\n\r\nProcedurally it might be nightmare to describe all the different paths, but in terms of state it actually becomes manageable. For a task like this I would start by designing the state, which should contain the following items:\r\n\r\n```js\r\nuserLoadState: 0,\r\nuserId: null,\r\nloginModal: false,\r\nproperties: [{\r\n  id: '',\r\n  favourite: false,\r\n  favouriteLoadState: 0,\r\n  // ... other data ...\r\n}]\r\n```\r\n\r\n**Note** I use `loadState` fairly ubiquitously with the following convention: 0 - not requested, 1 - loading, 2 - loaded, -1 - error. Representing these values numerically has the advantage that we test things with a simple comparison - ie if we need to know if already have a particular piece of information we test `loadState === 2` if we want to know if we should try to get something we can do `loadState \u0026lt; 1`.\r\n\r\nFrom the description of the state, our \u0026quot;sad-path\u0026quot; cases and their solutions become apparent:\r\n\r\n- If `userId === false`, we'll transition `loginModal` to true _instead of_ making any change to the `favourite` of a particular property. We can store the property id somewhere else and dispatch a new action to favourite the property once the login is successful. In fact, using redux, we can store the entire action (since actions are plain objects) to make it flexible enough to handle other types of events that might prompt a login.\r\n- If either `userLoadState` or `favouriteLoadState` is 1 or -1, we probably want to disable the button entirely (since the user doesn't know what action they are really taking). We'd want to show a loading icon or an error message somewhere if that's the case.\r\n- If everything is happy and the user can take action on the particular property, we can go ahead and reverse the value of `favourite` for that property. We'll also set `favouriteLoadState` back to 1, and represent this difference in the UI, say by making the button slightly smaller. This small cue will give reassurance to the user when the button returns to its normal size that the network request was successful.\r\n\r\n## Conclusion\r\n\r\nBy \u0026quot;thinking in state\u0026quot; we've anticipated a number of \u0026quot;sad path\u0026quot; cases and hopefully saved ourselves some headaches down the road. If we sketch out the state needed to handle a particular feature we can do a better job of estimating the time required to implement something - and sometimes even realized that we may need to send things back to design. This insight comes from realizing that all possible states need to be accounted for."}},"author":{"$oid":"57cddf32d75ea10a19c42073"},"publishedDate":{"$date":"2018-08-03T22:04:42.000Z"}}
{"_id":{"$oid":"5bca36cb8eae53022fec08e5"},"slug":"being-agile-as-a-freelancer","title":"Being Agile as a freelancer","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eWhen I began working a freelancer last year, I knew I wanted to use an agile approach to build apps for my clients, even if they were small projects. As there are limited resources for agiling independently, I thought I would write about my experience for others to use.\u003c/p\u003e\n","md":"When I began working a freelancer last year, I knew I wanted to use an agile approach to build apps for my clients, even if they were small projects. As there are limited resources for agiling independently, I thought I would write about my experience for others to use."},"extended":{"html":"\u003cp\u003eWhen I began working a freelancer last year, I knew I wanted to use an agile approach to build apps for my clients, even if they were small projects. As there are limited resources for agiling independently, I thought I would write about my experience for others to use.\u003c/p\u003e\n\u003cp\u003eFirst of all, some terms. I am going to contrast \u003cstrong\u003eAgile development\u003c/strong\u003e with the so-called \u003cstrong\u003ewaterfall approach\u003c/strong\u003e. In the waterfall approach, the entire website or application is envisioned from the beginning. The details vary a bit, but in my experience, it involves four stages: 1) wireframes, 2) mockups, 3) development and 4) deployment. At each stage, the client approves the work so far and the designer or developer moves on to the next stage.\u003c/p\u003e\n\u003cp\u003eIn the agile approach, a working website or app is produced at each stage. While the overall goal or scope is mapped out at the start, a key feature is that change is easy to handle. If a user changes their mind about particular featues as you go along, that feature can be changed without affecting the rest of the app. This is harder with waterfall, because a feature will be \u0026quot;present\u0026quot; in wireframes and mockups, but the client likely won\u0026#39;t \u003cstrong\u003efully\u003c/strong\u003e understand what it does until it works (is developed).\u003c/p\u003e\n\u003cp\u003eSo how do I do it? I begin by working with a client to map out a set of user stories in order to scope the project. I then seperate the stories into sprints and aim to complete each sprint every week or two. I request the client\u0026#39;s feedback and the end of each sprint and we make any changes we need to to the plan.\u003c/p\u003e\n\u003cp\u003eWithout fail, I have found this approach to be better for clients, better for developers, and better for the end-result. Here are the reasons why:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eYour clients stay engaged\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAsking clients to review work that is delivered using a waterfall approach means telling them what types of feedback you will accept at what time. If you show them mockups, they will give you feedback on language and copy. If you show them wireframes, they will likely be confused (and berate your poor colour choices). You can get sign-off at each stage only by telling them to ignore whatever doesn\u0026#39;t work (yet), and focus on what you want them to.\u003c/p\u003e\n\u003cp\u003eFor this reason, getting approval in a waterfall project always feels more like checking a box than actively involving the client. Only when they are able to fully use a feature will they understand whether you\u0026#39;ve built what they thought they were asking for.\u003c/p\u003e\n\u003cp\u003eAn obvious counter-argument: some clients don\u0026#39;t want to be engaged. They want you to go away and come back with working software. You don\u0026#39;t want these clients.\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eIt\u0026#39;s easier to estimate\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis may seem counterintuitive since embracing agile means embracing change, and estimates depend on accurate scoping. The key is to look at each sprint as an individual project and estimate based on that. Make sure the client understands your goal is to deliver \u003cem\u003eworking\u003c/em\u003e software at each sprint, and continuing the project depends on the agreement of both parties. That way, you are delivering a service, not a product.\u003c/p\u003e\n\u003cp\u003eGranted, most clients will want some assurance that you can build their entire vision for a price they deem reasonable. So it\u0026#39;s useful to be able to estimate a large project, assuming there are only minimal changes to the scope as you go along. Hopefully, your clients will understand that changes they request as you go along will generally add to that scope.\u003c/p\u003e\n\u003cp\u003eThe alternative, of course, is to argue with the client every time they ask for a change.\u003c/p\u003e\n\u003cp\u003eIt might seem that the agile approach lends itself only to hourly billing, but this need not be the case. Agreeing to a flat rate for a limited number of sprints is a great way to build trust and get the project off to a good start.\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eYou keep your clients\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eStop me if this sounds familiar: you launch a website for a client and don\u0026#39;t hear from them for five years or so. When their website begins to feel dated, they come back asking for a new one, and you start the process over again. That\u0026#39;s if you\u0026#39;re lucky - if you\u0026#39;re unlucky, they find another designer/developer/agency and they just call asking to transfer their domain.\u003c/p\u003e\n\u003cp\u003eYou\u0026#39;re delivering a service, not a product. Websites and apps are never done. Schedule some time to look at analytics, and test in the latest browsers after you launch and periodically every year or quarter. Your clients will get the most out of their websites/apps by continuously thinking about how to make them better. This is a win-win.\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eYour code is better\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAgile forces a particular way of thinking about code. A function is created for one purpose in one sprint; it is later given a new set of responsibilities in a future sprint. Because we have tests (right?), we know we aren\u0026#39;t breaking the function\u0026#39;s original purpose when we modify it to be more durable. We find bugs and fix them: we add more tests. The durability allows for change: it also makes it easier to find and fix problems. It makes it easier to repurpose units because the units. The code is better because it has been revisited several times.\u003c/p\u003e\n\u003cp\u003eFreelance projects worked on for a period of time by a single developer are going to be smaller in scale than projects worked on by a team over the course of years. With this difference in scale, it can be tempting to skip tests, ship code, and move on. And this is true, as far as it goes. But it ignores the basic reality that your software \u003cstrong\u003eis\u003c/strong\u003e going to change. It \u003cstrong\u003ewill\u003c/strong\u003e have bugs. Your clients \u003cstrong\u003ewill\u003c/strong\u003e change their minds, and if the projects get any attention from end users at all, they will have more requests that will lead to more change. Very likely the nature of this change will be to make it larger and more complex - so build for it from the beginning.\u003c/p\u003e\n","md":"When I began working a freelancer last year, I knew I wanted to use an agile approach to build apps for my clients, even if they were small projects. As there are limited resources for agiling independently, I thought I would write about my experience for others to use.\r\n\r\nFirst of all, some terms. I am going to contrast **Agile development** with the so-called **waterfall approach**. In the waterfall approach, the entire website or application is envisioned from the beginning. The details vary a bit, but in my experience, it involves four stages: 1) wireframes, 2) mockups, 3) development and 4) deployment. At each stage, the client approves the work so far and the designer or developer moves on to the next stage.\r\n\r\nIn the agile approach, a working website or app is produced at each stage. While the overall goal or scope is mapped out at the start, a key feature is that change is easy to handle. If a user changes their mind about particular featues as you go along, that feature can be changed without affecting the rest of the app. This is harder with waterfall, because a feature will be \u0026quot;present\u0026quot; in wireframes and mockups, but the client likely won't **fully** understand what it does until it works (is developed).\r\n\r\nSo how do I do it? I begin by working with a client to map out a set of user stories in order to scope the project. I then seperate the stories into sprints and aim to complete each sprint every week or two. I request the client's feedback and the end of each sprint and we make any changes we need to to the plan.\r\n\r\nWithout fail, I have found this approach to be better for clients, better for developers, and better for the end-result. Here are the reasons why:\r\n\r\n1. Your clients stay engaged\r\n\r\nAsking clients to review work that is delivered using a waterfall approach means telling them what types of feedback you will accept at what time. If you show them mockups, they will give you feedback on language and copy. If you show them wireframes, they will likely be confused (and berate your poor colour choices). You can get sign-off at each stage only by telling them to ignore whatever doesn't work (yet), and focus on what you want them to.\r\n\r\nFor this reason, getting approval in a waterfall project always feels more like checking a box than actively involving the client. Only when they are able to fully use a feature will they understand whether you've built what they thought they were asking for.\r\n\r\nAn obvious counter-argument: some clients don't want to be engaged. They want you to go away and come back with working software. You don't want these clients.\r\n\r\n2. It's easier to estimate\r\n\r\nThis may seem counterintuitive since embracing agile means embracing change, and estimates depend on accurate scoping. The key is to look at each sprint as an individual project and estimate based on that. Make sure the client understands your goal is to deliver _working_ software at each sprint, and continuing the project depends on the agreement of both parties. That way, you are delivering a service, not a product.\r\n\r\nGranted, most clients will want some assurance that you can build their entire vision for a price they deem reasonable. So it's useful to be able to estimate a large project, assuming there are only minimal changes to the scope as you go along. Hopefully, your clients will understand that changes they request as you go along will generally add to that scope.\r\n\r\nThe alternative, of course, is to argue with the client every time they ask for a change.\r\n\r\nIt might seem that the agile approach lends itself only to hourly billing, but this need not be the case. Agreeing to a flat rate for a limited number of sprints is a great way to build trust and get the project off to a good start.\r\n\r\n3. You keep your clients\r\n\r\nStop me if this sounds familiar: you launch a website for a client and don't hear from them for five years or so. When their website begins to feel dated, they come back asking for a new one, and you start the process over again. That's if you're lucky - if you're unlucky, they find another designer/developer/agency and they just call asking to transfer their domain.\r\n\r\nYou're delivering a service, not a product. Websites and apps are never done. Schedule some time to look at analytics, and test in the latest browsers after you launch and periodically every year or quarter. Your clients will get the most out of their websites/apps by continuously thinking about how to make them better. This is a win-win.\r\n\r\n4. Your code is better\r\n\r\nAgile forces a particular way of thinking about code. A function is created for one purpose in one sprint; it is later given a new set of responsibilities in a future sprint. Because we have tests (right?), we know we aren't breaking the function's original purpose when we modify it to be more durable. We find bugs and fix them: we add more tests. The durability allows for change: it also makes it easier to find and fix problems. It makes it easier to repurpose units because the units. The code is better because it has been revisited several times.\r\n\r\nFreelance projects worked on for a period of time by a single developer are going to be smaller in scale than projects worked on by a team over the course of years. With this difference in scale, it can be tempting to skip tests, ship code, and move on. And this is true, as far as it goes. But it ignores the basic reality that your software **is** going to change. It **will** have bugs. Your clients **will** change their minds, and if the projects get any attention from end users at all, they will have more requests that will lead to more change. Very likely the nature of this change will be to make it larger and more complex - so build for it from the beginning."}},"publishedDate":{"$date":"2019-01-07T18:42:48.000Z"},"author":{"$oid":"57cddf32d75ea10a19c42073"}}
{"_id":{"$oid":"5bd9dd7d44649043caddaf9e"},"sortOrder":11,"slug":"mitoviewer","title":"MitoViewer","__t":"Project","tech":[{"$oid":"5b60d59906b4cb76f813ded8"},{"$oid":"57edd06c8a31cb06684b45a2"},{"$oid":"57edd229ecd6d32a6890f978"}],"state":"published","__v":1,"author":{"$oid":"5b61f1f506b4cb76f813dedb"},"brief":"SVG-based viewer for genetic information","image":{"secure_url":"https://res.cloudinary.com/dfxksdivn/image/upload/v1541004953/v36o1t0qi4wjn6n2cfcw.png","url":"http://res.cloudinary.com/dfxksdivn/image/upload/v1541004953/v36o1t0qi4wjn6n2cfcw.png","resource_type":"image","format":"png","height":396,"width":1059,"signature":"b18ae9a23281fd0dd91d4fcb5182f3ba0e481533","version":1541004953,"public_id":"v36o1t0qi4wjn6n2cfcw"},"links":{"code":"","site":"http://mitoviewer.girihlet.com/"},"myRole":{"html":"\u003cp\u003eWorking from a SQLite database produced by Girihlet, I built an API to access the data and a JavaScript-based viewer that runs in the user\u0026#39;s browser. The user can view alleles and can manipulate the map by zooming, scrolling and rotating. Because the map is based on SVG, it is highly interactive: the user can drag to select regions for zooming and can get additional information about map features by hovering over them with the mouse.\u003c/p\u003e\n","md":"Working from a SQLite database produced by Girihlet, I built an API to access the data and a JavaScript-based viewer that runs in the user's browser. The user can view alleles and can manipulate the map by zooming, scrolling and rotating. Because the map is based on SVG, it is highly interactive: the user can drag to select regions for zooming and can get additional information about map features by hovering over them with the mouse."},"problem":{"html":"\u003cp\u003eGirihlet Inc. is a biotech startup deploying deep-sequencing technology. In one initiative, they have discovered that the human mitochondrial genome contains a great deal of \u003cem\u003eheteroplasmy:\u003c/em\u003e \u003ca href=\"https://pubmed.app/lens/4344500\"\u003egenetically distinct populations of mitochondria that are stably maintained during cell division\u003c/a\u003e. Some of these alleles have medical implications.\u003c/p\u003e\n\u003cp\u003eGirihlet required a web-based data viewer to make their work accessible to a broad audience.\u003c/p\u003e\n","md":"Girihlet Inc. is a biotech startup deploying deep-sequencing technology. In one initiative, they have discovered that the human mitochondrial genome contains a great deal of _heteroplasmy:_ [genetically distinct populations of mitochondria that are stably maintained during cell division](https://pubmed.app/lens/4344500). Some of these alleles have medical implications.\r\n\r\nGirihlet required a web-based data viewer to make their work accessible to a broad audience."},"status":{"html":"","md":""},"publishedDate":{"$date":"2018-10-31T04:00:00.000Z"}}
{"_id":{"$oid":"5c33a6900948c151432fcee3"},"slug":"why-and-how-to-start-with-react","title":"Why and How to Start With React","__t":"Talk","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eWhy you should try React, and how to do it without installing and configuring a million Webpack dependencies.\u003c/p\u003e\n","md":"Why you should try React, and how to do it without installing and configuring a million Webpack dependencies."}},"links":{"slides":"https://github.com/CAYdenberg/react-start","video":"https://www.youtube.com/watch?v=Y_vbKlEs3Pc"}}
{"_id":{"$oid":"5c33a75a0948c151432fcee4"},"slug":"finite-jest-pragmatic-unit-testing","title":"Finite Jest: Pragmatic Unit Testing","__t":"Talk","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eWhy you should write unit tests, and how to get started with the Jest test suite.\u003c/p\u003e\n","md":"Why you should write unit tests, and how to get started with the Jest test suite."}},"links":{"slides":"https://github.com/CAYdenberg/finite-jest","video":"https://www.youtube.com/watch?v=i9BOoe_F5rY\u0026t=5s"},"author":{"$oid":"57cddf32d75ea10a19c42073"}}
{"_id":{"$oid":"5c33a8fe0948c151432fcee5"},"slug":"the-script-tag-at-the-bottom-of-everything","title":"The script tag: at the bottom of everything","__t":"Talk","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eTo get started with JavaScript, you need to use the script tag. Most websites use dozens of them, and how they are used has lots of implications for performance and the security of your users.\u003c/p\u003e\n","md":"To get started with JavaScript, you need to use the script tag. Most websites use dozens of them, and how they are used has lots of implications for performance and the security of your users."}},"links":{"slides":"https://github.com/CAYdenberg/script-at-the-bottom-of-everything","video":"https://www.youtube.com/watch?v=F9z5awaO2gg\u0026t=135s"}}
{"_id":{"$oid":"5c461b8d8de8810dcd8acf5b"},"slug":"values","title":"Values","__t":"Page","state":"draft","__v":0,"content":{"extended":{"html":"\u003ch2 id=\"honesty-comes-before-all-else\"\u003eHonesty comes before all else\u003c/h2\u003e\n\u003cp\u003eThe most fundamental truth of being self-employed is that I am responsible for delivering on everything I promise. There is no one to pick me up when I stumble and no one to drag me across the finish line. \u003c/p\u003e\n\u003cp\u003eI will never inflate my skills or over-promise on a project, because the cost (relationships and reputation) are too much to lose. I always do my best to estimate accurately, and to be forthright with clients when a project takes a turn I\u0026#39;m uncomfortable with.\u003c/p\u003e\n\u003ch2 id=\"you-can-make-a-walled-garden-very-very-sweet-but-the-jungle-outside-is-always-more-appealing-in-the-long-term-\"\u003e\u0026quot;You can make a walled garden very, very sweet, but the jungle outside is always more appealing in the long term.\u0026quot;\u003c/h2\u003e\n\u003cp\u003eI first got interested in the web as a communication platform for academic researchers: people being paid to contribute to public knowledge. The quote above is from Tim Beners-Lee, who had similar interests; but he didn\u0026#39;t \u0026quot;get interested\u0026quot; in the web: he invented it.\u003c/p\u003e\n\u003cp\u003eThe programming languages and tooling that I work with are (almost) always open-source, because it is better for clients and better for users. The web - and JavaScript - have stood the test of time because despite their many limitations, they have robust community and have genuine interest in listening to those communities.\u003c/p\u003e\n\u003cp\u003eThere is something really profound about being able to send a document or application to anyone in the world via a URL. While paywalls or other barriers are not inherently evil, openness can always be strived for.\u003c/p\u003e\n\u003ch2 id=\"empathy-with-the-user-is-the-most-important-skill-of-a-software-developer\"\u003eEmpathy with the user is the most important skill of a software developer\u003c/h2\u003e\n\u003cp\u003eI have never heard a user complain about the following things:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe font on a website\u003c/li\u003e\n\u003cli\u003elack of parallax background images\u003c/li\u003e\n\u003cli\u003ea form element that that didn\u0026#39;t have floating labels or other animations\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis is not to say those things are not important! (Or that I will refuse to do them). It _is_ to say that those things can come with trade-offs, and sometimes those trade-offs are \u003cem\u003eother users\u003c/em\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe value of having just the right font has to be considered in light of users on slow connections who have to wait for the font to download before the page can render\u003c/li\u003e\n\u003cli\u003eThe value of the parallax background has to be considered in light of users of legacy browsers or devices, where lots of running JavaScript can slow things to a crawl\u003c/li\u003e\n\u003cli\u003ethe value of a a floating label has be considered in light of users with accessibility issues, where properly formed markup is far more important than style\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI have found that technology companies vastly overestimate the value of users who are most like them: who use Chrome, who have lightening fast connections and new phones, and who don\u0026#39;t have visual impairments or other disabilities. Those users are \u0026quot;visible\u0026quot;. Invisible users are real people - and real potential customers!\u003c/p\u003e\n\u003ch2 id=\"software-is-successful-because-it-s-changeable\"\u003eSoftware is successful because it\u0026#39;s changeable\u003c/h2\u003e\n\u003cp\u003eWe\u0026#39;ve all heard the phrase \u0026quot;software is eating the world\u0026quot;. The question is why. As a society, our expectations for software are shockingly low: jokes about broken Windows, the blue screen of death, control-alt-delete, the Chrome dinosaur, and bricking, probably go back to the dawn of the computer. Why is it that something so \u0026quot;bad\u0026quot; is transforming our society so quickly?\u003c/p\u003e\n\u003cp\u003eThe answer, I think, comes from the fundamental malleability of something that can be created with mere language. Hardware takes time to design and manufacture - and once built it\u0026#39;s rare to use it for something other than its original purpose. Software, as something more changeable, can be adapted and used across problem spaces much more rapidly.\u003c/p\u003e\n\u003cp\u003eThis is why, even as a freelancer, I\u0026#39;ve embraced agile processes and test-driven develpment. All features should be considered subject to change, and a project should be considered an evolving entity.\u003c/p\u003e\n","md":"## Honesty comes before all else\r\n\r\nThe most fundamental truth of being self-employed is that I am responsible for delivering on everything I promise. There is no one to pick me up when I stumble and no one to drag me across the finish line. \r\n\r\nI will never inflate my skills or over-promise on a project, because the cost (relationships and reputation) are too much to lose. I always do my best to estimate accurately, and to be forthright with clients when a project takes a turn I'm uncomfortable with.\r\n\r\n## \u0026quot;You can make a walled garden very, very sweet, but the jungle outside is always more appealing in the long term.\u0026quot;\r\n\r\nI first got interested in the web as a communication platform for academic researchers: people being paid to contribute to public knowledge. The quote above is from Tim Beners-Lee, who had similar interests; but he didn't \u0026quot;get interested\u0026quot; in the web: he invented it.\r\n\r\nThe programming languages and tooling that I work with are (almost) always open-source, because it is better for clients and better for users. The web - and JavaScript - have stood the test of time because despite their many limitations, they have robust community and have genuine interest in listening to those communities.\r\n\r\nThere is something really profound about being able to send a document or application to anyone in the world via a URL. While paywalls or other barriers are not inherently evil, openness can always be strived for.\r\n\r\n## Empathy with the user is the most important skill of a software developer\r\n\r\nI have never heard a user complain about the following things:\r\n- the font on a website\r\n- lack of parallax background images\r\n- a form element that that didn't have floating labels or other animations\r\n\r\nThis is not to say those things are not important! (Or that I will refuse to do them). It _is_ to say that those things can come with trade-offs, and sometimes those trade-offs are _other users_.\r\n\r\n- The value of having just the right font has to be considered in light of users on slow connections who have to wait for the font to download before the page can render\r\n- The value of the parallax background has to be considered in light of users of legacy browsers or devices, where lots of running JavaScript can slow things to a crawl\r\n- the value of a a floating label has be considered in light of users with accessibility issues, where properly formed markup is far more important than style\r\n\r\nI have found that technology companies vastly overestimate the value of users who are most like them: who use Chrome, who have lightening fast connections and new phones, and who don't have visual impairments or other disabilities. Those users are \u0026quot;visible\u0026quot;. Invisible users are real people - and real potential customers!\r\n\r\n## Software is successful because it's changeable\r\n\r\nWe've all heard the phrase \u0026quot;software is eating the world\u0026quot;. The question is why. As a society, our expectations for software are shockingly low: jokes about broken Windows, the blue screen of death, control-alt-delete, the Chrome dinosaur, and bricking, probably go back to the dawn of the computer. Why is it that something so \u0026quot;bad\u0026quot; is transforming our society so quickly?\r\n\r\nThe answer, I think, comes from the fundamental malleability of something that can be created with mere language. Hardware takes time to design and manufacture - and once built it's rare to use it for something other than its original purpose. Software, as something more changeable, can be adapted and used across problem spaces much more rapidly.\r\n\r\nThis is why, even as a freelancer, I've embraced agile processes and test-driven develpment. All features should be considered subject to change, and a project should be considered an evolving entity.\r\n"}}}
{"_id":{"$oid":"5c6e14448de8810dcd8acfd2"},"slug":"isomorphic-javascript-with-react-and-express","title":"Isomorphic JavaScript with React and Express","__t":"Talk","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eHow to set up a project that renders React on both the server and client.\u003c/p\u003e\n\u003cp\u003eThe presentation includes a \u003ca href=\"https://github.com/CAYdenberg/isomorphic-react-starter\"\u003eworking example code\u003c/a\u003e\u003c/p\u003e\n","md":"How to set up a project that renders React on both the server and client.\r\n\r\nThe presentation includes a [working example code](https://github.com/CAYdenberg/isomorphic-react-starter)"}},"links":{"slides":"https://docs.google.com/presentation/d/1iOv-6zQxR69pZxsBQy6APwrRXefkfsjao7zc1nD3N1c/edit","video":"https://www.youtube.com/watch?v=u3QMquC6U0I"}}
{"_id":{"$oid":"5d66eb808de8810dcd8ad135"},"slug":"conspiracy-thinking-is-not-skepticism","title":"Conspiracy Thinking Is Not \"Skepticism\"","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eIs there something virtuous in the skepticism that allows one to persist in the belief that the world is flat? The answer is no.\u003c/p\u003e\n","md":"Is there something virtuous in the skepticism that allows one to persist in the belief that the world is flat? The answer is no."},"extended":{"html":"\u003cp\u003eIt is the Flat Earthers that finally gave me pause.\u003c/p\u003e\n\u003cp\u003eNot the hypothesis itself. In the spectrum of likely possible realities, I put \u0026quot;flat earth\u0026quot; in between \u003ca href=\"https://en.wikipedia.org/wiki/World_Turtle\"\u003ea world sitting on the back of turtle\u003c/a\u003e and \u003ca href=\"https://dangerousminds.net/comments/spurious_correlations_between_nicolas_cage_movies_and_swimming_pool\"\u003ea direct, causal relationship between Nicolas Cage movies and swimming pool drownings\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIs there, however, something virtuous in the skepticism that allows one to persist in the belief that the world is flat? I cannot prove it one way or the other, \u003ca href=\"https://www.wired.com/2014/05/wuwt-foucaults-pendulum/\"\u003eat least not without going to more trouble that I\u0026#39;m willing to\u003c/a\u003e. My relative certainty is based to a large degree on the relative certainty of others: the people who have done the experiments (and the reasoning to complement them). It is the rejection of consensus opinion that represents the conspiracy: the addendum that a large number of people are lying (or very deluded) to preserve a hypothesis that simply cannot be true if the vast majority of experts on that subject reject it.\u003c/p\u003e\n\u003cp\u003eAnd yet, skepticism is the foundation of science. \u0026quot;Collective wisdom\u0026quot; was rejected by Darwin, Galileo and Copernicus. How can we tell the difference?\u003c/p\u003e\n\u003cp\u003eTo start, there is nothing fundamentally flawed in proposing a conspiracy. People conspire to do things all the time: there is no reason a hypothesis is false simply because it involves a conspiracy. The point is that the more people a conspiracy would have to involve, the less chance such a reality could continue to persist without anyone speaking out. A world in which all national governments, astronomers, pilots and astronauts are deliberately lying to make us believe the world is round, for no reason, is not impossible. It is just extraordinarily unlikely.\u003c/p\u003e\n\u003cp\u003eThe difference between skepticism and conspiracy thinking is one of humility. Science is, above all, an act of ultimate humility. Science is creative only in the sense that Newton created Newton\u0026#39;s laws: the laws would still exist if he had never been born. One\u0026#39;s own intelligence, fortitude, conviction and work-ethic, have no bearing whatsoever on the answer.\u003c/p\u003e\n\u003cp\u003eDarwin, Galileo and Copernicus did not reject collective wisdom without cause. Each of them realized precisely why their key insight contradicted the standing consensus, and - critically - what evidence would overturn their own new theories.\u003c/p\u003e\n\u003cp\u003eConspiracy thinking is the opposite of humility. It is a belief that perseveres even in the presence of overwhelming contradictory evidence. It is an assertion of power over objective reality, that simple facts cannot confine the strength of ones\u0026#39; convictions. It is a cliche to say that knowledge is power. But it is also true that the illusion of knowledge is the illusion of power, a simple escape from the tyranny of cold, hard truth. It is also an attempt to disarm those smarmy experts who get to say what is what, simply because they\u0026#39;ve spent long enough studying the subject that they actually know what they\u0026#39;re talking about.\u003c/p\u003e\n\u003cp\u003eTo be fair, the Flat Earthers seem like nice people, and a certain level of distrust in our politicians and institutions is probably healthy. But really, what is the difference between them and the cess-pool dumpster-fire of nutbars \u003ca href=\"https://www.timesofisrael.com/parents-of-jewish-sandy-hook-victim-forced-to-move-7-times-due-to-harassment/\"\u003ethreatening grieving parents\u003c/a\u003e, and \u003ca href=\"https://www.esquire.com/news-politics/news/a51268/what-is-pizzagate/\"\u003eshooting up pizza joints\u003c/a\u003e, and \u003ca href=\"https://lawstreetmedia.com/news/alberta-parents-found-guilty-didnt-provide-necessaries-life/\"\u003ekilling their children through negligence\u003c/a\u003e? Only the selection of which truths they choose to reject. And without humility, there simply is no way to tell the difference.\u003c/p\u003e\n","md":"It is the Flat Earthers that finally gave me pause.\r\n\r\nNot the hypothesis itself. In the spectrum of likely possible realities, I put \u0026quot;flat earth\u0026quot; in between [a world sitting on the back of turtle](https://en.wikipedia.org/wiki/World_Turtle) and [a direct, causal relationship between Nicolas Cage movies and swimming pool drownings](https://dangerousminds.net/comments/spurious_correlations_between_nicolas_cage_movies_and_swimming_pool).\r\n\r\nIs there, however, something virtuous in the skepticism that allows one to persist in the belief that the world is flat? I cannot prove it one way or the other, [at least not without going to more trouble that I'm willing to](https://www.wired.com/2014/05/wuwt-foucaults-pendulum/). My relative certainty is based to a large degree on the relative certainty of others: the people who have done the experiments (and the reasoning to complement them). It is the rejection of consensus opinion that represents the conspiracy: the addendum that a large number of people are lying (or very deluded) to preserve a hypothesis that simply cannot be true if the vast majority of experts on that subject reject it.\r\n\r\nAnd yet, skepticism is the foundation of science. \u0026quot;Collective wisdom\u0026quot; was rejected by Darwin, Galileo and Copernicus. How can we tell the difference?\r\n\r\nTo start, there is nothing fundamentally flawed in proposing a conspiracy. People conspire to do things all the time: there is no reason a hypothesis is false simply because it involves a conspiracy. The point is that the more people a conspiracy would have to involve, the less chance such a reality could continue to persist without anyone speaking out. A world in which all national governments, astronomers, pilots and astronauts are deliberately lying to make us believe the world is round, for no reason, is not impossible. It is just extraordinarily unlikely.\r\n\r\nThe difference between skepticism and conspiracy thinking is one of humility. Science is, above all, an act of ultimate humility. Science is creative only in the sense that Newton created Newton's laws: the laws would still exist if he had never been born. One's own intelligence, fortitude, conviction and work-ethic, have no bearing whatsoever on the answer.\r\n\r\nDarwin, Galileo and Copernicus did not reject collective wisdom without cause. Each of them realized precisely why their key insight contradicted the standing consensus, and - critically - what evidence would overturn their own new theories.\r\n\r\nConspiracy thinking is the opposite of humility. It is a belief that perseveres even in the presence of overwhelming contradictory evidence. It is an assertion of power over objective reality, that simple facts cannot confine the strength of ones' convictions. It is a cliche to say that knowledge is power. But it is also true that the illusion of knowledge is the illusion of power, a simple escape from the tyranny of cold, hard truth. It is also an attempt to disarm those smarmy experts who get to say what is what, simply because they've spent long enough studying the subject that they actually know what they're talking about.\r\n\r\nTo be fair, the Flat Earthers seem like nice people, and a certain level of distrust in our politicians and institutions is probably healthy. But really, what is the difference between them and the cess-pool dumpster-fire of nutbars [threatening grieving parents](https://www.timesofisrael.com/parents-of-jewish-sandy-hook-victim-forced-to-move-7-times-due-to-harassment/), and [shooting up pizza joints](https://www.esquire.com/news-politics/news/a51268/what-is-pizzagate/), and [killing their children through negligence](https://lawstreetmedia.com/news/alberta-parents-found-guilty-didnt-provide-necessaries-life/)? Only the selection of which truths they choose to reject. And without humility, there simply is no way to tell the difference."}},"publishedDate":{"$date":"2019-10-29T01:33:04.000Z"},"author":{"$oid":"57cddf32d75ea10a19c42073"}}
{"_id":{"$oid":"5dcdc6b28de8810dcd8ad164"},"slug":"we-have-already-built-our-robot-overlords","title":"We have already built our robot overlords","__t":"Post","state":"draft","__v":0,"content":{"brief":{"html":"","md":""},"extended":{"html":"\u003cp\u003e\u003ca href=\"https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2\"\u003ehttps://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.technologyreview.com/2013/02/26/16555/house-of-cards-and-our-future-of-algorithmic-programming/\"\u003ehttps://www.technologyreview.com/2013/02/26/16555/house-of-cards-and-our-future-of-algorithmic-programming/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.newyorker.com/news/letter-from-silicon-valley/our-ghost-kitchen-future\"\u003ehttps://www.newyorker.com/news/letter-from-silicon-valley/our-ghost-kitchen-future\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://hedgehogreview.com/issues/questioning-the-quantified-life/articles/into-the-whirlpool\"\u003ehttps://hedgehogreview.com/issues/questioning-the-quantified-life/articles/into-the-whirlpool\u003c/a\u003e\u003c/p\u003e\n","md":"https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2\r\n\r\nhttps://www.technologyreview.com/2013/02/26/16555/house-of-cards-and-our-future-of-algorithmic-programming/\r\n\r\nhttps://www.newyorker.com/news/letter-from-silicon-valley/our-ghost-kitchen-future\r\n\r\nhttps://hedgehogreview.com/issues/questioning-the-quantified-life/articles/into-the-whirlpool"}}}
{"_id":{"$oid":"5ddec5288de8810dcd8ad16a"},"slug":"offline-first-web-apps-eventual-consistency","title":"Offline-first Web Apps: Eventual Consistency","__t":"Talk","state":"published","__v":0,"author":{"$oid":"57cddf32d75ea10a19c42073"},"content":{"brief":{"html":"\u003cp\u003eThe rise of local storage on the web platform creates new opportunities - and new challenges - for users to work on the web without an internet connection and sync their data when the network is available. What mental models do we need to think about syncing and data conflict management and what technologies will help us?\u003c/p\u003e\n","md":"The rise of local storage on the web platform creates new opportunities - and new challenges - for users to work on the web without an internet connection and sync their data when the network is available. What mental models do we need to think about syncing and data conflict management and what technologies will help us?"}},"links":{"slides":"https://docs.google.com/presentation/d/13oknSu618rGIOFPFnsXPw0rPtRFjeOuHb4OqhEgz7QI/edit?usp=sharing","video":"https://www.youtube.com/watch?v=j1xrpYWI0AY\u0026feature=youtu.be"}}
{"_id":{"$oid":"5de0204c8de8810dcd8ad16d"},"slug":"you-might-need-redux","title":"You might need Redux","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eFrontend development is currently contending with two crises simultaneously: the bewilderingly rapid increase in the complexity of our toolkit, and facing up to the fact that much of the software we write is brittle, bloated, and broken. While these are often conflated, we need to recognize that sometimes there is a balance between the two of them.\u003c/p\u003e\n","md":"Frontend development is currently contending with two crises simultaneously: the bewilderingly rapid increase in the complexity of our toolkit, and facing up to the fact that much of the software we write is brittle, bloated, and broken. While these are often conflated, we need to recognize that sometimes there is a balance between the two of them."},"extended":{"html":"\u003cp\u003eWhen my kids were babies, sometimes it felt like a one-hour trip to the store required more planning than an expedition to Antarctica. We had a diaper bag we packed with all the things we thought we might need, but it was the \u003cem\u003eway\u003c/em\u003e it was packed that mattered. Diapers and wet bags and wipes have to be accessible so they need to go at the top. So does a bottle of milk and a spit rag. And a change of clothes ... sonner or later you realize: everything has to go at the top.\u003c/p\u003e\n\u003cp\u003eI recently thought about this while adding application menus to an existing React app that does not use Redux. Menus can do anything - they are concerned with all manner of state and all manner of components in the applications. Since a core React principle is that state must live at a level higher in the component tree than the DOM elements that depend on it, virtually all the state in the application had to be pushed up at least to the level of the menus (which were near the very top of the tree). Everything has to go at the top.\u003c/p\u003e\n\u003cp\u003eI think this illustrates a general problem with using React to manage application state. It isn\u0026#39;t a problem for trivial data, for example the string of text in an input field (although even that can be non-trivial). But as soon as state becomes concerned with multiple parts of the DOM, it often has to live many levels above the components where it is actually controlled and/or displayed. The outcome of this is that components, which ideally are engineered in isolation, need to be engineered in the context of both their parents and children. Code is harder to reuse, bits of logic get duplicated, and bugs are harder to trace because the state of the application at any one time is never clear. Eric Elliot called this last complexity \u003ca href=\"https://medium.com/javascript-scene/10-tips-for-better-redux-architecture-69250425af44\"\u003e\u0026quot;time-travelling spaghetti\u0026quot;\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eI am not arguing that you have to use Redux itself. But, if you accept that all your state is going to live at or near the top of your component tree, you better have a good strategy to manage it all. \u003ccode\u003euseState\u003c/code\u003e is not good enough; as soon as anything becomes sufficiently complex it\u0026#39;s a tangled mess. \u003ccode\u003euseReducer\u003c/code\u003e seems like a simpler of version of Redux itself, which might be fine. Of course we\u0026#39;re going to need a way to manage network requests, and we might want middleware, and wouldn\u0026#39;t it be nice to have a debugging tool that logs actions -- and oh boy we just reinvented Redux.\u003c/p\u003e\n\u003cp\u003eThe best criticism I\u0026#39;ve heard of Redux is that it makes simple things hard. This is undeniably true. If you want to manage a checkbox in Redux, you need an action creator, a clause in your reducer, and you need to write the binding to the component with the checkbox. To truly use best practices, you also need a selector that picks the checkbox state out of the store. What an immense amount of work to flip a checkbox from off to on. Finally, you have to contend with JavaScript\u0026#39;s original sin: using inherently mutable data types (objects are arrays) \u003ca href=\"https://caydenberg.io/keystone/posts/58f127d3b777ce067fa0d7a0\"\u003eand ensuring that they never mutate\u003c/a\u003e. \u003c/p\u003e\n\u003cp\u003eAnother frequent pain-point for new adopters is that Redux is barely useful on its own. To use it for virtually any frontend application beyond a demo, it also requires on to pick middleware for managing asynchronous actions.\u003c/p\u003e\n\u003cp\u003eWhile these are completely valid criticisms, and the Redux maintainers would do well to listen to these voices (and they do \u003ca href=\"https://redux-toolkit.js.org/\"\u003eseem to be\u003c/a\u003e) it is critical to note that \u003cstrong\u003ethe tradeoff to making simple things hard is making complex things manageable\u003c/strong\u003e. The advantage of having a defined space of all possible application states is that is that all possible states can be reasoned about. In general, if a given state is possible based on the defined shape of your state, it should produce a defined result in the DOM (one that doesn\u0026#39;t result in fatal errors or cause the app to look broken). If a state is possible, it should be handled, even if the path needed to get to that state is not clear to the programmer.\u003c/p\u003e\n\u003cp\u003eThis is especially true when one considers that the possible edges are impacted not only by user behaviour but also by unknowns in the network conditions and the server.\u003c/p\u003e\n\u003cp\u003eApplication state can be decoupled from the view. This it makes it easy to shift between states if you need to add menus or key commands, and easy to write simple, predictable unit tests. Optimizing re-rendering becomes much easier when you can see determine exactly which state transitions will affect the component giving you problems.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eFrontend development is currently contending with two crises simultaneously: the bewilderingly rapid increase in the complexity of our toolkit, and facing up to the fact that much of the software we write is brittle, bloated, underperformant, and broken. Some have even argued that single-page applications are too hard for anyone but the richest software companies to invest in.\u003c/p\u003e\n\u003cp\u003eOften, these two crises are conflated and discussed in the same breath. But we need to recognize that tools can both increase the amount that a developer needs to know, and decrease the complexity of an application at scale. Redux is clearly and example of this, and the field should be careful to move past it and technology like it.\u003c/p\u003e\n","md":"When my kids were babies, sometimes it felt like a one-hour trip to the store required more planning than an expedition to Antarctica. We had a diaper bag we packed with all the things we thought we might need, but it was the _way_ it was packed that mattered. Diapers and wet bags and wipes have to be accessible so they need to go at the top. So does a bottle of milk and a spit rag. And a change of clothes ... sonner or later you realize: everything has to go at the top.\r\n\r\nI recently thought about this while adding application menus to an existing React app that does not use Redux. Menus can do anything - they are concerned with all manner of state and all manner of components in the applications. Since a core React principle is that state must live at a level higher in the component tree than the DOM elements that depend on it, virtually all the state in the application had to be pushed up at least to the level of the menus (which were near the very top of the tree). Everything has to go at the top.\r\n\r\nI think this illustrates a general problem with using React to manage application state. It isn't a problem for trivial data, for example the string of text in an input field (although even that can be non-trivial). But as soon as state becomes concerned with multiple parts of the DOM, it often has to live many levels above the components where it is actually controlled and/or displayed. The outcome of this is that components, which ideally are engineered in isolation, need to be engineered in the context of both their parents and children. Code is harder to reuse, bits of logic get duplicated, and bugs are harder to trace because the state of the application at any one time is never clear. Eric Elliot called this last complexity [\u0026quot;time-travelling spaghetti\u0026quot;](https://medium.com/javascript-scene/10-tips-for-better-redux-architecture-69250425af44).\r\n\r\nI am not arguing that you have to use Redux itself. But, if you accept that all your state is going to live at or near the top of your component tree, you better have a good strategy to manage it all. `useState` is not good enough; as soon as anything becomes sufficiently complex it's a tangled mess. `useReducer` seems like a simpler of version of Redux itself, which might be fine. Of course we're going to need a way to manage network requests, and we might want middleware, and wouldn't it be nice to have a debugging tool that logs actions -- and oh boy we just reinvented Redux.\r\n\r\nThe best criticism I've heard of Redux is that it makes simple things hard. This is undeniably true. If you want to manage a checkbox in Redux, you need an action creator, a clause in your reducer, and you need to write the binding to the component with the checkbox. To truly use best practices, you also need a selector that picks the checkbox state out of the store. What an immense amount of work to flip a checkbox from off to on. Finally, you have to contend with JavaScript's original sin: using inherently mutable data types (objects are arrays) [and ensuring that they never mutate](https://caydenberg.io/keystone/posts/58f127d3b777ce067fa0d7a0). \r\n\r\nAnother frequent pain-point for new adopters is that Redux is barely useful on its own. To use it for virtually any frontend application beyond a demo, it also requires on to pick middleware for managing asynchronous actions.\r\n\r\nWhile these are completely valid criticisms, and the Redux maintainers would do well to listen to these voices (and they do [seem to be](https://redux-toolkit.js.org/)) it is critical to note that **the tradeoff to making simple things hard is making complex things manageable**. The advantage of having a defined space of all possible application states is that is that all possible states can be reasoned about. In general, if a given state is possible based on the defined shape of your state, it should produce a defined result in the DOM (one that doesn't result in fatal errors or cause the app to look broken). If a state is possible, it should be handled, even if the path needed to get to that state is not clear to the programmer.\r\n\r\nThis is especially true when one considers that the possible edges are impacted not only by user behaviour but also by unknowns in the network conditions and the server.\r\n\r\nApplication state can be decoupled from the view. This it makes it easy to shift between states if you need to add menus or key commands, and easy to write simple, predictable unit tests. Optimizing re-rendering becomes much easier when you can see determine exactly which state transitions will affect the component giving you problems.\r\n\r\n\r\n* * *\r\n\r\nFrontend development is currently contending with two crises simultaneously: the bewilderingly rapid increase in the complexity of our toolkit, and facing up to the fact that much of the software we write is brittle, bloated, underperformant, and broken. Some have even argued that single-page applications are too hard for anyone but the richest software companies to invest in.\r\n\r\nOften, these two crises are conflated and discussed in the same breath. But we need to recognize that tools can both increase the amount that a developer needs to know, and decrease the complexity of an application at scale. Redux is clearly and example of this, and the field should be careful to move past it and technology like it."}},"publishedDate":{"$date":"2020-10-16T19:04:55.000Z"}}
{"_id":{"$oid":"5de020718de8810dcd8ad16e"},"slug":"why-is-teaching-programming-so-hard","title":"Why is teaching programming so hard?","__t":"Post","state":"draft","__v":0,"content":{"brief":{"html":"","md":""},"extended":{"html":"\u003cp\u003eLook at the image above. What does it look like to you?\u003c/p\u003e\n\u003cp\u003eLikely, you recognize it as music. But maybe beyond that it doesn\u0026#39;t mean much. If you took piano at some point, maybe you can see the keys on the piano you\u0026#39;d need to play it. Or maybe if you\u0026#39;ve a had a lot of music you can hear the notes in your head. The difference between those states is merely fluency: the ability to recognize patterns and derive meaning from what - to someone else - might be random symbols.\u003c/p\u003e\n\u003cp\u003eI have spent a few weekends recently teaching basic coding to kids ranging from pre-teen to late high school. More and more, educational theory seems to reject rote learning in favour of teaching concepts, and the curriculum I am working with is no exception. We want kids to understand the concepts behind programming and computer science, and so we cover \u003cstrong\u003ea lot of ground\u003c/strong\u003e because we don\u0026#39;t get too far into the weeds. \u003c/p\u003e\n\u003cp\u003eMore and more I am coming to this elevation of concept over rote may be painfully limited. In many cases, kids struggle to get seemingly basic things to work. When a TA finally makes it to them, it turns out they have a \u0026quot;seemingly\u0026quot; obvious syntax error, even in a line of that\u0026#39;s been directly copied off the projector. Someone fluent can spot it in a second.\u003c/p\u003e\n\u003cp\u003eHow do we teach fluency?\u003c/p\u003e\n","md":"Look at the image above. What does it look like to you?\r\n\r\nLikely, you recognize it as music. But maybe beyond that it doesn't mean much. If you took piano at some point, maybe you can see the keys on the piano you'd need to play it. Or maybe if you've a had a lot of music you can hear the notes in your head. The difference between those states is merely fluency: the ability to recognize patterns and derive meaning from what - to someone else - might be random symbols.\r\n\r\nI have spent a few weekends recently teaching basic coding to kids ranging from pre-teen to late high school. More and more, educational theory seems to reject rote learning in favour of teaching concepts, and the curriculum I am working with is no exception. We want kids to understand the concepts behind programming and computer science, and so we cover **a lot of ground** because we don't get too far into the weeds. \r\n\r\nMore and more I am coming to this elevation of concept over rote may be painfully limited. In many cases, kids struggle to get seemingly basic things to work. When a TA finally makes it to them, it turns out they have a \u0026quot;seemingly\u0026quot; obvious syntax error, even in a line of that's been directly copied off the projector. Someone fluent can spot it in a second.\r\n\r\nHow do we teach fluency?"}}}
{"_id":{"$oid":"5e2b7c1c8de8810dcd8ad182"},"slug":"why-the-frontend-is-getting-harder","title":"Why the frontend is getting harder","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eDistributed computing, formerly the province of academics, comes into the browser uninvited.\u003c/p\u003e\n","md":"Distributed computing, formerly the province of academics, comes into the browser uninvited."},"extended":{"html":"\u003cp\u003eI gave a talk recently extoling the virtues of PouchDB and how you can use it build web experiences that feel very much like native apps. In short, with PouchDB you can give users app-like experiences with no login, and that store data while offline. And yet they still have the best feature of web app: they can found with a URL.\u003c/p\u003e\n\u003cp\u003eAfter the talk, I got a very natural question:\u003c/p\u003e\n\u003cp\u003e\u0026gt; Are there any UI libraries for resolving conflicts?\u003c/p\u003e\n\u003cp\u003eConflicts are a natural part of PouchDB apps, because if two users edit the same piece of data while offline, it\u0026#39;s only natural that any differences have to be resolved.\u003c/p\u003e\n\u003cp\u003eThe question threw me for a minute, because at first I thought: \u0026quot;Hey! There should be UI for resolving conflicts! And this is JavaScript, and it\u0026#39;s 2019, if something \u003cem\u003eshould\u003c/em\u003e be built, surely someone has already done it!\u0026quot;\u003c/p\u003e\n\u003cp\u003eA few seconds of thought cleared it up for me, though. How you deal with conflicts depends entirely on the nature of the data being editing, and therefore there can be as much variety in conflict UI as there is in the UI for editing values in the first place. How you resolve a conflict in a rich-text document bears no relationship to how you would do it for, say, a phone number, and so the question is really moot.\u003c/p\u003e\n\u003cp\u003eThe full implications of the question didn\u0026#39;t really hit me until later, though. Basically, \u003cstrong\u003eif we want apps to work offline, we inherit all the problems of distributed computing\u003c/strong\u003e, whether PouchDB is our tool of choice or not. Distributed computing, formerly the province of academics, comes into the browser uninvited.\u003c/p\u003e\n\u003cp\u003eAnd of course, we\u0026#39;ve been in this movie before. When the logic of user interaction moved from the server to the client, \u003ca href=\"https://caydenberg.io/blog/thinking-in-state-the-tao-of-frontend-development\"\u003efrontend developers had to worry about managing application state\u003c/a\u003e, and we had to invent browser state machines. \u003c/p\u003e\n\u003cp\u003eWith more and more computation happening in the browser, frontend developers had to learn about time-complexity, mostly for the first time in their careers.\u003c/p\u003e\n\u003cp\u003eWhen more and more code had to be delivered to the client to perform these additional tasks, a whole new science of build pipelines and code-splitting grew up.\u003c/p\u003e\n\u003cp\u003eI think about this every time I see yet another blog post about how complicated web development has become. \u003cstrong\u003eIt\u0026#39;s become complicated because it is complicated.\u003c/strong\u003e\u003c/p\u003e\n","md":"I gave a talk recently extoling the virtues of PouchDB and how you can use it build web experiences that feel very much like native apps. In short, with PouchDB you can give users app-like experiences with no login, and that store data while offline. And yet they still have the best feature of web app: they can found with a URL.\r\n\r\nAfter the talk, I got a very natural question:\r\n\r\n\u0026gt; Are there any UI libraries for resolving conflicts?\r\n\r\nConflicts are a natural part of PouchDB apps, because if two users edit the same piece of data while offline, it's only natural that any differences have to be resolved.\r\n\r\nThe question threw me for a minute, because at first I thought: \u0026quot;Hey! There should be UI for resolving conflicts! And this is JavaScript, and it's 2019, if something _should_ be built, surely someone has already done it!\u0026quot;\r\n\r\nA few seconds of thought cleared it up for me, though. How you deal with conflicts depends entirely on the nature of the data being editing, and therefore there can be as much variety in conflict UI as there is in the UI for editing values in the first place. How you resolve a conflict in a rich-text document bears no relationship to how you would do it for, say, a phone number, and so the question is really moot.\r\n\r\nThe full implications of the question didn't really hit me until later, though. Basically, **if we want apps to work offline, we inherit all the problems of distributed computing**, whether PouchDB is our tool of choice or not. Distributed computing, formerly the province of academics, comes into the browser uninvited.\r\n\r\nAnd of course, we've been in this movie before. When the logic of user interaction moved from the server to the client, [frontend developers had to worry about managing application state](https://caydenberg.io/blog/thinking-in-state-the-tao-of-frontend-development), and we had to invent browser state machines. \r\n\r\nWith more and more computation happening in the browser, frontend developers had to learn about time-complexity, mostly for the first time in their careers.\r\n\r\nWhen more and more code had to be delivered to the client to perform these additional tasks, a whole new science of build pipelines and code-splitting grew up.\r\n\r\nI think about this every time I see yet another blog post about how complicated web development has become. **It's become complicated because it is complicated.**"}},"publishedDate":{"$date":"2020-02-28T23:44:27.000Z"},"author":{"$oid":"57cddf32d75ea10a19c42073"}}
{"_id":{"$oid":"5e3645098de8810dcd8ad186"},"slug":"everything-i-ever-needed-to-know-for-life-i-learned-from-the-wheel-of-time","title":"Everything I ever needed to know for life I learned from the Wheel of Time","__t":"Post","state":"draft","__v":0,"content":{"brief":{"html":"","md":""},"extended":{"html":"\u003cp\u003eYou can never know everything\u003c/p\u003e\n\u003cp\u003eYour own limitations are mostly in your mind\u003c/p\u003e\n\u003cp\u003eCulture and race are only regional manifestations of our common humanity\u003c/p\u003e\n\u003cp\u003eAll human institutions are flawed\u003c/p\u003e\n\u003cp\u003eThere is no greater sin than coercion\u003c/p\u003e\n\u003cp\u003eEvil can only succeed through coercion\u003c/p\u003e\n","md":"You can never know everything\r\n\r\nYour own limitations are mostly in your mind\r\n\r\nCulture and race are only regional manifestations of our common humanity\r\n\r\nAll human institutions are flawed\r\n\r\nThere is no greater sin than coercion\r\n\r\nEvil can only succeed through coercion"}}}
{"_id":{"$oid":"5f3d887f8de8810dcd8ad1f0"},"slug":"our-public-discourse-about-covid-19-is-completely-idiotic","title":"Our public discourse about COVID-19 is completely idiotic","__t":"Post","state":"published","__v":0,"content":{"brief":{"html":"\u003cp\u003eIn which I rant about how government, the press, and social media have shaped our view of a global threat, and created an insane response.\u003c/p\u003e\n","md":"In which I rant about how government, the press, and social media have shaped our view of a global threat, and created an insane response."},"extended":{"html":"\u003cp\u003eIn much of the developed world right now, it is possible to attend a movie but not a university lecture. This is the sort of insane fact we\u0026#39;ve gotten used to over the past few months, the sort of thing that makes us shake our heads for a moment, acknowledge that money talks, and move on with our lives. But this sort of resigned cynicism masks the basic frustration that all of us are dealing with, individually and as a society: we don\u0026#39;t know how to manage the risks associated with COVID-19 because we don\u0026#39;t know how much a threat it really is. The greatest frustration is that no one is interested in finding out, or apparently cares.\u003c/p\u003e\n\u003cp\u003e2020 may well be remembered as the year that social media went from being something irritating but ubiquitous, like genital herpes, to something actively dangerous, like HIV. In the nonsensical looking-glass reality inhabited by Facebook and Twitter \u0026quot;heavy users\u0026quot;, how to respond to a global pandemic - a once-a-century event that we supposedly should treat with all the seriousness of a world war - has become politicized to the point that we no longer know how to think about it. \u0026quot;Lockdownists\u0026quot;, typically those on the liberal side of the spectrum, have pushed for strict social distancing, closure of schools and non-essential workplaces, and mask-wearing compelled by the rule of law. They have also advocated for the generous use of social welfare to combat the inevitable collateral damage of these measures. \u0026quot;Anti-lockdownists\u0026quot;, typically those on the conservative side of the spectrum, have argued that this collateral damage is simply too much to be justified by the scale of the threat.\u003c/p\u003e\n\u003cp\u003eBoth of these positions are idiotic, because they advocate a course of action before understanding what that action is responding to. In fact, an individual\u0026#39;s understanding of the threat posed by the virus is far more likely to be informed by their personal beliefs about what the role of government is or should be, rather than any real-world data about epidemiology or transmission rates. In the most extreme cases, the desire to avoid open-mindedness about what can or should be done morphs into conspiracy theories. This sort of cart/action before horse/understanding mindset would be a catastrophe for a business or marriage; somehow in the social-media age, it has become our modus operandi for responding to important events.\u003c/p\u003e\n\u003cp\u003eThere is a way to measure the threat posed by COVID-19: random testing of the population, combined with monitoring of those tested over time. Not once, but again and again, in as many countries as possible. Since the beginning of the pandemic, there has been widespread confusion among epidemiologists and public health officials about the true deadliness of the virus. The original infection fatality ratio cited by the WHO was 3.4%, a number approaching the 1918 flu, was cause for alarm. That number is now generally regarded as being much too high, mostly due to the large number of people infected who never develop symptoms (or get tested). However, to develop an accurate model of the potential impact, there are too many other questions we don\u0026#39;t know the answer to: Is everyone susceptible? Are \u0026quot;asymptomatic\u0026quot; people merely pre-symptomatic? Can people be re-infected, and if so, will their symptoms be as severe, and can they spread the virus? Given the high rate of co-morbidity, how many deaths are \u003cem\u003edue to\u003c/em\u003e COVID-19, and how many would have happened anyway? What percentage of cases result in apparently chronic symptoms, even when the patient survives? \u003c/p\u003e\n\u003cp\u003eWestern governments are apparently uninterested in answering these questions. Yes, random testing is expensive, and raises some difficulties about personal freedoms, but so do all the other measures currently place in the name of social distancing. At the moment we are being asked for tremendous shared sacrifice, in Churchill-like language, by governments uninterested in determining whether our enemy is Hitler, or merely a loudmouthed but petty warlord.\u003c/p\u003e\n\u003cp\u003eMeanwhile, in the absence of accurate risk assessment, raw fear is being driven each day by an unscrupulous and scientifically illiterate popular press. The favourite phrase of the media these last months has been \u003cem\u003egrim milestone\u003c/em\u003e, in articles where cases or deaths pass some arbitrary mark, like an athlete reaching 50 goals in a season or 500 career home-runs. Since confirmed cases represent only a fraction of total infections, and since that fraction likely varies between regions and over time, these milestones are simple numerology: a belief in the mystical power of numbers.\u003c/p\u003e\n\u003cp\u003ePutting too much stock in the mostly-meaningless statistic of positive test count, journalists consistently commit an irksome fallacy where they ascribe any change in the numbers to some sort of simplistic and easily observable cause. If two different countries or regions have curves moving in different directions, it must be because one population is failing in their social distancing responsibilities. If more young people are testing positive, it must be because they are gathering and partying. These simplistic conclusions ignore any possible variation in the human population that affects their susceptibility, any variation in the viral population that affect its virility, and - most confoundingly - any variation in peoples\u0026#39; behaviour that affects their likelihood of getting a test.\u003c/p\u003e\n\u003cp\u003eThe true role of media should be to uncover truth, and to hold power to account. This would include not only doing their damnedest to answer the important questions, to the extent that good data is currently available, but also to demand that public officials explain the cost and consequences of their chosen strategy. While social distancing originally had to be enacted quickly and severely, it is now past time to discuss what the goal is in the medium- to long-term. Is our strategy to eradicate the virus? Prevent the healthcare system from being overwhelmed? Or to delay until a vaccine is available, if such a thing is even possible? Without understanding what we\u0026#39;re trying to do, any relaxation of social distancing \u003cem\u003eseems\u003c/em\u003e unacceptable, because some people will inevitably become infected as a result. To truly measure the benefit of social distancing, one first has to know how many of those people will eventually become infected anyway.\u003c/p\u003e\n\u003cp\u003eAnd yet the memes that substitute for public discourse have already had their say on this: \u0026quot;I will not die for the sake of the economy\u0026quot; is a particularly powerful and also stupid one. We accept all kinds of risk as a result of living our ordinary lives. If a child is killed by a car while walking to school, it would be very strange to say that the child was killed as a result of attending school. There is also no question (at least if you spend more than 240 characters thinking about it) that a sufficiently damaged economy will result in loss of human life.\u003c/p\u003e\n\u003cp\u003eRemember: I\u0026#39;m not arguing against lockdowns. That would be idiotic.\u003c/p\u003e\n\u003cp\u003ePerhaps my favourite meme is: \u0026quot;You cannot compare COVID to the seasonal flu\u0026quot;. This is demonstrably false. If the seasonal flu has an infection fatality rate of 0.1% and COVID-19 has an infection fatality rate of 0.6%, then COVID is six times deadlier than the seasonal flu. What you really cannot compare is the emotion surrounding something old and ordinary, versus something new and unmeasured. If only we knew more.\u003c/p\u003e\n","md":"In much of the developed world right now, it is possible to attend a movie but not a university lecture. This is the sort of insane fact we've gotten used to over the past few months, the sort of thing that makes us shake our heads for a moment, acknowledge that money talks, and move on with our lives. But this sort of resigned cynicism masks the basic frustration that all of us are dealing with, individually and as a society: we don't know how to manage the risks associated with COVID-19 because we don't know how much a threat it really is. The greatest frustration is that no one is interested in finding out, or apparently cares.\r\n\r\n2020 may well be remembered as the year that social media went from being something irritating but ubiquitous, like genital herpes, to something actively dangerous, like HIV. In the nonsensical looking-glass reality inhabited by Facebook and Twitter \u0026quot;heavy users\u0026quot;, how to respond to a global pandemic - a once-a-century event that we supposedly should treat with all the seriousness of a world war - has become politicized to the point that we no longer know how to think about it. \u0026quot;Lockdownists\u0026quot;, typically those on the liberal side of the spectrum, have pushed for strict social distancing, closure of schools and non-essential workplaces, and mask-wearing compelled by the rule of law. They have also advocated for the generous use of social welfare to combat the inevitable collateral damage of these measures. \u0026quot;Anti-lockdownists\u0026quot;, typically those on the conservative side of the spectrum, have argued that this collateral damage is simply too much to be justified by the scale of the threat.\r\n\r\nBoth of these positions are idiotic, because they advocate a course of action before understanding what that action is responding to. In fact, an individual's understanding of the threat posed by the virus is far more likely to be informed by their personal beliefs about what the role of government is or should be, rather than any real-world data about epidemiology or transmission rates. In the most extreme cases, the desire to avoid open-mindedness about what can or should be done morphs into conspiracy theories. This sort of cart/action before horse/understanding mindset would be a catastrophe for a business or marriage; somehow in the social-media age, it has become our modus operandi for responding to important events.\r\n\r\nThere is a way to measure the threat posed by COVID-19: random testing of the population, combined with monitoring of those tested over time. Not once, but again and again, in as many countries as possible. Since the beginning of the pandemic, there has been widespread confusion among epidemiologists and public health officials about the true deadliness of the virus. The original infection fatality ratio cited by the WHO was 3.4%, a number approaching the 1918 flu, was cause for alarm. That number is now generally regarded as being much too high, mostly due to the large number of people infected who never develop symptoms (or get tested). However, to develop an accurate model of the potential impact, there are too many other questions we don't know the answer to: Is everyone susceptible? Are \u0026quot;asymptomatic\u0026quot; people merely pre-symptomatic? Can people be re-infected, and if so, will their symptoms be as severe, and can they spread the virus? Given the high rate of co-morbidity, how many deaths are _due to_ COVID-19, and how many would have happened anyway? What percentage of cases result in apparently chronic symptoms, even when the patient survives? \r\n\r\nWestern governments are apparently uninterested in answering these questions. Yes, random testing is expensive, and raises some difficulties about personal freedoms, but so do all the other measures currently place in the name of social distancing. At the moment we are being asked for tremendous shared sacrifice, in Churchill-like language, by governments uninterested in determining whether our enemy is Hitler, or merely a loudmouthed but petty warlord.\r\n\r\nMeanwhile, in the absence of accurate risk assessment, raw fear is being driven each day by an unscrupulous and scientifically illiterate popular press. The favourite phrase of the media these last months has been _grim milestone_, in articles where cases or deaths pass some arbitrary mark, like an athlete reaching 50 goals in a season or 500 career home-runs. Since confirmed cases represent only a fraction of total infections, and since that fraction likely varies between regions and over time, these milestones are simple numerology: a belief in the mystical power of numbers.\r\n\r\nPutting too much stock in the mostly-meaningless statistic of positive test count, journalists consistently commit an irksome fallacy where they ascribe any change in the numbers to some sort of simplistic and easily observable cause. If two different countries or regions have curves moving in different directions, it must be because one population is failing in their social distancing responsibilities. If more young people are testing positive, it must be because they are gathering and partying. These simplistic conclusions ignore any possible variation in the human population that affects their susceptibility, any variation in the viral population that affect its virility, and - most confoundingly - any variation in peoples' behaviour that affects their likelihood of getting a test.\r\n\r\nThe true role of media should be to uncover truth, and to hold power to account. This would include not only doing their damnedest to answer the important questions, to the extent that good data is currently available, but also to demand that public officials explain the cost and consequences of their chosen strategy. While social distancing originally had to be enacted quickly and severely, it is now past time to discuss what the goal is in the medium- to long-term. Is our strategy to eradicate the virus? Prevent the healthcare system from being overwhelmed? Or to delay until a vaccine is available, if such a thing is even possible? Without understanding what we're trying to do, any relaxation of social distancing _seems_ unacceptable, because some people will inevitably become infected as a result. To truly measure the benefit of social distancing, one first has to know how many of those people will eventually become infected anyway.\r\n\r\nAnd yet the memes that substitute for public discourse have already had their say on this: \u0026quot;I will not die for the sake of the economy\u0026quot; is a particularly powerful and also stupid one. We accept all kinds of risk as a result of living our ordinary lives. If a child is killed by a car while walking to school, it would be very strange to say that the child was killed as a result of attending school. There is also no question (at least if you spend more than 240 characters thinking about it) that a sufficiently damaged economy will result in loss of human life.\r\n\r\nRemember: I'm not arguing against lockdowns. That would be idiotic.\r\n\r\nPerhaps my favourite meme is: \u0026quot;You cannot compare COVID to the seasonal flu\u0026quot;. This is demonstrably false. If the seasonal flu has an infection fatality rate of 0.1% and COVID-19 has an infection fatality rate of 0.6%, then COVID is six times deadlier than the seasonal flu. What you really cannot compare is the emotion surrounding something old and ordinary, versus something new and unmeasured. If only we knew more."}},"publishedDate":{"$date":"2020-08-30T19:30:14.000Z"}}
